{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218aeb79",
   "metadata": {
    "id": "218aeb79"
   },
   "source": [
    "## Predication with Different Classification Method to The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8u87wItZgc5z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10160,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "8u87wItZgc5z",
    "outputId": "afc8db8e-a3ed-44a0-a2b9-6ec5d7c597ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (0.13.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from scikeras) (3.7.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from scikeras) (1.5.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from keras>=3.2.0->scikeras) (24.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecb0a47",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "cecb0a47"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Ensemble Methods\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5f1c92",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "df5f1c92"
   },
   "outputs": [],
   "source": [
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b276802",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "4b276802",
    "outputId": "202ce665-362a-4eda-9c93-74ed5c461aab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function IPython.lib.pretty._type_pprint(obj, p, cycle)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set max output lines before scrolling\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.instance().display_formatter.formatters['text/plain'].for_type(\n",
    "    type, lambda obj, p, cycle: p.text(repr(obj)[:10000])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db941cad",
   "metadata": {
    "id": "db941cad"
   },
   "source": [
    "### Metrics Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aceecb7",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "1aceecb7"
   },
   "outputs": [],
   "source": [
    "#Metrics Calculations\n",
    "\n",
    "def calculate_metrics(classifier, y_val, y_pred):\n",
    "    print(f\"{classifier} metrics: \")\n",
    "\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9677b8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "c9677b8a"
   },
   "outputs": [],
   "source": [
    "def train_and_accuracy_gen(model, label, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    calculate_metrics(label, y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a91ddf",
   "metadata": {
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1733444518838,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "93a91ddf"
   },
   "outputs": [],
   "source": [
    "class ModelEvaluationPipeline:\n",
    "\n",
    "    param_grid_logistic_regression = {\n",
    "        'C': [0.01, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [100, 500, 1000]\n",
    "    }\n",
    "\n",
    "    param_grid_decission_tree_classifier = {\n",
    "        'max_depth': [None, 5, 20, 50],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "\n",
    "    param_grid_random_forest_classifier = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20, 50],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_gaussian_naive_bias = {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    }\n",
    "\n",
    "    param_grid_svc = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': [100, 500, 700, 900, 1100, 1500],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['minkowski'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    param_grid_ada_boost = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.5, 1.0],\n",
    "        'estimator': [\n",
    "            DecisionTreeClassifier(max_depth=1),\n",
    "            DecisionTreeClassifier(max_depth=3)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    }\n",
    "\n",
    "    param_grid_grad_boost = {\n",
    "      'n_estimators': [50, 100, 200],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 5, 7],\n",
    "      'random_state': [42]\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'model__n_neurons': [64],\n",
    "        'model__activation': ['relu', 'tanh'],\n",
    "        'epochs': [100, 150],\n",
    "        'batch_size': [50, 100]\n",
    "    }\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.feature_path = file_path\n",
    "        self.feature_df = self.get_feture()\n",
    "        self.X, self.y = self.split_feture_and_target()\n",
    "        self.y = self.map_zero_to_n() # mapping y zero to number of class to make it usable for some modles i.e. xgaboost\n",
    "        self.number_of_categories = self.get_number_of_categories()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.get_scale_and_test_train_split()\n",
    "\n",
    "    # data read and processing section\n",
    "    def remove_outliear(self, feature_df):\n",
    "        iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "        outliers = iso.fit_predict(feature_df)\n",
    "        data_cleaned = feature_df[outliers == 1]\n",
    "\n",
    "        return data_cleaned\n",
    "\n",
    "    def get_feture(self):\n",
    "        feature_df = pd.read_csv(self.feature_path)\n",
    "        feature_df = feature_df.iloc[:, 1:] # remove index\n",
    "\n",
    "        return self.remove_outliear(feature_df)\n",
    "\n",
    "    def split_feture_and_target(self):\n",
    "        X = self.feature_df.iloc[:, :-1]\n",
    "        y = self.feature_df.iloc[:, -1]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def get_scale_and_test_train_split(self):\n",
    "        #Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_fature = scaler.fit_transform(self.X)\n",
    "\n",
    "        #test train split\n",
    "        return train_test_split(scaled_fature, self.y, train_size=.20, random_state=42, stratify=self.y)\n",
    "\n",
    "    def map_zero_to_n(self):\n",
    "        unique_values = {val: idx for idx, val in enumerate(self.y.unique())}\n",
    "        y_mapped = self.y.map(unique_values)\n",
    "\n",
    "        return y_mapped\n",
    "\n",
    "    def get_number_of_categories(self):\n",
    "        return len(self.y.unique())\n",
    "\n",
    "    def onehot_encode(self):\n",
    "        self.y_train = to_categorical(self.y_train, num_classes = self.number_of_categories)\n",
    "\n",
    "        print(self.y_train.shape)\n",
    "\n",
    "    # Cross validation section\n",
    "    def kfold_cross_validation(self, model, n_splits):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        kfold_score = cross_val_score(model, self.X, self.y, cv=kf)\n",
    "        mean_score = np.mean(kfold_score)\n",
    "        print(\"K-fold cross-validation scores:\", kfold_score)\n",
    "        print(\"Mean K-fold cross-validation score:\", mean_score)\n",
    "\n",
    "    def stratified_cross_validation(self, model, n_splits):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        skfold_score = cross_val_score(model, self.X, self.y, cv=skf)\n",
    "        \n",
    "        mean_score = np.mean(skfold_score)\n",
    "        print(\"Straified cross validation scores:\", skfold_score)\n",
    "        print(\"Mean Straified cross-validation score:\", mean_score)\n",
    "\n",
    "    def cross_validation(self, model, n_splits):\n",
    "        self.kfold_cross_validation(model, n_splits)\n",
    "        self.stratified_cross_validation(model, n_splits)\n",
    "\n",
    "    # Hyper parameter tuning\n",
    "\n",
    "    def gridSerach(self, estimator, param_grid):\n",
    "        print(\"==== Grid Search: =====\")\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3, verbose=0)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters found: \", grid_search.best_params_)\n",
    "        print(\"Best score found: \", grid_search.best_score_)\n",
    "\n",
    "        return grid_search\n",
    "\n",
    "    def randomSearch(self, estimator, param_grid):\n",
    "        print(\"\\n==== Random Search: =====\")\n",
    "\n",
    "        random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=500, cv=3, random_state=42)\n",
    "        random_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters found: \", random_search.best_params_)\n",
    "        print(\"Best score found: \", random_search.best_score_)\n",
    "\n",
    "        return random_search\n",
    "\n",
    "    def hyper_parameter_tuning(self, model, param_grid):\n",
    "        grid_search = self.gridSerach(model, param_grid)\n",
    "        random_search = self.randomSearch(model, param_grid)\n",
    "\n",
    "        return grid_search if grid_search.best_score_ > random_search.best_score_ else random_search\n",
    "\n",
    "    # Models section\n",
    "    def run_logistic_regression_model(self):\n",
    "        print(\"=============== 1. Logistic Regression Section: ==================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(LogisticRegression(), self.param_grid_logistic_regression)\n",
    "        lrm = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(lrm, \"1. Logistic regression\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(lrm, 10)\n",
    "\n",
    "    def run_decission_tree_classifier_model(self):\n",
    "        print(\"=================2. Decission Tree Classifier Section: ================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(DecisionTreeClassifier(), self.param_grid_decission_tree_classifier)\n",
    "        dt = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(dt, \"2. Decission Tree Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(dt, 10)\n",
    "\n",
    "    def run_random_forest_classifier_model(self):\n",
    "        print(\"=================== 3. Random Forest Classifier Section: ==================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(RandomForestClassifier(), self.param_grid_random_forest_classifier)\n",
    "        rfc = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(rfc, \"3.  Random Forest Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(rfc, 10)\n",
    "\n",
    "    def run_gaussian_naive_bias_classifier_model(self):\n",
    "        print(\"=================== 4. Gaussian Naive Bias Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GaussianNB(), self.param_grid_gaussian_naive_bias)\n",
    "        gnb = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(gnb, \"4. Gaussian Naive Bias Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gnb, 10)\n",
    "\n",
    "\n",
    "    def run_support_vector_classifier_model(self):\n",
    "        print(\"=================== 5. Support Vector Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(SVC(), self.param_grid_svc)\n",
    "        svc = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(svc, \"5. Support Vector Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(svc, 10)\n",
    "\n",
    "\n",
    "    def run_knn_classifier_model(self):\n",
    "        print(\"=================== 6. K-Nearest Neighbors Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(KNeighborsClassifier(), self.param_grid_knn)\n",
    "        knn = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(knn, \"6. K-Nearest Neighbors\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(knn, 10)\n",
    "\n",
    "    def run_ada_boost_classifier_model(self):\n",
    "        print(\"=================== 7. Ada Boost Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(AdaBoostClassifier(), self.param_grid_ada_boost)\n",
    "        abc = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(abc, \"7. Ada Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(abc, 10)\n",
    "\n",
    "    def run_xg_boost_classifier_model(self):\n",
    "        print(\"=================== 8. XG Boost Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(XGBClassifier(), self.param_grid_xgb)\n",
    "        xgb = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(xgb, \"8. XG Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(xgb, 10)\n",
    "\n",
    "    def run_gradient_boost_classifier_model(self):\n",
    "        print(\"=================== 9. Gradient Boost Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GradientBoostingClassifier(), self.param_grid_grad_boost)\n",
    "        gb = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(gb, \"9. Gradient Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gb, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_ann(n_neurons=128, activation='relu'):\n",
    "        model = Sequential()\n",
    "        # Input layer\n",
    "        model.add(Dense(n_neurons, activation=activation, input_shape=(24,)))\n",
    "\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "\n",
    "        # Output layer (example for binary classification)\n",
    "        model.add(Dense(units=15, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def run_ann_model(self):\n",
    "        print(\"=================== 10. Artificial Neural Net Section: ===================\")\n",
    "\n",
    "        y_train_tmp = self.y_train\n",
    "\n",
    "        self.onehot_encode()\n",
    "\n",
    "        model = KerasClassifier(build_fn=self.build_ann, verbose=0, epochs = 50, batch_size = 100)\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(model, self.param_grid_ann)\n",
    "        ann = tuned_model.best_estimator_\n",
    "\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        calculate_metrics(\"10. Artificial Neuralnet\", self.y_test, y_pred_classes)\n",
    "        self.cross_validation(ann, 2)\n",
    "\n",
    "        self.y_train = y_train_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "xkrwkNYuf8X7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1733444518838,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "xkrwkNYuf8X7"
   },
   "outputs": [],
   "source": [
    "ROOT = '../data/Processed_Features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "A0T3QkR1CVXP",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "model_evaluation_pipeline = ModelEvaluationPipeline(ROOT + \"W500_O50_features.csv\")\n",
    "#model_evaluation_pipeline.run_ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40ba5f7e-4ef8-48ef-983d-a8d96e856514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================2. Decission Tree Classifier Section: ================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best score found:  0.4526228099448337\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 2, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best score found:  0.4521723611462547\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.30      0.26        44\n",
      "           1       0.95      0.80      0.87        45\n",
      "           2       0.42      0.59      0.49        44\n",
      "           3       0.72      0.70      0.71        44\n",
      "           4       0.85      0.80      0.82        44\n",
      "           5       0.85      0.77      0.81        44\n",
      "           6       0.43      0.36      0.39        45\n",
      "           7       0.79      0.95      0.87        44\n",
      "           8       0.51      0.57      0.54        44\n",
      "           9       0.50      0.41      0.45        44\n",
      "          10       0.87      0.75      0.80        44\n",
      "          11       0.83      0.89      0.86        44\n",
      "          12       0.56      0.69      0.62        45\n",
      "          13       0.56      0.50      0.53        44\n",
      "          14       0.56      0.41      0.47        44\n",
      "          15       0.23      0.24      0.24        45\n",
      "          16       0.07      0.07      0.07        44\n",
      "          17       0.44      0.43      0.44        44\n",
      "          18       0.18      0.18      0.18        44\n",
      "          19       0.30      0.41      0.35        41\n",
      "          20       0.51      0.48      0.49        44\n",
      "          21       0.10      0.09      0.10        44\n",
      "          22       0.17      0.17      0.17        40\n",
      "          23       0.43      0.48      0.45        44\n",
      "          24       0.44      0.52      0.48        44\n",
      "          25       0.78      0.64      0.70        44\n",
      "          26       0.64      0.66      0.65        44\n",
      "          27       0.27      0.36      0.31        44\n",
      "          28       0.85      0.66      0.74        44\n",
      "          29       0.24      0.20      0.22        44\n",
      "          30       0.85      0.39      0.53        44\n",
      "          31       0.13      0.09      0.11        44\n",
      "          32       0.62      0.48      0.54        44\n",
      "          33       0.18      0.27      0.21        44\n",
      "          34       0.59      0.43      0.50        44\n",
      "          35       0.07      0.07      0.07        43\n",
      "          36       0.24      0.25      0.25        44\n",
      "          37       0.16      0.20      0.18        44\n",
      "          38       0.24      0.20      0.22        44\n",
      "          39       0.13      0.16      0.14        44\n",
      "          40       0.57      0.64      0.61        36\n",
      "          41       0.06      0.02      0.03        44\n",
      "          42       0.46      0.48      0.47        44\n",
      "          43       0.17      0.16      0.17        44\n",
      "          44       0.12      0.18      0.15        44\n",
      "          45       0.70      0.76      0.73        41\n",
      "          46       0.41      0.52      0.46        42\n",
      "          47       0.41      0.17      0.24        42\n",
      "          48       0.31      0.27      0.29        41\n",
      "          49       0.59      0.59      0.59        41\n",
      "          50       0.75      0.50      0.60        42\n",
      "          51       0.26      0.26      0.26        42\n",
      "          52       0.95      0.85      0.90        46\n",
      "          53       0.33      0.34      0.33        41\n",
      "          54       0.35      0.28      0.31        43\n",
      "          55       0.21      0.29      0.25        41\n",
      "          56       0.76      0.67      0.71        42\n",
      "          57       0.47      0.61      0.53        44\n",
      "          58       0.42      0.30      0.35        44\n",
      "          59       0.70      0.70      0.70        44\n",
      "          60       0.32      0.50      0.39        44\n",
      "          61       0.90      0.64      0.75        44\n",
      "          62       0.38      0.25      0.30        44\n",
      "          63       0.95      0.91      0.93        44\n",
      "          64       0.44      0.55      0.48        44\n",
      "          65       0.84      0.73      0.78        44\n",
      "          66       0.52      0.59      0.55        44\n",
      "          67       0.29      0.34      0.32        44\n",
      "          68       0.28      0.41      0.33        39\n",
      "          69       0.49      0.48      0.48        44\n",
      "          70       0.42      0.38      0.40        39\n",
      "          71       0.81      0.77      0.79        44\n",
      "          72       0.56      0.79      0.65        42\n",
      "          73       0.30      0.22      0.25        46\n",
      "          74       0.61      0.85      0.71        47\n",
      "          75       0.70      0.67      0.68        57\n",
      "          76       0.38      0.43      0.40        44\n",
      "          77       0.21      0.16      0.18        44\n",
      "          78       0.58      0.50      0.54        44\n",
      "          79       0.26      0.32      0.29        41\n",
      "          80       1.00      0.36      0.53        53\n",
      "          81       0.32      0.36      0.34        42\n",
      "          82       0.82      0.90      0.86        41\n",
      "          83       0.17      0.21      0.19        42\n",
      "          84       0.37      0.32      0.34        50\n",
      "          85       0.91      1.00      0.95        41\n",
      "          86       0.94      0.76      0.84        41\n",
      "          87       0.31      0.30      0.31        33\n",
      "          88       1.00      0.98      0.99        48\n",
      "          89       0.87      0.83      0.85        41\n",
      "          90       0.13      0.14      0.13        29\n",
      "          91       0.38      0.60      0.47        43\n",
      "          92       0.69      0.80      0.74        45\n",
      "          93       0.97      0.78      0.86        45\n",
      "          94       0.47      0.82      0.60        45\n",
      "          95       0.26      0.37      0.31        43\n",
      "          96       0.69      0.80      0.74        46\n",
      "          97       0.88      0.78      0.82        45\n",
      "          98       0.19      0.16      0.17        45\n",
      "          99       0.42      0.22      0.29        46\n",
      "         100       0.30      0.29      0.29        45\n",
      "         101       0.48      0.27      0.34        45\n",
      "         102       0.30      0.33      0.32        45\n",
      "         103       0.19      0.18      0.18        45\n",
      "         104       0.81      0.96      0.88        46\n",
      "         105       0.68      0.37      0.48        46\n",
      "         106       0.93      1.00      0.96        41\n",
      "         107       0.41      0.25      0.31        44\n",
      "         108       0.55      0.26      0.35        42\n",
      "         109       0.65      0.69      0.67        45\n",
      "         110       0.40      0.48      0.44        46\n",
      "         111       0.00      0.00      0.00        12\n",
      "         112       0.23      0.42      0.30        45\n",
      "         113       0.44      0.32      0.37        44\n",
      "         114       0.49      0.67      0.57        45\n",
      "         115       0.87      0.91      0.89        45\n",
      "         116       0.50      0.26      0.34        23\n",
      "         117       0.70      0.80      0.74        44\n",
      "         118       0.48      0.57      0.52        44\n",
      "         119       0.31      0.44      0.37        45\n",
      "         120       0.64      0.74      0.69        47\n",
      "         121       0.77      0.56      0.65        41\n",
      "         122       0.55      0.66      0.60        41\n",
      "         123       0.87      0.98      0.92        41\n",
      "         124       0.46      0.83      0.59        41\n",
      "         125       0.92      0.80      0.86        41\n",
      "         126       0.81      0.62      0.70        42\n",
      "         127       0.33      0.39      0.35        44\n",
      "         128       0.61      0.50      0.55        46\n",
      "         129       0.46      0.26      0.33        43\n",
      "         130       0.60      0.68      0.64        41\n",
      "         131       0.60      0.59      0.59        41\n",
      "         132       0.74      0.73      0.74        44\n",
      "         133       0.58      0.77      0.66        44\n",
      "         134       0.80      0.64      0.71        44\n",
      "         135       0.48      0.50      0.49        44\n",
      "         136       0.43      0.48      0.45        44\n",
      "         137       0.31      0.30      0.31        43\n",
      "         138       0.29      0.23      0.25        44\n",
      "         139       0.36      0.41      0.38        44\n",
      "         140       0.42      0.36      0.39        44\n",
      "         141       0.20      0.18      0.19        44\n",
      "         142       0.10      0.09      0.09        44\n",
      "         143       0.76      0.80      0.78        44\n",
      "         144       0.16      0.20      0.18        44\n",
      "         145       0.62      0.55      0.58        44\n",
      "         146       0.24      0.18      0.21        44\n",
      "         147       0.08      0.11      0.10        44\n",
      "         148       0.90      0.82      0.86        45\n",
      "         149       0.30      0.36      0.33        39\n",
      "         150       0.91      0.91      0.91        44\n",
      "         151       0.71      0.59      0.64        46\n",
      "         152       0.42      0.32      0.36        41\n",
      "         153       0.02      0.03      0.03        32\n",
      "         154       0.53      0.61      0.57        44\n",
      "         155       0.95      0.78      0.86        46\n",
      "         156       1.00      1.00      1.00        48\n",
      "         157       0.80      0.89      0.84        44\n",
      "         158       0.68      0.59      0.63        46\n",
      "         159       0.96      0.96      0.96        45\n",
      "         160       0.29      0.33      0.31        36\n",
      "         161       0.58      0.75      0.65        44\n",
      "         162       0.81      0.83      0.82        36\n",
      "         163       0.59      0.73      0.65        41\n",
      "         164       0.25      0.09      0.13        11\n",
      "         165       0.92      0.85      0.89        41\n",
      "         166       0.50      0.55      0.52        42\n",
      "         167       0.00      0.00      0.00        41\n",
      "         168       0.30      0.43      0.35        42\n",
      "         169       0.33      0.46      0.38        41\n",
      "         170       0.55      0.49      0.52        45\n",
      "         171       0.48      0.24      0.32        42\n",
      "         172       0.52      0.40      0.45        43\n",
      "         173       0.81      0.85      0.83        41\n",
      "         174       0.09      0.12      0.10        41\n",
      "         175       0.46      0.43      0.44        42\n",
      "         176       0.32      0.34      0.33        44\n",
      "         177       0.28      0.22      0.25        45\n",
      "         178       0.08      0.05      0.06        44\n",
      "         179       0.59      0.45      0.51        44\n",
      "         180       0.31      0.34      0.33        44\n",
      "         181       0.55      0.25      0.34        44\n",
      "         182       0.39      0.55      0.46        44\n",
      "         183       0.37      0.34      0.35        44\n",
      "         184       0.61      0.74      0.67        42\n",
      "         185       0.26      0.25      0.26        44\n",
      "         186       0.32      0.18      0.23        44\n",
      "         187       0.11      0.11      0.11        45\n",
      "         188       0.33      0.36      0.35        44\n",
      "         189       0.83      0.55      0.66        44\n",
      "         190       0.14      0.09      0.11        44\n",
      "         191       0.26      0.41      0.32        44\n",
      "         192       0.77      0.75      0.76        44\n",
      "         193       0.15      0.13      0.14        45\n",
      "         194       0.26      0.21      0.23        43\n",
      "         195       0.21      0.31      0.25        42\n",
      "         196       0.58      0.43      0.49        44\n",
      "         197       0.19      0.18      0.18        44\n",
      "         198       0.09      0.11      0.10        45\n",
      "         199       0.59      0.66      0.62        44\n",
      "         200       0.64      0.41      0.50        44\n",
      "         201       0.14      0.09      0.11        44\n",
      "         202       0.42      0.50      0.45        44\n",
      "         203       0.25      0.32      0.28        44\n",
      "         204       0.49      0.48      0.48        44\n",
      "         205       0.10      0.09      0.10        44\n",
      "\n",
      "    accuracy                           0.48      8868\n",
      "   macro avg       0.48      0.47      0.47      8868\n",
      "weighted avg       0.49      0.48      0.47      8868\n",
      "\n",
      "K-fold cross validaiton scores: [0.65915239 0.63300271 0.625789   0.6465284  0.6299639  0.64801444\n",
      " 0.62184116 0.61552347 0.59205776 0.61462094]\n",
      "Straified cross validation scores: [0.63390442 0.62849414 0.62398557 0.62398557 0.64259928 0.63808664\n",
      " 0.6299639  0.63086643 0.61642599 0.6299639 ]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2762c3c-ebb4-460a-a3af-16587e341cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
