{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218aeb79",
   "metadata": {
    "id": "218aeb79"
   },
   "source": [
    "## Predication with Different Classification Method to The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8u87wItZgc5z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10160,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "8u87wItZgc5z",
    "outputId": "afc8db8e-a3ed-44a0-a2b9-6ec5d7c597ff"
   },
   "outputs": [],
   "source": [
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cecb0a47",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "cecb0a47"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Ensemble Methods\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df5f1c92",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "df5f1c92"
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b276802",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "4b276802",
    "outputId": "202ce665-362a-4eda-9c93-74ed5c461aab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(obj, p, cycle)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set maximum output lines before scrolling\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.instance().display_formatter.formatters['text/plain'].for_type(\n",
    "    type, lambda obj, p, cycle: p.text(repr(obj)[:10000])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db941cad",
   "metadata": {
    "id": "db941cad"
   },
   "source": [
    "### Metrics Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1aceecb7",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "1aceecb7"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(classifier, y_value, y_pred):\n",
    "    print(f\"\\n{classifier} Metrics: \")\n",
    "    print(classification_report(y_value, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9677b8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "c9677b8a"
   },
   "outputs": [],
   "source": [
    "def fit_model_and_generate_metrics(model, label, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    calculate_metrics(label, y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "93a91ddf",
   "metadata": {
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1733444518838,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "93a91ddf"
   },
   "outputs": [],
   "source": [
    "class ModelTuningAndEvaluation:\n",
    "\n",
    "    param_grid_logistic_regression = {\n",
    "        'C': [0.01, 1, 10],\n",
    "        'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [100, 500]\n",
    "    }\n",
    "\n",
    "    param_grid_decission_tree_classifier = {\n",
    "        'max_depth': [None, 5, 20, 50],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "\n",
    "    param_grid_random_forest_classifier = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [10, 20],\n",
    "        'bootstrap': [True],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_gaussian_naive_bias = {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    }\n",
    "\n",
    "    param_grid_svc = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': [100, 500, 700, 900, 1100],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['minkowski'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    param_grid_ada_boost = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.5, 1.0],\n",
    "        'estimator': [\n",
    "            DecisionTreeClassifier(max_depth=1)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'gamma': [0, 0.1],\n",
    "    }\n",
    "\n",
    "    param_grid_grad_boost = {\n",
    "      'n_estimators': [50, 100],\n",
    "      'learning_rate': [0.1, 0.2],\n",
    "      'max_depth': [3, 5],\n",
    "      'random_state': [42]\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'model__n_neurons': [64],\n",
    "        'model__activation': ['relu', 'tanh'],\n",
    "        'epochs': [100, 150],\n",
    "        'batch_size': [50, 100]\n",
    "    }\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.feature_path = file_path\n",
    "        self.feature_df = self.get_feture()\n",
    "        self.X, self.y = self.split_feture_and_target()\n",
    "        # for xgaboost mapping y to start from zero\n",
    "        self.y = self.map_zero_to_n() \n",
    "        self.number_of_categories = self.get_number_of_categories()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.get_scale_and_test_train_split()\n",
    "\n",
    "    # data read and processing section\n",
    "    def remove_outliear(self, feature_df):\n",
    "        iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "        outliers = iso.fit_predict(feature_df)\n",
    "        data_cleaned = feature_df[outliers == 1]\n",
    "        return data_cleaned\n",
    "\n",
    "    def get_feture(self):\n",
    "        feature_df = pd.read_csv(self.feature_path)\n",
    "        feature_df = feature_df.iloc[:, 1:] # remove index\n",
    "        return self.remove_outliear(feature_df)\n",
    "\n",
    "    def split_feture_and_target(self):\n",
    "        X = self.feature_df.iloc[:, :-1]\n",
    "        y = self.feature_df.iloc[:, -1]\n",
    "        return X, y\n",
    "\n",
    "    def get_scale_and_test_train_split(self):\n",
    "        #Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_fature = scaler.fit_transform(self.X)\n",
    "        #test train split\n",
    "        return train_test_split(scaled_fature, self.y, train_size=.20, random_state=42, stratify=self.y)\n",
    "\n",
    "    def map_zero_to_n(self):\n",
    "        unique_values = {val: idx for idx, val in enumerate(self.y.unique())}\n",
    "        y_mapped = self.y.map(unique_values)\n",
    "        return y_mapped\n",
    "\n",
    "    def get_number_of_categories(self):\n",
    "        return len(self.y.unique())\n",
    "\n",
    "    def onehot_encode(self):\n",
    "        self.y_train = to_categorical(self.y_train, num_classes = self.number_of_categories)\n",
    "        print(self.y_train.shape)\n",
    "\n",
    "    # Cross validation\n",
    "    def kfold_cross_validation(self, model, n_splits):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        kfold_score = cross_val_score(model, self.X, self.y, cv=kf)\n",
    "        mean_score = np.mean(kfold_score)\n",
    "        print(\"\\nK-fold cross-validation scores:\", kfold_score)\n",
    "        print(\"Mean K-fold cross-validation score:\", mean_score)\n",
    "\n",
    "    def stratified_cross_validation(self, model, n_splits):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        skfold_score = cross_val_score(model, self.X, self.y, cv=skf)\n",
    "        \n",
    "        mean_score = np.mean(skfold_score)\n",
    "        print(\"\\nStraified cross validation scores:\", skfold_score)\n",
    "        print(\"Mean Straified cross-validation score:\", mean_score)\n",
    "\n",
    "    def cross_validation(self, model, n_splits):\n",
    "        self.kfold_cross_validation(model, n_splits)\n",
    "        self.stratified_cross_validation(model, n_splits)\n",
    "\n",
    "    # Hyper-parameter tuning\n",
    "\n",
    "    def gridSerach(self, estimator, param_grid):\n",
    "        print(\"#---------- Grid Search ------------#\")\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3, verbose=0)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters: \", grid_search.best_params_)\n",
    "        print(\"Best score: \", grid_search.best_score_)\n",
    "        return grid_search\n",
    "\n",
    "    def randomSearch(self, estimator, param_grid):\n",
    "        print(\"\\n#---------- Random Search -----------#\")\n",
    "\n",
    "        random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=500, cv=3, random_state=42)\n",
    "        random_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters: \", random_search.best_params_)\n",
    "        print(\"Best score: \", random_search.best_score_)\n",
    "        return random_search\n",
    "\n",
    "    def hyper_parameter_tuning(self, model, param_grid):\n",
    "        grid_search = self.gridSerach(model, param_grid)\n",
    "        random_search = self.randomSearch(model, param_grid)\n",
    "        return grid_search if grid_search.best_score_ > random_search.best_score_ else random_search\n",
    "\n",
    "    # Models section\n",
    "    def logistic_regression_model(self):\n",
    "        print(\"#------------------- #1. Logistic Regression Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(LogisticRegression(), self.param_grid_logistic_regression)\n",
    "        lrm = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(lrm, \"Logistic Regression\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(lrm, 3)\n",
    "\n",
    "    def decission_tree_classifier_model(self):\n",
    "        print(\"#-------------------- #2. Decission Tree Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(DecisionTreeClassifier(), self.param_grid_decission_tree_classifier)\n",
    "        dt = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(dt, \"Decission Tree Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(dt, 3)\n",
    "\n",
    "    def random_forest_classifier_model(self):\n",
    "        print(\"#-------------------- #3. Random Forest Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(RandomForestClassifier(), self.param_grid_random_forest_classifier)\n",
    "        rfc = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(rfc, \"Random Forest Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(rfc, 3)\n",
    "\n",
    "    def gaussian_naive_bias_classifier_model(self):\n",
    "        print(\"#-------------------- #4. Gaussian Naive Bias Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GaussianNB(), self.param_grid_gaussian_naive_bias)\n",
    "        gnb = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(gnb, \"Gaussian Naive Bias Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gnb, 3)\n",
    "\n",
    "\n",
    "    def support_vector_classifier_model(self):\n",
    "        print(\"#-------------------- #5. Support Vector Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(SVC(), self.param_grid_svc)\n",
    "        svc = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(svc, \"Support Vector Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(svc, 3)\n",
    "\n",
    "\n",
    "    def knn_classifier_model(self):\n",
    "        print(\"#-------------------- #6. K-Nearest Neighbors Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(KNeighborsClassifier(), self.param_grid_knn)\n",
    "        knn = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(knn, \"K-Nearest Neighbors\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(knn, 3)\n",
    "\n",
    "    def ada_boost_classifier_model(self):\n",
    "        print(\"#-------------------- #7. Ada-Boost Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(AdaBoostClassifier(), self.param_grid_ada_boost)\n",
    "        abc = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(abc, \"Ada-Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(abc, 3)\n",
    "\n",
    "    def xg_boost_classifier_model(self):\n",
    "        print(\"-------------------- #8. XG Boost Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(XGBClassifier(), self.param_grid_xgb)\n",
    "        xgb = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(xgb, \"XG Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(xgb, 3)\n",
    "\n",
    "    def gradient_boost_model(self):\n",
    "        print(\"#-------------------- #9. Gradient Boost Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GradientBoostingClassifier(), self.param_grid_grad_boost)\n",
    "        gb = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(gb, \"Gradient Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gb, 3)\n",
    "\n",
    "    \n",
    "    # ----------------------- #10. Artificial Neural Net Model ------------------------#\n",
    "    def ann_kfold_cross_validation(self, model, n_splits=2, epochs=50, batch_size=100):\n",
    "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "      scores = []\n",
    "\n",
    "      X = self.X\n",
    "      y = self.y\n",
    "      for train_index, val_index in kf.split(X):\n",
    "          X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "          y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "          y_train = to_categorical(y_train, num_classes=self.number_of_categories)\n",
    "\n",
    "          model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "          # Evaluate the model\n",
    "          y_val_pred = np.argmax(model.predict(X_val), axis=1)  # Convert probabilities to class labels\n",
    "          accuracy = accuracy_score(y_val, y_val_pred)\n",
    "          scores.append(accuracy)\n",
    "\n",
    "      print(\"\\nK-fold cross-validation scores:\", scores)\n",
    "      print(\"Average score:\", np.mean(scores))\n",
    "\n",
    "    def ann_stratified_cross_validation(self, model, n_splits=2, epochs=50, batch_size=100):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "\n",
    "        for train_index, val_index in skf.split(self.X, self.y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            y_train = to_categorical(y_train, num_classes=self.number_of_categories)\n",
    "\n",
    "            model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_val_pred = np.argmax(model.predict(X_val), axis=1)  # Convert probabilities to class labels\n",
    "            accuracy = accuracy_score(y_val, y_val_pred)\n",
    "            scores.append(accuracy)\n",
    "\n",
    "        print(\"\\nStratified cross-validation scores:\", scores)\n",
    "        print(\"Average score:\", np.mean(scores))\n",
    "\n",
    "    def ann_cross_validation(self, model, n_splits=2, epochs=50, batch_size=100):\n",
    "        self.ann_kfold_cross_validation(model, n_splits, epochs, batch_size)\n",
    "        self.ann_stratified_cross_validation(model, n_splits, epochs, batch_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_ann(n_neurons=64, activation='relu'):\n",
    "        model = Sequential()\n",
    "        # Input layer\n",
    "        model.add(Dense(n_neurons, activation=activation, input_shape=(24,)))\n",
    "\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "\n",
    "        # Output layer (example for binary classification)\n",
    "        model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def ann_model(self):\n",
    "        print(\"#----------------------- #10. Artificial Neural Net Model ------------------------#\")\n",
    "\n",
    "        y_train_tmp = self.y_train\n",
    "\n",
    "        self.onehot_encode()\n",
    "\n",
    "        model = KerasClassifier(build_fn=self.build_ann, verbose=0, epochs = 50, batch_size = 100)\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(model, self.param_grid_ann)\n",
    "        ann = tuned_model.best_estimator_\n",
    "\n",
    "        ann.fit(self.X_train, self.y_train)\n",
    "        y_pred = ann.predict(self.X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        calculate_metrics(\"Artificial Neural Net\", self.y_test, y_pred_classes)\n",
    "        self.ann_cross_validation(ann)\n",
    "\n",
    "        self.y_train = y_train_tmp\n",
    "        \n",
    "    def driver(self):\n",
    "        self.run_ann_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "xkrwkNYuf8X7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1733444518838,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "xkrwkNYuf8X7"
   },
   "outputs": [],
   "source": [
    "path = '../data/Processed_Features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a7ab797-fc88-4549-80e3-a894b4ccb2e5",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "# Evaluation for W100_O25_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W100_O25_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12070a8f-49e6-42ad-ac43-d4e01fac55eb",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------- #1. Logistic Regression Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score:  0.3515655965120888\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "Best score:  0.3515655965120888\n",
      "Logistic Regression Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.43      0.32      2021\n",
      "           1       0.37      0.57      0.45      2114\n",
      "           2       0.26      0.24      0.25      2278\n",
      "           3       0.22      0.51      0.31      2224\n",
      "           4       0.32      0.33      0.33      2270\n",
      "           5       0.32      0.38      0.35      1974\n",
      "           6       0.27      0.12      0.16      2084\n",
      "           7       0.16      0.13      0.14      2222\n",
      "           8       0.60      0.80      0.69      1650\n",
      "           9       0.87      0.73      0.80      1698\n",
      "          10       0.61      0.71      0.66      1996\n",
      "          11       0.23      0.20      0.21      2172\n",
      "          12       0.27      0.05      0.09      2137\n",
      "          13       0.28      0.11      0.16      1788\n",
      "          14       0.25      0.04      0.07      1650\n",
      "\n",
      "    accuracy                           0.35     30278\n",
      "   macro avg       0.35      0.36      0.33     30278\n",
      "weighted avg       0.34      0.35      0.32     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.30383091 0.32655218 0.32021136 0.31651255 0.32496697 0.31545575\n",
      " 0.31281374 0.3147463  0.34196617 0.32003171]\n",
      "Mean K-fold cross-validation score: 0.31970876470768944\n",
      "Straified cross validation scores: [0.31413474 0.32549538 0.30356671 0.30805812 0.32628798 0.29775429\n",
      " 0.31492734 0.32161734 0.32082452 0.31183932]\n",
      "Mean Straified cross-validation score: 0.31445057546060584\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression on W100_O25_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "215375fa-1a21-4a55-bc78-b39b965ca436",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #2. Decission Tree Classifier Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5}\n",
      "Best score:  0.4975558197912538\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'min_samples_split': 2, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "Best score:  0.5001981767736822\n",
      "Decission Tree Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69      2021\n",
      "           1       0.83      0.74      0.79      2114\n",
      "           2       0.56      0.63      0.60      2278\n",
      "           3       0.62      0.59      0.61      2224\n",
      "           4       0.51      0.48      0.49      2270\n",
      "           5       0.34      0.34      0.34      1974\n",
      "           6       0.28      0.27      0.27      2084\n",
      "           7       0.40      0.41      0.41      2222\n",
      "           8       0.64      0.69      0.67      1650\n",
      "           9       0.83      0.83      0.83      1698\n",
      "          10       0.63      0.63      0.63      1996\n",
      "          11       0.45      0.44      0.44      2172\n",
      "          12       0.42      0.40      0.41      2137\n",
      "          13       0.41      0.43      0.42      1788\n",
      "          14       0.36      0.38      0.37      1650\n",
      "\n",
      "    accuracy                           0.53     30278\n",
      "   macro avg       0.53      0.53      0.53     30278\n",
      "weighted avg       0.53      0.53      0.53     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.61558785 0.61188904 0.62034346 0.62219287 0.60634082 0.61109643\n",
      " 0.63513871 0.64217759 0.62817125 0.61522199]\n",
      "Mean K-fold cross-validation score: 0.6208159992291815\n",
      "Straified cross validation scores: [0.62985469 0.61294584 0.62245707 0.62166446 0.61955086 0.61532365\n",
      " 0.61743725 0.61020085 0.6205074  0.61997886]\n",
      "Mean Straified cross-validation score: 0.6189920921295533\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Classifier on W100_O25_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b7ca97e-c79d-4f7f-ac40-e0a2a9ebd41a",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #3. Random Forest Classifier Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 500}\n",
      "Best score:  0.6364116792178623\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 200, 'max_depth': 20, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score:  0.6356189721231339\n",
      "Random Forest Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80      2021\n",
      "           1       0.87      0.87      0.87      2114\n",
      "           2       0.66      0.74      0.70      2278\n",
      "           3       0.68      0.69      0.69      2224\n",
      "           4       0.59      0.69      0.64      2270\n",
      "           5       0.40      0.61      0.49      1974\n",
      "           6       0.49      0.32      0.39      2084\n",
      "           7       0.49      0.54      0.51      2222\n",
      "           8       0.72      0.85      0.78      1650\n",
      "           9       0.91      0.88      0.89      1698\n",
      "          10       0.68      0.82      0.74      1996\n",
      "          11       0.72      0.50      0.59      2172\n",
      "          12       0.70      0.41      0.51      2137\n",
      "          13       0.58      0.50      0.54      1788\n",
      "          14       0.55      0.44      0.49      1650\n",
      "\n",
      "    accuracy                           0.65     30278\n",
      "   macro avg       0.65      0.65      0.64     30278\n",
      "weighted avg       0.65      0.65      0.64     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.74081902 0.7347424  0.74161162 0.71889036 0.72575958 0.72892999\n",
      " 0.73844122 0.75528541 0.74894292 0.71590909]\n",
      "Mean K-fold cross-validation score: 0.7349331608301379\n",
      "Straified cross validation scores: [0.74161162 0.73923382 0.73632761 0.73949802 0.7331572  0.73896962\n",
      " 0.732893   0.73546512 0.72991543 0.74233615]\n",
      "Mean Straified cross-validation score: 0.7369407586975403\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Classifier on W100_O25_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12627a95-a599-4995-898c-76c1491b295f",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #4. Gaussian Naive Bias Classifier Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'var_smoothing': 1e-09}\n",
      "Best score:  0.2212973972783723\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'var_smoothing': 1e-09}\n",
      "Best score:  0.2212973972783723\n",
      "Gaussian Naive Bias Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.88      0.20      2021\n",
      "           1       0.10      0.02      0.03      2114\n",
      "           2       0.11      0.07      0.09      2278\n",
      "           3       0.09      0.04      0.05      2224\n",
      "           4       0.23      0.13      0.16      2270\n",
      "           5       0.30      0.18      0.22      1974\n",
      "           6       0.16      0.07      0.10      2084\n",
      "           7       0.11      0.06      0.08      2222\n",
      "           8       0.52      0.65      0.58      1650\n",
      "           9       0.70      0.70      0.70      1698\n",
      "          10       0.49      0.57      0.52      1996\n",
      "          11       0.24      0.00      0.01      2172\n",
      "          12       0.21      0.01      0.03      2137\n",
      "          13       0.17      0.06      0.09      1788\n",
      "          14       0.14      0.03      0.05      1650\n",
      "\n",
      "    accuracy                           0.22     30278\n",
      "   macro avg       0.25      0.23      0.19     30278\n",
      "weighted avg       0.24      0.22      0.18     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.19286658 0.20290621 0.20845443 0.19048877 0.19682959 0.18996037\n",
      " 0.2007926  0.19714588 0.2140592  0.20798097]\n",
      "Mean K-fold cross-validation score: 0.20014845934072686\n",
      "Straified cross validation scores: [0.19762219 0.18837517 0.19260238 0.19815059 0.2005284  0.20898283\n",
      " 0.20554822 0.2095666  0.2032241  0.19635307]\n",
      "Mean Straified cross-validation score: 0.2000953538642857\n"
     ]
    }
   ],
   "source": [
    "# 4. Gaussian Naive Bayes on W100_O25_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ef0415-5601-495b-9e8e-c049dd559042",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #5. Support Vector Classifier Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score:  0.5768265292641036\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score:  0.5768265292641036\n",
      "Support Vector Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2021\n",
      "           1       0.83      0.85      0.84      2114\n",
      "           2       0.56      0.72      0.63      2278\n",
      "           3       0.59      0.68      0.63      2224\n",
      "           4       0.59      0.61      0.60      2270\n",
      "           5       0.38      0.41      0.39      1974\n",
      "           6       0.41      0.33      0.37      2084\n",
      "           7       0.49      0.46      0.47      2222\n",
      "           8       0.72      0.78      0.75      1650\n",
      "           9       0.73      0.88      0.80      1698\n",
      "          10       0.63      0.77      0.70      1996\n",
      "          11       0.51      0.47      0.49      2172\n",
      "          12       0.42      0.26      0.32      2137\n",
      "          13       0.55      0.43      0.48      1788\n",
      "          14       0.49      0.39      0.44      1650\n",
      "\n",
      "    accuracy                           0.59     30278\n",
      "   macro avg       0.58      0.59      0.58     30278\n",
      "weighted avg       0.57      0.59      0.58     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.16882431 0.16380449 0.17384412 0.16882431 0.15402906 0.17516513\n",
      " 0.18018494 0.16014799 0.1717759  0.16437632]\n",
      "Mean K-fold cross-validation score: 0.16809765654455527\n",
      "Straified cross validation scores: [0.17807133 0.17040951 0.17225892 0.17305152 0.16908851 0.1669749\n",
      " 0.16195509 0.1609408  0.16120507 0.18551797]\n",
      "Mean Straified cross-validation score: 0.16994736232094532\n"
     ]
    }
   ],
   "source": [
    "# 5. Support Vector Classifier on W100_O25_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a47d20f1-e356-4d62-bc53-1c413231aa08",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #6. K-Nearest Neighbors Classifier Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score:  0.49742370194213237\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score:  0.49742370194213237\n",
      "K-Nearest Neighbors Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68      2021\n",
      "           1       0.72      0.79      0.75      2114\n",
      "           2       0.44      0.65      0.52      2278\n",
      "           3       0.47      0.73      0.57      2224\n",
      "           4       0.55      0.50      0.52      2270\n",
      "           5       0.33      0.40      0.36      1974\n",
      "           6       0.37      0.17      0.24      2084\n",
      "           7       0.31      0.38      0.34      2222\n",
      "           8       0.49      0.86      0.62      1650\n",
      "           9       0.92      0.70      0.80      1698\n",
      "          10       0.55      0.67      0.60      1996\n",
      "          11       0.59      0.40      0.47      2172\n",
      "          12       0.75      0.28      0.41      2137\n",
      "          13       0.48      0.29      0.37      1788\n",
      "          14       0.51      0.20      0.28      1650\n",
      "\n",
      "    accuracy                           0.52     30278\n",
      "   macro avg       0.54      0.52      0.50     30278\n",
      "weighted avg       0.54      0.52      0.50     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.35719947 0.35719947 0.36089828 0.36908851 0.34742404 0.35587847\n",
      " 0.3682959  0.3615222  0.36707188 0.34408034]\n",
      "Mean K-fold cross-validation score: 0.3588658566557095\n",
      "Straified cross validation scores: [0.3675033  0.3653897  0.36116248 0.37569353 0.33976222 0.35799207\n",
      " 0.35508587 0.34936575 0.35729387 0.37130021]\n",
      "Mean Straified cross-validation score: 0.3600548998634311\n"
     ]
    }
   ],
   "source": [
    "# 6. K-Nearest Neighbors on W100_O25_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48417b5f-7b0b-47d2-800b-a37b454b625f",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #7. Ada-Boost Classifier Model --------------------#\n",
      "#-------- Grid Search --------#\n",
      "Best parameters:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best score:  0.3361078081648831\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 100, 'learning_rate': 0.01, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score:  0.3361078081648831\n",
      "Ada-Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.61      0.44      2021\n",
      "           1       0.76      0.28      0.41      2114\n",
      "           2       0.27      0.54      0.36      2278\n",
      "           3       0.36      0.47      0.41      2224\n",
      "           4       0.32      0.47      0.38      2270\n",
      "           5       0.26      0.66      0.37      1974\n",
      "           6       0.16      0.02      0.04      2084\n",
      "           7       0.23      0.23      0.23      2222\n",
      "           8       0.71      0.66      0.69      1650\n",
      "           9       0.84      0.01      0.02      1698\n",
      "          10       0.37      0.81      0.51      1996\n",
      "          11       0.50      0.26      0.34      2172\n",
      "          12       0.44      0.02      0.04      2137\n",
      "          13       0.32      0.05      0.09      1788\n",
      "          14       0.24      0.03      0.05      1650\n",
      "\n",
      "    accuracy                           0.35     30278\n",
      "   macro avg       0.41      0.34      0.29     30278\n",
      "weighted avg       0.40      0.35      0.29     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.32391017 0.32470277 0.33685601 0.32047556 0.34266843 0.32972259\n",
      " 0.34689564 0.30919662 0.34963002 0.33245243]\n",
      "Mean K-fold cross-validation score: 0.33165102454609685\n",
      "Straified cross validation scores: [0.32206077 0.3347424  0.32338177 0.32945839 0.34768824 0.32945839\n",
      " 0.32708058 0.33165962 0.32267442 0.34645877]\n",
      "Mean Straified cross-validation score: 0.3314663353450948\n"
     ]
    }
   ],
   "source": [
    "# 7. AdaBoost Classifier on W100_O25_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49207abc-5dcd-4125-a186-7084322dde32",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #9. Gradient Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score:  0.6123662306777646\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'random_state': 42, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.2}\n",
      "Best score:  0.6123662306777646\n",
      "Gradient Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2021\n",
      "           1       0.86      0.84      0.85      2114\n",
      "           2       0.64      0.70      0.66      2278\n",
      "           3       0.66      0.68      0.67      2224\n",
      "           4       0.62      0.64      0.63      2270\n",
      "           5       0.40      0.52      0.45      1974\n",
      "           6       0.38      0.33      0.36      2084\n",
      "           7       0.47      0.52      0.49      2222\n",
      "           8       0.76      0.82      0.79      1650\n",
      "           9       0.89      0.85      0.87      1698\n",
      "          10       0.71      0.79      0.75      1996\n",
      "          11       0.59      0.50      0.54      2172\n",
      "          12       0.56      0.43      0.48      2137\n",
      "          13       0.54      0.48      0.51      1788\n",
      "          14       0.48      0.40      0.44      1650\n",
      "\n",
      "    accuracy                           0.62     30278\n",
      "   macro avg       0.62      0.62      0.62     30278\n",
      "weighted avg       0.62      0.62      0.62     30278\n",
      "\n",
      "K-fold cross-validation scores: [0.69379128 0.69511229 0.7001321  0.69035667 0.69247028 0.67556143\n",
      " 0.70409511 0.71538055 0.7095666  0.68551797]\n",
      "Mean K-fold cross-validation score: 0.6961984270836533\n",
      "Straified cross validation scores: [0.6998679  0.69669749 0.6990753  0.70700132 0.69194188 0.69801849\n",
      " 0.67978864 0.6897463  0.69053911 0.69608879]\n",
      "Mean Straified cross-validation score: 0.6948765224361211\n"
     ]
    }
   ],
   "source": [
    "# 8. Gradient Boost on W100_O25_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3ac3f337-d5fa-45c4-89b7-257b7fa20cad",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- #8. XG Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 9. XGBoost Classifier on W100_O25_Features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxg_boost_classifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 230\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.xg_boost_classifier_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mxg_boost_classifier_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------- #8. XG Boost Classifier Model --------------------#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 230\u001b[0m     tuned_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyper_parameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXGBClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid_xgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     xgb \u001b[38;5;241m=\u001b[39m tuned_model\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    233\u001b[0m     fit_model_and_generate_metrics(xgb, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXG Boost Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test)\n",
      "Cell \u001b[1;32mIn[78], line 157\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.hyper_parameter_tuning\u001b[1;34m(self, model, param_grid)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhyper_parameter_tuning\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, param_grid):\n\u001b[1;32m--> 157\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgridSerach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     random_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandomSearch(model, param_grid)\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grid_search \u001b[38;5;28;01mif\u001b[39;00m grid_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m>\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;28;01melse\u001b[39;00m random_search\n",
      "Cell \u001b[1;32mIn[78], line 140\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.gridSerach\u001b[1;34m(self, estimator, param_grid)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#---------- Grid Search ------------#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mestimator, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 140\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 9. XGBoost Classifier on W100_O25_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce386c-5884-4658-b8ab-0a18af715f0b",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W100_O25_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be476206-82e2-4220-9050-5f1a70f0aa80",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "# Evaluation for W100_O50_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W100_O50_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b12d11f-e62b-4958-9688-79aa0d5cd409",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------- #1. Logistic Regression Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'C': 100, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score:  0.3527498002302693\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 500, 'C': 100}\n",
      "Best score:  0.3527498002302693\n",
      "Logistic Regression Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.32      3031\n",
      "           1       0.38      0.63      0.48      3168\n",
      "           2       0.27      0.27      0.27      3416\n",
      "           3       0.22      0.58      0.32      3333\n",
      "           4       0.34      0.33      0.33      3404\n",
      "           5       0.36      0.38      0.37      2958\n",
      "           6       0.29      0.14      0.19      3123\n",
      "           7       0.16      0.15      0.16      3334\n",
      "           8       0.61      0.78      0.69      2473\n",
      "           9       0.88      0.75      0.81      2536\n",
      "          10       0.66      0.68      0.67      2993\n",
      "          11       0.24      0.10      0.14      3257\n",
      "          12       0.21      0.06      0.10      3213\n",
      "          13       0.31      0.16      0.21      2681\n",
      "          14       0.25      0.07      0.11      2473\n",
      "\n",
      "    accuracy                           0.36     45393\n",
      "   macro avg       0.36      0.36      0.34     45393\n",
      "weighted avg       0.35      0.36      0.33     45393\n",
      "\n",
      "K-fold cross-validation scores: [0.18784141 0.17712372 0.18452591 0.18963694 0.18029609 0.17976736\n",
      " 0.18082481 0.18505464 0.19862531 0.17395136]\n",
      "Mean K-fold cross-validation score: 0.18376475429309672\n",
      "Straified cross validation scores: [0.18273128 0.18470215 0.1799436  0.18470215 0.18205851 0.18540712\n",
      " 0.17976736 0.19721537 0.18382094 0.18011984]\n",
      "Mean Straified cross-validation score: 0.18404683237085773\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression on W100_O50_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56b6b7ad-f260-4f12-bb3b-93c943538e1b",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #2. Decission Tree Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best score:  0.5348086262128361\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'min_samples_split': 2, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best score:  0.533663244033037\n",
      "Decission Tree Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73      3031\n",
      "           1       0.82      0.82      0.82      3168\n",
      "           2       0.62      0.63      0.63      3416\n",
      "           3       0.64      0.64      0.64      3333\n",
      "           4       0.54      0.53      0.54      3404\n",
      "           5       0.35      0.35      0.35      2958\n",
      "           6       0.32      0.31      0.32      3123\n",
      "           7       0.45      0.46      0.46      3334\n",
      "           8       0.68      0.73      0.71      2473\n",
      "           9       0.84      0.84      0.84      2536\n",
      "          10       0.68      0.66      0.67      2993\n",
      "          11       0.50      0.51      0.51      3257\n",
      "          12       0.46      0.46      0.46      3213\n",
      "          13       0.46      0.45      0.45      2681\n",
      "          14       0.40      0.41      0.41      2473\n",
      "\n",
      "    accuracy                           0.57     45393\n",
      "   macro avg       0.57      0.57      0.57     45393\n",
      "weighted avg       0.57      0.57      0.57     45393\n",
      "\n",
      "K-fold cross-validation scores: [0.66273128 0.66408178 0.66267184 0.6542122  0.66531547 0.65438844\n",
      " 0.65685583 0.66108565 0.66954529 0.68082481]\n",
      "Mean K-fold cross-validation score: 0.6631712595827012\n",
      "Straified cross validation scores: [0.66555066 0.66214311 0.66372929 0.65068735 0.65826577 0.66231935\n",
      " 0.66284808 0.66249559 0.66214311 0.65385971]\n",
      "Mean Straified cross-validation score: 0.6604042024909977\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Classifier on W100_O50_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9c9af-26ea-4e36-b20e-80c59cc73079",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W100_O50_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff19990a-24e2-4c9a-b227-34104c216a38",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #4. Gaussian Naive Bias Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'var_smoothing': 0.0001}\n",
      "Best score:  0.24656051018036984\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'var_smoothing': 0.0001}\n",
      "Best score:  0.24656051018036984\n",
      "\n",
      "Gaussian Naive Bias Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.81      0.27      3031\n",
      "           1       0.12      0.07      0.09      3168\n",
      "           2       0.11      0.05      0.07      3416\n",
      "           3       0.19      0.50      0.27      3333\n",
      "           4       0.23      0.13      0.16      3404\n",
      "           5       0.30      0.17      0.22      2958\n",
      "           6       0.14      0.07      0.09      3123\n",
      "           7       0.13      0.08      0.10      3334\n",
      "           8       0.53      0.62      0.57      2473\n",
      "           9       0.80      0.71      0.76      2536\n",
      "          10       0.47      0.58      0.52      2993\n",
      "          11       0.30      0.02      0.04      3257\n",
      "          12       0.03      0.00      0.00      3213\n",
      "          13       0.15      0.06      0.08      2681\n",
      "          14       0.13      0.03      0.05      2473\n",
      "\n",
      "    accuracy                           0.25     45393\n",
      "   macro avg       0.25      0.26      0.22     45393\n",
      "weighted avg       0.24      0.25      0.21     45393\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.13497797 0.13746916 0.135178   0.13746916 0.13429679 0.1247797\n",
      " 0.13112443 0.13306309 0.13165315 0.12989073]\n",
      "Mean K-fold cross-validation score: 0.13299021892891136\n",
      "\n",
      "Straified cross validation scores: [0.12722467 0.12883327 0.13130067 0.12795206 0.13077194 0.13112443\n",
      " 0.13412055 0.14134649 0.13412055 0.13623546]\n",
      "Mean Straified cross-validation score: 0.1323030097872823\n"
     ]
    }
   ],
   "source": [
    "# 4. Gaussian Naive Bayes on W100_O50_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d54c8974-6c89-4991-8b00-6018c49524e0",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #5. Support Vector Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score:  0.5836261324575477\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score:  0.5836261324575477\n",
      "\n",
      "Support Vector Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      3031\n",
      "           1       0.86      0.87      0.86      3168\n",
      "           2       0.61      0.74      0.67      3416\n",
      "           3       0.61      0.71      0.66      3333\n",
      "           4       0.61      0.65      0.63      3404\n",
      "           5       0.43      0.50      0.46      2958\n",
      "           6       0.46      0.35      0.40      3123\n",
      "           7       0.52      0.48      0.50      3334\n",
      "           8       0.75      0.81      0.78      2473\n",
      "           9       0.89      0.88      0.88      2536\n",
      "          10       0.62      0.81      0.70      2993\n",
      "          11       0.52      0.53      0.52      3257\n",
      "          12       0.46      0.31      0.37      3213\n",
      "          13       0.59      0.49      0.53      2681\n",
      "          14       0.55      0.42      0.47      2473\n",
      "\n",
      "    accuracy                           0.62     45393\n",
      "   macro avg       0.62      0.62      0.62     45393\n",
      "weighted avg       0.61      0.62      0.61     45393\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.17867841 0.17342263 0.19210434 0.18382094 0.17359887 0.17201269\n",
      " 0.17712372 0.17571378 0.19985901 0.18805076]\n",
      "Mean K-fold cross-validation score: 0.1814385146560787\n",
      "\n",
      "Straified cross validation scores: [0.17127753 0.18258724 0.1753613  0.18452591 0.18558336 0.17659499\n",
      " 0.17959112 0.18734579 0.17800493 0.1799436 ]\n",
      "Mean Straified cross-validation score: 0.1800815777664251\n"
     ]
    }
   ],
   "source": [
    "# 5. Support Vector Classifier on W100_O50_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98ca1940-6334-4a36-a5db-47b61c720448",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #6. K-Nearest Neighbors Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score:  0.5176236532579929\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score:  0.5176236532579929\n",
      "\n",
      "K-Nearest Neighbors Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67      3031\n",
      "           1       0.71      0.84      0.77      3168\n",
      "           2       0.46      0.71      0.56      3416\n",
      "           3       0.54      0.67      0.60      3333\n",
      "           4       0.55      0.53      0.54      3404\n",
      "           5       0.36      0.40      0.38      2958\n",
      "           6       0.43      0.20      0.27      3123\n",
      "           7       0.34      0.48      0.40      3334\n",
      "           8       0.50      0.86      0.64      2473\n",
      "           9       0.91      0.77      0.83      2536\n",
      "          10       0.58      0.69      0.63      2993\n",
      "          11       0.62      0.46      0.53      3257\n",
      "          12       0.75      0.35      0.48      3213\n",
      "          13       0.56      0.33      0.41      2681\n",
      "          14       0.51      0.24      0.33      2473\n",
      "\n",
      "    accuracy                           0.55     45393\n",
      "   macro avg       0.57      0.55      0.54     45393\n",
      "weighted avg       0.56      0.55      0.53     45393\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.3785022  0.37715897 0.376454   0.37539655 0.37945012 0.37733521\n",
      " 0.37486782 0.37046176 0.37839267 0.38508988]\n",
      "Mean K-fold cross-validation score: 0.37731091818465556\n",
      "\n",
      "Straified cross validation scores: [0.37726872 0.376454   0.37099048 0.37416285 0.37997885 0.37116673\n",
      " 0.38861473 0.38526613 0.36429327 0.37856891]\n",
      "Mean Straified cross-validation score: 0.3766764668889237\n"
     ]
    }
   ],
   "source": [
    "# 6. K-Nearest Neighbors on W100_O50_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8492252-5ed0-4bca-9df3-04b6ad1bf548",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #7. Ada-Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.5, 'n_estimators': 100}\n",
      "Best score:  0.2658628162888713\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 100, 'learning_rate': 0.5, 'estimator': DecisionTreeClassifier(max_depth=1)}\n",
      "Best score:  0.2658628162888713\n",
      "\n",
      "Ada-Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.30      0.24      3031\n",
      "           1       0.22      0.49      0.30      3168\n",
      "           2       0.23      0.21      0.22      3416\n",
      "           3       0.11      0.01      0.02      3333\n",
      "           4       0.26      0.29      0.27      3404\n",
      "           5       0.35      0.34      0.34      2958\n",
      "           6       0.18      0.05      0.08      3123\n",
      "           7       0.15      0.34      0.20      3334\n",
      "           8       0.37      0.59      0.46      2473\n",
      "           9       0.47      0.67      0.55      2536\n",
      "          10       0.25      0.23      0.24      2993\n",
      "          11       0.25      0.02      0.04      3257\n",
      "          12       0.34      0.35      0.34      3213\n",
      "          13       0.12      0.04      0.06      2681\n",
      "          14       0.23      0.03      0.05      2473\n",
      "\n",
      "    accuracy                           0.26     45393\n",
      "   macro avg       0.25      0.26      0.23     45393\n",
      "weighted avg       0.24      0.26      0.22     45393\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.31629956 0.29961227 0.31124427 0.32763483 0.29203384 0.31899894\n",
      " 0.29943602 0.29873105 0.32040888 0.30842439]\n",
      "Mean K-fold cross-validation score: 0.3092824057180213\n",
      "\n",
      "Straified cross validation scores: [0.31577093 0.30260839 0.29379626 0.33239337 0.30948185 0.3163553\n",
      " 0.30683821 0.32234755 0.31670779 0.31159676]\n",
      "Mean Straified cross-validation score: 0.3127896409777034\n"
     ]
    }
   ],
   "source": [
    "# 7. AdaBoost Classifier on W100_O50_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa81194-7998-49f9-9d42-8648131dc303",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W100_O50_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b034aad1-1fc1-4d03-9578-d2e89db4b20b",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- #8. XG Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 9. XGBoost Classifier on W100_O50_Features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxg_boost_classifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 230\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.xg_boost_classifier_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mxg_boost_classifier_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------- #8. XG Boost Classifier Model --------------------#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 230\u001b[0m     tuned_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyper_parameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXGBClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid_xgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     xgb \u001b[38;5;241m=\u001b[39m tuned_model\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    233\u001b[0m     fit_model_and_generate_metrics(xgb, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXG Boost Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test)\n",
      "Cell \u001b[1;32mIn[78], line 157\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.hyper_parameter_tuning\u001b[1;34m(self, model, param_grid)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhyper_parameter_tuning\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, param_grid):\n\u001b[1;32m--> 157\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgridSerach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     random_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandomSearch(model, param_grid)\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grid_search \u001b[38;5;28;01mif\u001b[39;00m grid_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m>\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;28;01melse\u001b[39;00m random_search\n",
      "Cell \u001b[1;32mIn[78], line 140\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.gridSerach\u001b[1;34m(self, estimator, param_grid)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#---------- Grid Search ------------#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mestimator, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 140\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 9. XGBoost Classifier on W100_O50_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903c504-9b3e-463f-b421-51ee981ce6c5",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W100_O50_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9092b8-46f5-4f42-8d27-3810b0da9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W200_O25_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W200_O25_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dda51b-658b-4c85-bc93-0b04c2464575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression on W200_O25_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c41771b-6e83-4795-b743-706d168085e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier on W200_O25_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3d1a0-ec41-4aac-962a-1b709aebd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W200_O25_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9a5e3-dc60-489c-8634-dff72f0dd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes on W200_O25_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84af67-88b3-4d67-ae38-195e63aad0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Support Vector Classifier on W200_O25_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61bbae-8a74-42c4-b6c6-43c518b3dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. K-Nearest Neighbors on W200_O25_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9a9b1-8275-4565-b2bc-b450aa08439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Classifier on W200_O25_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d34b8-73bd-4836-8fa0-d5fdbbf1c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W200_O25_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605d1c7-0cb4-4d4c-a4f1-7d71091fc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W200_O25_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b3eb5-adaa-4fb5-8237-532e78021db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W200_O25_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611454d7-457d-4e3a-b976-5a964fa0767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W200_O50_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W200_O50_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b20b36-ab6d-47cf-9705-caf7fc45956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression on W200_O50_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18825ab7-a321-4507-9e67-f43f95ded3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier on W200_O50_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc478b02-693c-4b68-a550-16f71165f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W200_O50_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fab774-c9f9-44e7-a048-9d3e9aa2ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes on W200_O50_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee63308-045d-4670-ae01-d7ac3c61b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Support Vector Classifier on W200_O50_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d264b7-fd18-4f3d-a922-3076adcd0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. K-Nearest Neighbors on W200_O50_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3f5de-26cf-4d6b-a5a9-8b9178bce9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Classifier on W200_O50_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f60d1c-6d15-4d53-9793-2a8f4e2c8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W200_O50_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803b9a1-4b8a-4853-bf13-ce75cbae3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W200_O50_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc02e2-7568-4c45-a698-273863d68f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W200_O50_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253aba33-f986-42dd-816f-bb040a7767f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W300_O25_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W300_O25_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eedb0e5-4b2f-42fe-a88f-cb49356afeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression on W300_O25_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bc5e8-e239-4dac-b578-a27895eb4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier on W300_O25_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8387f-e633-4f71-b07d-993043e916fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W300_O25_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd42cad-e17e-4cf4-9eae-b35e35300640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes on W300_O25_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782a0f7-58d6-44c1-a3dc-eee7dbaceae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Support Vector Classifier on W300_O25_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109229e-8316-4ab3-8f1b-f06a43b61f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. K-Nearest Neighbors on W300_O25_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd7430-9537-4715-be34-4b39ff9d9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Classifier on W300_O25_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602c946-67c2-4f77-a0b1-93f7b2b0569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W300_O25_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec888f8c-a007-4a19-affa-1ee018407969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W300_O25_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f9c61-e299-4cc5-b725-a5b7b4c3d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W300_O25_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ffc8c-fd94-41f6-80fa-367877c3f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W300_O50_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W300_O50_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b5c58-60cd-4e22-8a2b-4c869a122ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression on W300_O50_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1528e-c120-40f7-ab94-a6ffe82a37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier on W300_O50_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f571e-ad54-4502-b34c-2b433eff26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W300_O50_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57833a5b-06d2-4fb7-9758-2f3827fb2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes on W300_O50_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b6018-1811-477b-9363-f0d89d3cb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Support Vector Classifier on W300_O50_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d0592-921d-4618-b214-4bedae7abb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. K-Nearest Neighbors on W300_O50_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b208f-6786-4b85-a56e-c4721e13b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Classifier on W300_O50_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46743c6-f6aa-4e50-9b22-967b77183baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W300_O50_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27312d-d08d-4461-8223-952859671470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W300_O50_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e972d-abf8-42b0-8807-5756a50333c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W300_O50_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced19f4-f9b0-43f9-bd4a-c27079f0bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W400_O25_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W400_O25_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857e162-77dd-4302-b852-80b1e82998fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression on W400_O25_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc8be8-a9bd-4b22-ace0-80062dbe9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier on W400_O25_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f073799-7f09-4055-9c79-a6d5b4d3dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W400_O25_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af99e4-55c2-405c-b0fc-06ed24e7863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes on W400_O25_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d40c0-768e-41e4-a975-ec55ee3b6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Support Vector Classifier on W400_O25_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfc9b6-37f2-4fa6-b3d4-99fabd92afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. K-Nearest Neighbors on W400_O25_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8130e6-3100-4173-b58a-62697132437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Classifier on W400_O25_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc5ebb-226f-4acb-b2ba-d6c69958bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W400_O25_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cbb333-655d-47f4-aa23-5078b76474ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W400_O25_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebbd24-a1c1-4647-8ada-05dc1c2d0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W400_O25_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a0465-4ef1-478a-b302-abd012706e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W400_O50_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W400_O50_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aee36f-6d7e-4d8c-bdb9-bdbe4fe5fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression on W400_O50_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d76188-f9be-4776-9b19-5cab4b1c8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree Classifier on W400_O50_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1017a1e-2d66-42bc-9b0c-1ebb7c3cc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Classifier on W400_O50_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186016a-f714-43bb-b422-e55f748ddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gaussian Naive Bayes on W400_O50_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d353d-71f9-4ee0-8d9a-d172059ca75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Support Vector Classifier on W400_O50_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec16383-8d9a-4962-9a69-afd08afe8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. K-Nearest Neighbors on W400_O50_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919df13-c00f-42a4-a80c-60ad40f89c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost Classifier on W400_O50_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd4b57-cd16-4e38-a1a4-9a57c2afadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boost on W400_O50_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc7fbd-cb2b-4af2-81ad-eb425f1f3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W400_O50_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81b880-70e2-4ac9-8df3-8e0c72bc6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W400_O50_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff0c9a7c-5105-4d61-afd5-d93c43ab8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W500_O25_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W500_O25_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "229feec1-83a6-40a9-bad1-3b0983b7407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------- #1. Logistic Regression Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score:  0.4216682958618443\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 100, 'C': 10}\n",
      "Best score:  0.4216682958618443\n",
      "\n",
      "Logistic Regression Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.38      0.32       397\n",
      "           1       0.43      0.65      0.51       414\n",
      "           2       0.35      0.34      0.34       447\n",
      "           3       0.28      0.53      0.37       437\n",
      "           4       0.33      0.29      0.31       448\n",
      "           5       0.48      0.49      0.49       388\n",
      "           6       0.42      0.38      0.39       410\n",
      "           7       0.20      0.21      0.20       439\n",
      "           8       0.60      0.70      0.64       324\n",
      "           9       0.89      0.80      0.84       339\n",
      "          10       0.78      0.78      0.78       394\n",
      "          11       0.37      0.20      0.26       422\n",
      "          12       0.34      0.13      0.19       413\n",
      "          13       0.40      0.30      0.34       351\n",
      "          14       0.36      0.17      0.23       325\n",
      "\n",
      "    accuracy                           0.42      5948\n",
      "   macro avg       0.43      0.42      0.42      5948\n",
      "weighted avg       0.42      0.42      0.41      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.20572812 0.1928975  0.22477805]\n",
      "Mean K-fold cross-validation score: 0.20780122032335538\n",
      "\n",
      "Straified cross validation scores: [0.20330779 0.21711057 0.208636  ]\n",
      "Mean Straified cross-validation score: 0.209684785070568\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression on W500_O25_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85e84e82-d29a-42e0-826f-0088fa22c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #2. Decission Tree Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5}\n",
      "Best score:  0.42973281199087654\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'min_samples_split': 5, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "Best score:  0.43041028565222117\n",
      "\n",
      "Decission Tree Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       397\n",
      "           1       0.67      0.71      0.69       414\n",
      "           2       0.46      0.43      0.44       447\n",
      "           3       0.46      0.55      0.50       437\n",
      "           4       0.32      0.31      0.31       448\n",
      "           5       0.37      0.42      0.39       388\n",
      "           6       0.25      0.31      0.28       410\n",
      "           7       0.26      0.30      0.28       439\n",
      "           8       0.57      0.64      0.60       324\n",
      "           9       0.85      0.84      0.84       339\n",
      "          10       0.71      0.63      0.67       394\n",
      "          11       0.31      0.26      0.28       422\n",
      "          12       0.36      0.30      0.33       413\n",
      "          13       0.35      0.31      0.33       351\n",
      "          14       0.29      0.20      0.24       325\n",
      "\n",
      "    accuracy                           0.45      5948\n",
      "   macro avg       0.45      0.45      0.45      5948\n",
      "weighted avg       0.45      0.45      0.45      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.55385236 0.57990315 0.60855529]\n",
      "Mean K-fold cross-validation score: 0.5807702646812184\n",
      "\n",
      "Straified cross validation scores: [0.58289633 0.57546408 0.57465698]\n",
      "Mean Straified cross-validation score: 0.5776724648467628\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Classifier on W500_O25_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "123ad44e-cbc4-421a-83e4-481803479e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #3. Random Forest Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}\n",
      "Best score:  0.5635861301183882\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 50, 'max_depth': 20, 'criterion': 'gini', 'bootstrap': True}\n",
      "Best score:  0.557535027696318\n",
      "\n",
      "Random Forest Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.65       397\n",
      "           1       0.67      0.82      0.73       414\n",
      "           2       0.60      0.64      0.62       447\n",
      "           3       0.57      0.58      0.58       437\n",
      "           4       0.47      0.60      0.53       448\n",
      "           5       0.47      0.69      0.56       388\n",
      "           6       0.40      0.48      0.43       410\n",
      "           7       0.41      0.46      0.44       439\n",
      "           8       0.63      0.84      0.72       324\n",
      "           9       0.95      0.83      0.89       339\n",
      "          10       0.78      0.78      0.78       394\n",
      "          11       0.58      0.29      0.38       422\n",
      "          12       0.54      0.28      0.37       413\n",
      "          13       0.52      0.36      0.43       351\n",
      "          14       0.52      0.27      0.35       325\n",
      "\n",
      "    accuracy                           0.57      5948\n",
      "   macro avg       0.58      0.57      0.56      5948\n",
      "weighted avg       0.58      0.57      0.56      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.69624849 0.70137207 0.69612591]\n",
      "Mean K-fold cross-validation score: 0.6979154898456694\n",
      "\n",
      "Straified cross validation scores: [0.69342477 0.70258273 0.68724778]\n",
      "Mean Straified cross-validation score: 0.6944184255087368\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Classifier on W500_O25_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4e0d7049-e4f6-4de7-881f-dcda060548c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #4. Gaussian Naive Bias Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'var_smoothing': 0.0001}\n",
      "Best score:  0.2837976539589443\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'var_smoothing': 0.0001}\n",
      "Best score:  0.2837976539589443\n",
      "\n",
      "Gaussian Naive Bias Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.13      0.18       397\n",
      "           1       0.29      0.04      0.07       414\n",
      "           2       0.13      0.06      0.08       447\n",
      "           3       0.16      0.89      0.27       437\n",
      "           4       0.32      0.23      0.27       448\n",
      "           5       0.36      0.28      0.32       388\n",
      "           6       0.28      0.31      0.30       410\n",
      "           7       0.17      0.15      0.16       439\n",
      "           8       0.45      0.61      0.52       324\n",
      "           9       0.76      0.72      0.74       339\n",
      "          10       0.60      0.59      0.59       394\n",
      "          11       0.49      0.12      0.20       422\n",
      "          12       0.07      0.00      0.00       413\n",
      "          13       0.27      0.15      0.19       351\n",
      "          14       0.30      0.16      0.21       325\n",
      "\n",
      "    accuracy                           0.29      5948\n",
      "   macro avg       0.33      0.30      0.27      5948\n",
      "weighted avg       0.32      0.29      0.26      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.19967729 0.18644068 0.23365617]\n",
      "Mean K-fold cross-validation score: 0.2065913805099234\n",
      "\n",
      "Straified cross validation scores: [0.17507059 0.21993543 0.21186441]\n",
      "Mean Straified cross-validation score: 0.20229014385351343\n"
     ]
    }
   ],
   "source": [
    "# 4. Gaussian Naive Bayes on W500_O25_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4212fd16-2a41-4496-9dc3-af2052f691ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #5. Support Vector Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score:  0.534646193113935\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score:  0.534646193113935\n",
      "\n",
      "Support Vector Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       397\n",
      "           1       0.79      0.80      0.80       414\n",
      "           2       0.56      0.60      0.58       447\n",
      "           3       0.59      0.62      0.60       437\n",
      "           4       0.58      0.53      0.55       448\n",
      "           5       0.42      0.53      0.47       388\n",
      "           6       0.41      0.49      0.45       410\n",
      "           7       0.44      0.43      0.44       439\n",
      "           8       0.66      0.77      0.71       324\n",
      "           9       0.73      0.87      0.79       339\n",
      "          10       0.76      0.75      0.75       394\n",
      "          11       0.46      0.32      0.38       422\n",
      "          12       0.34      0.26      0.30       413\n",
      "          13       0.50      0.40      0.44       351\n",
      "          14       0.41      0.35      0.38       325\n",
      "\n",
      "    accuracy                           0.56      5948\n",
      "   macro avg       0.56      0.57      0.56      5948\n",
      "weighted avg       0.56      0.56      0.56      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.07503025 0.09241324 0.08999193]\n",
      "Mean K-fold cross-validation score: 0.08581180653024822\n",
      "\n",
      "Straified cross validation scores: [0.08592174 0.09039548 0.09160613]\n",
      "Mean Straified cross-validation score: 0.0893077856143882\n"
     ]
    }
   ],
   "source": [
    "# 5. Support Vector Classifier on W500_O25_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cfcd635-3391-454e-835a-5fdc62ca7031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #6. K-Nearest Neighbors Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score:  0.3873845986749213\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score:  0.3873845986749213\n",
      "\n",
      "K-Nearest Neighbors Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.47      0.44       397\n",
      "           1       0.49      0.77      0.60       414\n",
      "           2       0.39      0.64      0.48       447\n",
      "           3       0.43      0.67      0.52       437\n",
      "           4       0.40      0.25      0.31       448\n",
      "           5       0.39      0.37      0.38       388\n",
      "           6       0.26      0.41      0.32       410\n",
      "           7       0.28      0.29      0.28       439\n",
      "           8       0.34      0.70      0.46       324\n",
      "           9       0.81      0.69      0.74       339\n",
      "          10       0.68      0.48      0.56       394\n",
      "          11       0.67      0.14      0.23       422\n",
      "          12       0.61      0.16      0.25       413\n",
      "          13       0.39      0.21      0.27       351\n",
      "          14       0.41      0.06      0.10       325\n",
      "\n",
      "    accuracy                           0.42      5948\n",
      "   macro avg       0.46      0.42      0.40      5948\n",
      "weighted avg       0.46      0.42      0.40      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.33844292 0.36117837 0.35391445]\n",
      "Mean K-fold cross-validation score: 0.35117857910673494\n",
      "\n",
      "Straified cross validation scores: [0.33844292 0.3724778  0.34543987]\n",
      "Mean Straified cross-validation score: 0.35212019869242234\n"
     ]
    }
   ],
   "source": [
    "# 6. K-Nearest Neighbors on W500_O25_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9165cfe4-46db-4318-b75d-3f4705c11e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #7. Ada-Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.5, 'n_estimators': 50}\n",
      "Best score:  0.24207668078635822\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 50, 'learning_rate': 0.5, 'estimator': DecisionTreeClassifier(max_depth=1)}\n",
      "Best score:  0.24207668078635822\n",
      "\n",
      "Ada-Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       397\n",
      "           1       0.24      0.36      0.29       414\n",
      "           2       0.09      0.01      0.02       447\n",
      "           3       0.18      0.91      0.29       437\n",
      "           4       0.24      0.27      0.25       448\n",
      "           5       0.36      0.52      0.43       388\n",
      "           6       0.22      0.10      0.13       410\n",
      "           7       0.00      0.00      0.00       439\n",
      "           8       0.30      0.40      0.35       324\n",
      "           9       0.35      0.60      0.44       339\n",
      "          10       0.13      0.06      0.08       394\n",
      "          11       0.32      0.29      0.30       422\n",
      "          12       0.24      0.02      0.04       413\n",
      "          13       0.23      0.04      0.07       351\n",
      "          14       0.10      0.03      0.05       325\n",
      "\n",
      "    accuracy                           0.24      5948\n",
      "   macro avg       0.20      0.24      0.18      5948\n",
      "weighted avg       0.20      0.24      0.18      5948\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.23638564 0.24697337 0.24939467]\n",
      "Mean K-fold cross-validation score: 0.2442512260372114\n",
      "\n",
      "Straified cross validation scores: [0.23396531 0.2425343  0.20258273]\n",
      "Mean Straified cross-validation score: 0.22636077948498898\n"
     ]
    }
   ],
   "source": [
    "# 7. AdaBoost Classifier on W500_O25_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798665f-6314-41e8-978f-9072aa150b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #9. Gradient Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n"
     ]
    }
   ],
   "source": [
    "# 8. Gradient Boost on W500_O25_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110aaa3-1c3b-4669-a9ed-ccfba360d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. XGBoost Classifier on W500_O25_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df5a4c-ab6a-4f0d-94f4-d9632bb34c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Artificial Neural Network on W500_O25_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "184a3b44-7859-4f84-9e2b-653f2469c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for W500_O50_Features\n",
    "evaluate_model = ModelTuningAndEvaluation(path + \"W500_O50_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3cd89a4d-6178-4f20-a62a-28ea8b09e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#------------------- #1. Logistic Regression Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'C': 10, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score:  0.437269656864363\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 500, 'C': 10}\n",
      "Best score:  0.437269656864363\n",
      "Logistic Regression Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.43      0.41       591\n",
      "           1       0.43      0.66      0.52       619\n",
      "           2       0.36      0.38      0.37       667\n",
      "           3       0.29      0.56      0.38       651\n",
      "           4       0.39      0.34      0.36       667\n",
      "           5       0.48      0.54      0.51       579\n",
      "           6       0.44      0.45      0.45       610\n",
      "           7       0.27      0.19      0.22       652\n",
      "           8       0.68      0.70      0.69       484\n",
      "           9       0.90      0.84      0.87       502\n",
      "          10       0.81      0.78      0.80       589\n",
      "          11       0.46      0.23      0.31       631\n",
      "          12       0.27      0.19      0.23       619\n",
      "          13       0.41      0.32      0.36       523\n",
      "          14       0.37      0.20      0.26       484\n",
      "\n",
      "    accuracy                           0.45      8868\n",
      "   macro avg       0.46      0.45      0.45      8868\n",
      "weighted avg       0.45      0.45      0.44      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.23985573 0.23264202 0.22272317 0.22723174 0.21750903 0.21299639\n",
      " 0.23104693 0.20126354 0.25631769 0.23555957]\n",
      "Mean K-fold cross-validation score: 0.22771458008483264\n",
      "\n",
      "Straified cross validation scores: [0.24526601 0.19927863 0.23354373 0.22633003 0.2265343  0.22382671\n",
      " 0.24277978 0.21841155 0.22382671 0.23104693]\n",
      "Mean Straified cross-validation score: 0.22708443877301893\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression on W500_O50_Features\n",
    "evaluate_model.logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0194a77-96c8-41bc-aa4f-7bc186a988dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #2. Decission Tree Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}\n",
      "Best score:  0.4787757327280084\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'min_samples_split': 2, 'max_depth': 50, 'criterion': 'entropy'}\n",
      "Best score:  0.4851119643357011\n",
      "\n",
      "Decission Tree Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65       591\n",
      "           1       0.73      0.69      0.71       619\n",
      "           2       0.55      0.55      0.55       667\n",
      "           3       0.51      0.54      0.52       651\n",
      "           4       0.42      0.39      0.40       667\n",
      "           5       0.45      0.46      0.45       579\n",
      "           6       0.38      0.38      0.38       610\n",
      "           7       0.38      0.43      0.40       652\n",
      "           8       0.66      0.68      0.67       484\n",
      "           9       0.88      0.85      0.87       502\n",
      "          10       0.68      0.69      0.68       589\n",
      "          11       0.34      0.33      0.33       631\n",
      "          12       0.37      0.34      0.35       619\n",
      "          13       0.36      0.36      0.36       523\n",
      "          14       0.33      0.36      0.35       484\n",
      "\n",
      "    accuracy                           0.51      8868\n",
      "   macro avg       0.51      0.51      0.51      8868\n",
      "weighted avg       0.51      0.51      0.51      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.61380244 0.62598106 0.62587981]\n",
      "Mean K-fold cross-validation score: 0.6218877654312215\n",
      "\n",
      "Straified cross validation scores: [0.61001353 0.62381597 0.63616676]\n",
      "Mean Straified cross-validation score: 0.623332085408832\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Classifier on W500_O50_Features\n",
    "evaluate_model.decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c8944fd-39f8-42c0-be1a-51a9fe641615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #3. Random Forest Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100}\n",
      "Best score:  0.598825532684736\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 100, 'max_depth': 20, 'criterion': 'gini', 'bootstrap': True}\n",
      "Best score:  0.6096540284302256\n",
      "\n",
      "Random Forest Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       591\n",
      "           1       0.83      0.84      0.83       619\n",
      "           2       0.59      0.76      0.67       667\n",
      "           3       0.66      0.69      0.67       651\n",
      "           4       0.58      0.60      0.59       667\n",
      "           5       0.54      0.73      0.62       579\n",
      "           6       0.49      0.55      0.52       610\n",
      "           7       0.49      0.54      0.52       652\n",
      "           8       0.76      0.84      0.80       484\n",
      "           9       0.92      0.93      0.93       502\n",
      "          10       0.79      0.86      0.82       589\n",
      "          11       0.58      0.41      0.48       631\n",
      "          12       0.60      0.36      0.45       619\n",
      "          13       0.62      0.49      0.55       523\n",
      "          14       0.64      0.39      0.48       484\n",
      "\n",
      "    accuracy                           0.65      8868\n",
      "   macro avg       0.66      0.65      0.65      8868\n",
      "weighted avg       0.65      0.65      0.64      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.74154263 0.74046008 0.74363833]\n",
      "Mean K-fold cross-validation score: 0.7418803462636383\n",
      "\n",
      "Straified cross validation scores: [0.74127199 0.75074425 0.7485111 ]\n",
      "Mean Straified cross-validation score: 0.7468424457464212\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Classifier on W500_O50_Features\n",
    "evaluate_model.random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "804b28d1-9d16-41db-b90a-0ab96401f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #4. Gaussian Naive Bias Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'var_smoothing': 0.0001}\n",
      "Best score:  0.2847441487495615\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'var_smoothing': 0.0001}\n",
      "Best score:  0.2847441487495615\n",
      "\n",
      "Gaussian Naive Bias Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.86      0.25       591\n",
      "           1       0.31      0.06      0.10       619\n",
      "           2       0.21      0.16      0.18       667\n",
      "           3       0.19      0.03      0.05       651\n",
      "           4       0.29      0.22      0.25       667\n",
      "           5       0.45      0.28      0.35       579\n",
      "           6       0.32      0.41      0.36       610\n",
      "           7       0.14      0.10      0.12       652\n",
      "           8       0.52      0.60      0.55       484\n",
      "           9       0.71      0.73      0.72       502\n",
      "          10       0.57      0.66      0.61       589\n",
      "          11       0.45      0.12      0.19       631\n",
      "          12       0.37      0.05      0.09       619\n",
      "          13       0.29      0.14      0.19       523\n",
      "          14       0.27      0.12      0.17       484\n",
      "\n",
      "    accuracy                           0.29      8868\n",
      "   macro avg       0.35      0.30      0.28      8868\n",
      "weighted avg       0.34      0.29      0.27      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.22083897 0.19756428 0.19030861]\n",
      "Mean K-fold cross-validation score: 0.20290395206211587\n",
      "\n",
      "Straified cross validation scores: [0.20568336 0.1962111  0.184353  ]\n",
      "Mean Straified cross-validation score: 0.19541581894495919\n"
     ]
    }
   ],
   "source": [
    "# 4. Gaussian Naive Bayes on W500_O50_Features\n",
    "evaluate_model.gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "372efca4-61a3-4fd3-b147-ddf976581ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #5. Support Vector Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score:  0.5762572533258035\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score:  0.5762572533258035\n",
      "\n",
      "Support Vector Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       591\n",
      "           1       0.83      0.84      0.83       619\n",
      "           2       0.62      0.76      0.69       667\n",
      "           3       0.63      0.65      0.64       651\n",
      "           4       0.61      0.65      0.63       667\n",
      "           5       0.51      0.59      0.54       579\n",
      "           6       0.52      0.47      0.50       610\n",
      "           7       0.54      0.49      0.51       652\n",
      "           8       0.76      0.83      0.79       484\n",
      "           9       0.87      0.90      0.89       502\n",
      "          10       0.71      0.88      0.78       589\n",
      "          11       0.45      0.32      0.37       631\n",
      "          12       0.44      0.40      0.42       619\n",
      "          13       0.54      0.51      0.52       523\n",
      "          14       0.52      0.37      0.43       484\n",
      "\n",
      "    accuracy                           0.63      8868\n",
      "   macro avg       0.62      0.63      0.62      8868\n",
      "weighted avg       0.62      0.63      0.62      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.08903924 0.09418133 0.09664321]\n",
      "Mean K-fold cross-validation score: 0.0932879245110688\n",
      "\n",
      "Straified cross validation scores: [0.09364005 0.09607578 0.09799675]\n",
      "Mean Straified cross-validation score: 0.09590419456486143\n"
     ]
    }
   ],
   "source": [
    "# 5. Support Vector Classifier on W500_O50_Features\n",
    "evaluate_model.support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7aee2f0b-9d07-4739-8719-18cc4b1e941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #6. K-Nearest Neighbors Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score:  0.4300478074695045\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score:  0.4300478074695045\n",
      "\n",
      "K-Nearest Neighbors Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.63       591\n",
      "           1       0.58      0.72      0.65       619\n",
      "           2       0.43      0.67      0.52       667\n",
      "           3       0.43      0.73      0.54       651\n",
      "           4       0.52      0.32      0.40       667\n",
      "           5       0.42      0.43      0.42       579\n",
      "           6       0.28      0.40      0.33       610\n",
      "           7       0.34      0.39      0.36       652\n",
      "           8       0.43      0.76      0.55       484\n",
      "           9       0.77      0.68      0.72       502\n",
      "          10       0.70      0.63      0.66       589\n",
      "          11       0.63      0.19      0.29       631\n",
      "          12       0.60      0.21      0.31       619\n",
      "          13       0.48      0.27      0.35       523\n",
      "          14       0.47      0.10      0.16       484\n",
      "\n",
      "    accuracy                           0.48      8868\n",
      "   macro avg       0.51      0.48      0.46      8868\n",
      "weighted avg       0.51      0.48      0.46      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.36589986 0.35967524 0.3946941 ]\n",
      "Mean K-fold cross-validation score: 0.37342306667555597\n",
      "\n",
      "Straified cross validation scores: [0.37618403 0.38322057 0.37520303]\n",
      "Mean Straified cross-validation score: 0.37820254425186683\n"
     ]
    }
   ],
   "source": [
    "# 6. K-Nearest Neighbors on W500_O50_Features\n",
    "evaluate_model.knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bfd6b7c7-2890-4132-9900-d1c83c1f00fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #7. Ada-Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.5, 'n_estimators': 50}\n",
      "Best score:  0.2125354338793726\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'n_estimators': 50, 'learning_rate': 0.5, 'estimator': DecisionTreeClassifier(max_depth=1)}\n",
      "Best score:  0.2125354338793726\n",
      "\n",
      "Ada-Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.38      0.38       591\n",
      "           1       0.00      0.00      0.00       619\n",
      "           2       0.16      0.31      0.21       667\n",
      "           3       0.17      0.29      0.22       651\n",
      "           4       0.20      0.31      0.25       667\n",
      "           5       0.34      0.58      0.43       579\n",
      "           6       0.14      0.10      0.12       610\n",
      "           7       0.13      0.09      0.11       652\n",
      "           8       0.27      0.08      0.12       484\n",
      "           9       0.29      0.58      0.39       502\n",
      "          10       0.08      0.03      0.04       589\n",
      "          11       0.08      0.14      0.10       631\n",
      "          12       0.40      0.22      0.29       619\n",
      "          13       0.19      0.03      0.06       523\n",
      "          14       0.38      0.05      0.09       484\n",
      "\n",
      "    accuracy                           0.21      8868\n",
      "   macro avg       0.21      0.21      0.19      8868\n",
      "weighted avg       0.21      0.21      0.19      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.26008119 0.28470907 0.26827287]\n",
      "Mean K-fold cross-validation score: 0.2710210440121725\n",
      "\n",
      "Straified cross validation scores: [0.2232747  0.26603518 0.25933947]\n",
      "Mean Straified cross-validation score: 0.24954978254121873\n"
     ]
    }
   ],
   "source": [
    "# 7. AdaBoost Classifier on W500_O50_Features\n",
    "evaluate_model.ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "020fac99-7d9f-4330-8176-05159a71e0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------- #9. Gradient Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score:  0.5879945921696476\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'random_state': 42, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "Best score:  0.5879945921696476\n",
      "Gradient Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.72       591\n",
      "           1       0.80      0.84      0.82       619\n",
      "           2       0.66      0.71      0.69       667\n",
      "           3       0.62      0.64      0.63       651\n",
      "           4       0.62      0.64      0.63       667\n",
      "           5       0.57      0.74      0.65       579\n",
      "           6       0.45      0.51      0.48       610\n",
      "           7       0.49      0.53      0.51       652\n",
      "           8       0.81      0.82      0.81       484\n",
      "           9       0.88      0.87      0.88       502\n",
      "          10       0.82      0.81      0.82       589\n",
      "          11       0.49      0.40      0.44       631\n",
      "          12       0.48      0.37      0.42       619\n",
      "          13       0.53      0.51      0.52       523\n",
      "          14       0.49      0.40      0.44       484\n",
      "\n",
      "    accuracy                           0.63      8868\n",
      "   macro avg       0.63      0.63      0.63      8868\n",
      "weighted avg       0.63      0.63      0.63      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.69882777 0.7141569  0.7276826  0.7213706  0.71750903 0.71480144\n",
      " 0.70848375 0.72202166 0.72472924 0.72021661]\n",
      "Mean K-fold cross-validation score: 0.7169799604808702\n",
      "\n",
      "Straified cross validation scores: [0.71686204 0.71866546 0.70333634 0.72407574 0.72833935 0.71119134\n",
      " 0.72021661 0.70487365 0.72743682 0.68953069]\n",
      "Mean Straified cross-validation score: 0.7144528032865332\n"
     ]
    }
   ],
   "source": [
    "# 8. Gradient Boost on W500_O50_Features\n",
    "evaluate_model.gradient_boost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ab2fa67-bd21-4539-b444-3142f5a6e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- #8. XG Boost Classifier Model --------------------#\n",
      "#---------- Grid Search ------------#\n",
      "Best parameters:  {'gamma': 0, 'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best score:  0.628156655946352\n",
      "\n",
      "#---------- Random Search -----------#\n",
      "Best parameters:  {'subsample': 0.8, 'n_estimators': 100, 'learning_rate': 0.1, 'gamma': 0}\n",
      "Best score:  0.628156655946352\n",
      "XG Boost Classifier Metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78       591\n",
      "           1       0.85      0.89      0.87       619\n",
      "           2       0.67      0.77      0.72       667\n",
      "           3       0.69      0.69      0.69       651\n",
      "           4       0.63      0.66      0.65       667\n",
      "           5       0.64      0.77      0.70       579\n",
      "           6       0.50      0.57      0.53       610\n",
      "           7       0.53      0.54      0.54       652\n",
      "           8       0.80      0.86      0.83       484\n",
      "           9       0.92      0.93      0.92       502\n",
      "          10       0.83      0.86      0.85       589\n",
      "          11       0.57      0.47      0.52       631\n",
      "          12       0.57      0.42      0.48       619\n",
      "          13       0.59      0.55      0.57       523\n",
      "          14       0.56      0.46      0.51       484\n",
      "\n",
      "    accuracy                           0.68      8868\n",
      "   macro avg       0.68      0.68      0.68      8868\n",
      "weighted avg       0.67      0.68      0.67      8868\n",
      "\n",
      "\n",
      "K-fold cross-validation scores: [0.75022543 0.76735798 0.7754734  0.78449053 0.77707581 0.77075812\n",
      " 0.76353791 0.78700361 0.79061372 0.76083032]\n",
      "Mean K-fold cross-validation score: 0.7727366834530734\n",
      "\n",
      "Straified cross validation scores: [0.75563571 0.77006312 0.77727683 0.77457169 0.78971119 0.76444043\n",
      " 0.75812274 0.76444043 0.79693141 0.76805054]\n",
      "Mean Straified cross-validation score: 0.7719244090848425\n"
     ]
    }
   ],
   "source": [
    "# 9. XGBoost Classifier on W500_O50_Features\n",
    "evaluate_model.xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e2825b5-a6f8-4bb5-b0d9-577366c133e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------- #10. Artificial Neural Net Model ------------------------#\n",
      "(11348, 15)\n",
      "#---------- Grid Search ------------#\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_240\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_245\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_250\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_255\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_260\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_265\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_270\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_275\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_280\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_285\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_290\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_295\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_300\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_305\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_310\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_315\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_320\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_325\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_330\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_335\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_340\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_345\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_350\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_355\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 10. Artificial Neural Network on W500_O50_Features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mann_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 324\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.ann_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monehot_encode()\n\u001b[0;32m    322\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_ann, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m--> 324\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyper_parameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid_ann\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m ann \u001b[38;5;241m=\u001b[39m tuned_model\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    327\u001b[0m ann\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n",
      "Cell \u001b[1;32mIn[78], line 157\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.hyper_parameter_tuning\u001b[1;34m(self, model, param_grid)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhyper_parameter_tuning\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, param_grid):\n\u001b[1;32m--> 157\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgridSerach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     random_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandomSearch(model, param_grid)\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grid_search \u001b[38;5;28;01mif\u001b[39;00m grid_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m>\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;28;01melse\u001b[39;00m random_search\n",
      "Cell \u001b[1;32mIn[78], line 140\u001b[0m, in \u001b[0;36mModelTuningAndEvaluation.gridSerach\u001b[1;34m(self, estimator, param_grid)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#---------- Grid Search ------------#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mestimator, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 140\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    994\u001b[0m     )\n\u001b[1;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_240\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_245\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_250\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_255\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_260\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_265\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_270\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_275\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_280\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_285\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_290\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_295\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_300\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_305\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_310\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_315\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_320\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_325\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_330\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_335\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_340\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_345\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_350\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 770, in fit\n    self._fit(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\scikeras\\wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\nahid\\miniconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_355\" is incompatible with the layer: expected axis -1 of input shape to have value 24, but received input with shape (None, 25)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 25), dtype=float32)\n  • training=True\n  • mask=None\n"
     ]
    }
   ],
   "source": [
    "# 10. Artificial Neural Network on W500_O50_Features\n",
    "evaluate_model.ann_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da724a54-6468-42b7-9344-4bfec81bf4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
