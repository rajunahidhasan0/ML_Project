{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dad4a5c-e7ef-4eee-9b58-cd6c35c8146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix  \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "018ce2fc-3fb7-41a4-b061-980538186449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"data/Processed_Features/W100_O50_Features.csv\"  # Adjust your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assume the last column is the target\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c075da4-f465-4891-982c-08beb778556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary Calculation\n",
    "X = X.head(100)\n",
    "y = y.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eecfcad3-81f3-4301-9892-b15dee54bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_holdout_test_set(data, test_size=0.25):\n",
    "    \"\"\"Separates a holdout test set randomly.\"\"\"\n",
    "    X = data.iloc[:, :-1].values  # Features\n",
    "    y = data.iloc[:, -1].values   # Target\n",
    "    X_train_valid, X_holdout, y_train_valid, y_holdout = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    return X_train_valid, X_holdout, y_train_valid, y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a37d12da-603a-4f38-be8d-fb3b1e7efcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train-validation and holdout test set\n",
    "X_train_valid, X_holdout, y_train_valid, y_holdout = create_holdout_test_set(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0316eaa-a214-4f87-b83d-0efa3d7a82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Scaling\n",
    "def preprocess_and_scale(X_train, X_test):\n",
    "    \"\"\"Scales the data using StandardScaler.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7720ec12-edf8-41a7-a0c0-62ae45cc4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate model using accuracy, classification report, and confusion matrix.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "441e5c03-c877-4725-a0c6-dffa1809fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Holdout Test Set\n",
    "def evaluate_on_holdout(model, X_holdout, y_holdout):\n",
    "    \"\"\"Evaluate model on the holdout set.\"\"\"\n",
    "    accuracy, report, cm = evaluate_model(model, X_holdout, y_holdout)\n",
    "    print(\"Holdout Test Set Results\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81fcb441-321c-43e4-8cf2-c06d5a08cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with Grid Search and K-Fold Cross-Validation\n",
    "def logistic_regression_grid_search(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Runs Logistic Regression with Grid Search and K-Fold Cross-Validation.\"\"\"\n",
    "    param_grid = {'C': [0.1, 1], 'penalty': ['l2'], 'solver': ['lbfgs', 'saga']}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"Logistic Regression with Grid Search (K-Fold)\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "923b0e99-5799-4a22-b613-6cb0f3e8c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_grid_search(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Grid Search for Decision Tree.\"\"\"\n",
    "    param_grid = {'max_depth': [3, None], 'min_samples_split': [2, 5]}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"Decision Tree Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c79cd367-1d30-48cd-af23-8c4f956bd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'n_estimators': [50], 'max_depth': [5,None], 'min_samples_split': [2]}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = RandomForestClassifier()\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"Random Forest Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38157882-ca86-4540-8975-e862d249c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy, report, cm = evaluate_model(model, X_test, y_test)\n",
    "    print(\"Gaussian Na√Øve Bayes Results\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f22c7a0-27d2-495f-ac91-0bf1dedd7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'C': [0.1, 1], 'kernel': ['linear', 'rbf']}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = SVC(probability=True)\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"SVM Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a36402d-5414-4315-a743-c69d5c8f9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'n_neighbors': [3, 5], 'weights': ['uniform', 'distance']}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = KNeighborsClassifier()\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"KNN Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96060cb0-aab4-4903-94ae-1ebc6b63c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'n_estimators': [50], 'learning_rate': [0.01]}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = AdaBoostClassifier()\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"AdaBoost Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07684636-5cb2-4ada-bfd4-964be121f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boost_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'learning_rate': [0.1, 0.2], 'n_estimators': [50], 'max_depth': [3]}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = GradientBoostingClassifier()\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"Gradient Boost Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6362b1b3-67f0-49b8-86f5-cb357a15430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'learning_rate': [0.01], 'n_estimators': [50], 'max_depth': [3]}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"XGBoost Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57f61e9c-093a-4c27-ad49-6e2c401bb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_grid_search(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'activation': ['relu', 'tanh'], 'learning_rate': ['constant', 'adaptive']}\n",
    "    kfold = KFold(n_splits=5)\n",
    "    model = MLPClassifier(max_iter=500)\n",
    "    grid = GridSearchCV(model, param_grid, cv=kfold, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    accuracy, report, cm = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"Artificial Neural Networks (ANN) Results\")\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Classification Report:\\n\", report)\n",
    "    # print(\"Confusion Matrix:\\n\", cm)\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4816793-9340-48bd-b529-8a22f21c60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=42)\n",
    "X_train_scaled, X_test_scaled = preprocess_and_scale(X_train, X_test)\n",
    "X_holdout_scaled = StandardScaler().fit_transform(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b663fe-38cc-48e8-89fa-32c976db0c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Logistic Regression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Grid Search (K-Fold)\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy: 0.479413817166783\n",
      "\n",
      "--- Evaluating Logistic Regression on Holdout Test Set ---\n",
      "Holdout Test Set Results\n",
      "Accuracy: 0.4704445530043967\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.62      0.35      0.45        74\n",
      "         134       0.78      0.93      0.85        71\n",
      "         135       0.59      0.93      0.72        75\n",
      "         136       0.62      0.91      0.74        78\n",
      "         137       0.51      0.48      0.50        75\n",
      "         138       0.50      0.24      0.33        83\n",
      "         139       0.32      0.34      0.33        61\n",
      "         140       0.50      0.88      0.64        77\n",
      "         141       0.82      0.86      0.84        59\n",
      "         142       0.97      0.97      0.97        69\n",
      "         143       0.53      0.57      0.55        54\n",
      "         144       0.50      0.03      0.05        71\n",
      "         145       0.00      0.00      0.00        78\n",
      "         146       0.33      0.33      0.33        69\n",
      "         147       0.35      0.23      0.28        77\n",
      "         148       0.50      0.62      0.55        60\n",
      "         149       0.56      0.96      0.71        57\n",
      "         150       0.49      0.46      0.48        65\n",
      "         151       0.95      0.99      0.97        75\n",
      "         152       0.96      0.96      0.96        83\n",
      "         153       0.57      0.49      0.52        68\n",
      "         154       0.37      0.31      0.34        74\n",
      "         155       0.45      0.92      0.60        60\n",
      "         156       0.94      0.92      0.93        90\n",
      "         157       0.96      0.97      0.97        73\n",
      "         158       0.85      0.97      0.91        64\n",
      "         159       0.40      0.08      0.14        71\n",
      "         160       0.24      0.06      0.10        65\n",
      "         161       0.30      0.41      0.35        59\n",
      "         162       0.39      0.33      0.36        75\n",
      "         163       0.49      0.88      0.63        74\n",
      "         164       0.84      0.86      0.85        92\n",
      "         165       0.41      0.91      0.56        78\n",
      "         166       0.48      0.75      0.58        76\n",
      "         167       0.55      0.28      0.37        79\n",
      "         168       0.41      0.40      0.41        78\n",
      "         169       0.23      0.14      0.17        63\n",
      "         170       0.49      0.98      0.65        61\n",
      "         174       0.21      0.05      0.08        57\n",
      "         175       0.32      0.16      0.22        74\n",
      "         176       0.20      0.13      0.16        68\n",
      "         177       0.05      0.04      0.04        57\n",
      "         178       0.50      0.78      0.61        79\n",
      "         179       0.52      0.79      0.63        68\n",
      "         180       0.44      0.71      0.55        73\n",
      "         181       0.44      0.31      0.36        78\n",
      "         182       0.28      0.58      0.38        69\n",
      "         183       0.00      0.00      0.00        73\n",
      "         184       0.04      0.03      0.03        72\n",
      "         185       0.10      0.18      0.13        57\n",
      "         186       0.67      0.82      0.74        68\n",
      "         187       0.90      0.72      0.80        74\n",
      "         188       0.47      0.48      0.48        66\n",
      "         189       0.00      0.00      0.00        70\n",
      "         190       0.00      0.00      0.00        74\n",
      "         191       0.00      0.00      0.00        70\n",
      "         192       0.00      0.00      0.00        64\n",
      "         193       0.71      0.86      0.78        81\n",
      "         194       0.63      0.94      0.75        62\n",
      "         195       0.64      0.90      0.75        78\n",
      "         196       0.27      0.86      0.41        72\n",
      "         197       0.34      0.31      0.33        70\n",
      "         198       0.52      0.48      0.50        71\n",
      "         199       0.42      0.26      0.32        81\n",
      "         200       0.56      0.25      0.34        73\n",
      "         201       0.88      0.89      0.89        66\n",
      "         202       0.97      1.00      0.99        70\n",
      "         203       0.91      0.91      0.91        68\n",
      "         204       0.44      0.19      0.26        81\n",
      "         205       0.33      0.45      0.38        71\n",
      "         206       0.54      0.77      0.63        83\n",
      "         207       0.37      0.27      0.31        66\n",
      "         208       0.46      0.52      0.49        62\n",
      "         209       0.32      0.83      0.46        66\n",
      "         210       0.30      0.77      0.43        69\n",
      "         211       0.35      0.67      0.46        67\n",
      "         212       0.40      0.60      0.48        70\n",
      "         213       0.33      0.57      0.42        77\n",
      "         214       0.00      0.00      0.00        76\n",
      "         215       0.15      0.07      0.09        75\n",
      "         216       0.61      0.68      0.64        68\n",
      "         217       0.71      0.80      0.75        66\n",
      "         218       0.26      0.16      0.20        73\n",
      "         219       0.25      0.03      0.05        77\n",
      "         220       0.80      0.06      0.11        66\n",
      "         221       0.18      0.08      0.11        79\n",
      "         222       0.12      0.03      0.05        70\n",
      "         223       0.70      0.88      0.78        76\n",
      "         224       0.92      0.97      0.95        74\n",
      "         225       0.37      0.39      0.38        72\n",
      "         226       0.37      0.78      0.50        65\n",
      "         227       0.64      0.74      0.69        74\n",
      "         228       0.39      0.43      0.41        58\n",
      "         229       0.43      0.32      0.37        72\n",
      "         230       0.40      0.14      0.21        71\n",
      "         231       0.61      0.82      0.70        62\n",
      "         232       0.92      0.91      0.92        66\n",
      "         233       0.64      0.70      0.67        63\n",
      "         234       0.58      0.38      0.46        74\n",
      "         235       0.25      0.10      0.14        63\n",
      "         236       0.51      0.58      0.54        78\n",
      "         237       0.59      0.59      0.59        70\n",
      "         238       0.70      0.68      0.69        80\n",
      "         239       0.72      0.65      0.68        74\n",
      "         240       0.12      0.06      0.07        54\n",
      "         241       0.17      0.14      0.16        76\n",
      "         242       0.47      0.66      0.55        56\n",
      "         243       0.21      0.15      0.18        67\n",
      "         244       0.54      0.33      0.41        80\n",
      "         245       0.18      0.32      0.23        71\n",
      "         246       0.29      0.24      0.26        66\n",
      "         247       0.86      0.76      0.80        86\n",
      "         248       0.57      0.52      0.54        71\n",
      "         249       0.18      0.03      0.06        59\n",
      "         250       0.12      0.01      0.02        78\n",
      "         251       0.32      0.27      0.29        73\n",
      "         252       0.28      0.09      0.13        81\n",
      "         253       0.24      0.31      0.27        70\n",
      "         254       0.58      0.45      0.50        76\n",
      "         255       0.13      0.15      0.14        74\n",
      "         256       0.11      0.65      0.19        52\n",
      "         257       0.62      0.78      0.69        74\n",
      "         258       0.32      0.12      0.17        77\n",
      "         259       0.23      0.13      0.17        77\n",
      "         260       0.26      0.13      0.18        67\n",
      "         261       0.42      0.52      0.47        66\n",
      "         262       0.80      0.88      0.84        84\n",
      "         263       0.34      0.30      0.32        74\n",
      "         264       0.36      0.07      0.11        76\n",
      "         265       0.12      0.02      0.03        66\n",
      "         266       0.26      0.27      0.27        77\n",
      "         267       0.20      0.21      0.20        72\n",
      "         268       0.11      0.12      0.11        34\n",
      "         269       0.79      0.88      0.83        73\n",
      "         270       0.45      0.56      0.50        80\n",
      "         271       0.30      0.84      0.44        63\n",
      "         272       0.41      0.45      0.43        84\n",
      "         273       0.08      0.06      0.07        16\n",
      "         275       0.33      0.32      0.33        65\n",
      "         276       0.46      0.73      0.56        74\n",
      "         277       0.90      0.87      0.89        71\n",
      "         278       0.51      0.78      0.61        60\n",
      "         279       0.00      0.00      0.00        83\n",
      "         280       0.22      0.05      0.08        82\n",
      "         281       0.00      0.00      0.00        70\n",
      "         282       0.46      0.33      0.38        79\n",
      "         283       0.62      0.69      0.65        70\n",
      "         284       0.42      0.57      0.48        74\n",
      "         285       0.24      0.52      0.33        69\n",
      "         286       0.13      0.20      0.16        61\n",
      "         287       0.38      0.29      0.33        68\n",
      "         288       0.33      0.32      0.33        71\n",
      "         289       0.11      0.01      0.02        73\n",
      "         290       0.16      0.07      0.10        70\n",
      "         291       0.54      0.59      0.56        76\n",
      "         292       0.86      0.90      0.88        69\n",
      "         293       0.50      0.49      0.50        63\n",
      "         294       0.00      0.00      0.00        64\n",
      "         295       0.00      0.00      0.00        72\n",
      "         296       0.17      0.01      0.02        81\n",
      "         297       0.30      0.04      0.07        72\n",
      "         298       0.25      0.58      0.35        73\n",
      "         299       0.50      0.95      0.65        57\n",
      "         300       0.68      0.95      0.79        65\n",
      "         301       0.58      0.91      0.71        70\n",
      "         302       0.35      0.29      0.32        75\n",
      "         303       0.40      0.51      0.45        59\n",
      "         304       0.27      0.23      0.25        66\n",
      "         305       0.46      0.46      0.46        71\n",
      "         306       0.75      0.77      0.76        64\n",
      "         307       0.84      0.87      0.86        62\n",
      "         308       0.22      0.03      0.05        73\n",
      "         309       0.00      0.00      0.00        59\n",
      "         312       0.40      0.95      0.56        56\n",
      "         313       0.78      0.97      0.87        70\n",
      "         314       0.35      0.74      0.48        58\n",
      "         315       0.38      0.71      0.50        68\n",
      "         316       0.47      0.23      0.31        65\n",
      "         317       0.26      0.27      0.27        70\n",
      "         318       0.00      0.00      0.00        71\n",
      "         319       0.27      0.47      0.34        58\n",
      "         320       0.60      0.75      0.66        67\n",
      "         321       0.62      0.38      0.47        21\n",
      "         322       0.12      0.03      0.05        58\n",
      "         323       0.14      0.04      0.07        70\n",
      "         324       0.44      0.33      0.38        73\n",
      "         328       0.60      0.69      0.65        59\n",
      "         329       0.41      0.88      0.56        69\n",
      "         330       0.29      0.40      0.34        82\n",
      "         332       0.28      0.44      0.34        70\n",
      "         333       0.52      0.88      0.65        64\n",
      "         335       0.81      0.81      0.81        69\n",
      "         336       0.15      0.03      0.04        80\n",
      "         337       0.19      0.07      0.10        59\n",
      "         340       0.98      0.76      0.85        66\n",
      "         341       0.73      1.00      0.85        58\n",
      "         342       0.61      0.82      0.70        62\n",
      "         343       0.70      0.80      0.75        83\n",
      "         344       0.61      0.82      0.70        51\n",
      "         345       0.57      0.68      0.62        63\n",
      "         346       0.54      0.40      0.46        84\n",
      "         347       0.39      0.52      0.44        61\n",
      "         348       0.87      0.82      0.84        71\n",
      "         349       0.52      0.75      0.62        65\n",
      "         350       0.14      0.01      0.02        87\n",
      "         351       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.47     14329\n",
      "   macro avg       0.43      0.47      0.43     14329\n",
      "weighted avg       0.43      0.47      0.43     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26  1  4 ...  0  0  0]\n",
      " [ 0 66  1 ...  0  0  0]\n",
      " [ 0  0 70 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 49  0  1]\n",
      " [ 0  0  0 ...  2  1  2]\n",
      " [ 0  0  0 ...  4  0  0]]\n",
      "\n",
      "--- Running Decision Tree ---\n",
      "Decision Tree Results\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Accuracy: 0.576296813212375\n",
      "\n",
      "--- Evaluating Decision Tree on Holdout Test Set ---\n",
      "Holdout Test Set Results\n",
      "Accuracy: 0.46653639472398634\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.47      0.78      0.59        74\n",
      "         134       0.90      0.49      0.64        71\n",
      "         135       0.75      0.48      0.59        75\n",
      "         136       0.61      0.49      0.54        78\n",
      "         137       0.39      0.63      0.48        75\n",
      "         138       0.20      0.27      0.23        83\n",
      "         139       0.14      0.28      0.19        61\n",
      "         140       0.54      0.60      0.57        77\n",
      "         141       0.90      0.88      0.89        59\n",
      "         142       0.99      0.97      0.98        69\n",
      "         143       0.60      0.70      0.65        54\n",
      "         144       0.43      0.37      0.40        71\n",
      "         145       0.40      0.13      0.19        78\n",
      "         146       0.22      0.10      0.14        69\n",
      "         147       0.41      0.27      0.33        77\n",
      "         148       0.57      0.40      0.47        60\n",
      "         149       1.00      0.98      0.99        57\n",
      "         150       0.74      0.35      0.48        65\n",
      "         151       0.96      1.00      0.98        75\n",
      "         152       1.00      0.90      0.95        83\n",
      "         153       0.39      0.32      0.35        68\n",
      "         154       0.28      0.20      0.24        74\n",
      "         155       0.44      0.13      0.21        60\n",
      "         156       0.92      0.88      0.90        90\n",
      "         157       0.93      0.95      0.94        73\n",
      "         158       0.80      0.88      0.84        64\n",
      "         159       0.37      0.28      0.32        71\n",
      "         160       0.25      0.26      0.26        65\n",
      "         161       0.41      0.19      0.26        59\n",
      "         162       0.51      0.28      0.36        75\n",
      "         163       0.55      0.78      0.65        74\n",
      "         164       0.83      0.57      0.67        92\n",
      "         165       0.47      0.67      0.55        78\n",
      "         166       0.80      0.64      0.72        76\n",
      "         167       0.39      0.35      0.37        79\n",
      "         168       0.35      0.31      0.33        78\n",
      "         169       0.34      0.40      0.36        63\n",
      "         170       0.57      0.85      0.68        61\n",
      "         174       0.15      0.14      0.14        57\n",
      "         175       0.44      0.36      0.40        74\n",
      "         176       0.81      0.65      0.72        68\n",
      "         177       0.56      0.51      0.53        57\n",
      "         178       0.72      0.65      0.68        79\n",
      "         179       0.78      0.69      0.73        68\n",
      "         180       0.61      0.26      0.37        73\n",
      "         181       0.68      0.62      0.64        78\n",
      "         182       0.60      0.45      0.51        69\n",
      "         183       0.04      0.03      0.03        73\n",
      "         184       0.21      0.22      0.22        72\n",
      "         185       0.18      0.30      0.23        57\n",
      "         186       0.60      0.68      0.63        68\n",
      "         187       0.66      0.69      0.68        74\n",
      "         188       0.32      0.48      0.39        66\n",
      "         189       0.39      0.40      0.40        70\n",
      "         190       0.18      0.19      0.18        74\n",
      "         191       0.18      0.19      0.18        70\n",
      "         192       0.09      0.09      0.09        64\n",
      "         193       0.94      0.94      0.94        81\n",
      "         194       0.89      0.13      0.23        62\n",
      "         195       0.90      0.72      0.80        78\n",
      "         196       0.49      0.88      0.63        72\n",
      "         197       0.25      0.43      0.32        70\n",
      "         198       0.64      0.63      0.64        71\n",
      "         199       0.31      0.33      0.32        81\n",
      "         200       0.41      0.23      0.30        73\n",
      "         201       0.86      0.91      0.88        66\n",
      "         202       1.00      0.99      0.99        70\n",
      "         203       0.93      0.74      0.82        68\n",
      "         204       0.56      0.48      0.52        81\n",
      "         205       0.67      0.45      0.54        71\n",
      "         206       0.76      0.58      0.66        83\n",
      "         207       0.51      0.61      0.56        66\n",
      "         208       0.39      0.21      0.27        62\n",
      "         209       0.39      0.32      0.35        66\n",
      "         210       0.58      0.62      0.60        69\n",
      "         211       0.50      0.51      0.50        67\n",
      "         212       0.30      0.34      0.32        70\n",
      "         213       0.28      0.27      0.27        77\n",
      "         214       0.13      0.14      0.13        76\n",
      "         215       0.35      0.24      0.28        75\n",
      "         216       0.51      0.59      0.54        68\n",
      "         217       0.66      0.67      0.66        66\n",
      "         218       0.22      0.25      0.23        73\n",
      "         219       0.31      0.52      0.39        77\n",
      "         220       0.17      0.11      0.13        66\n",
      "         221       0.22      0.14      0.17        79\n",
      "         222       0.39      0.31      0.35        70\n",
      "         223       0.86      0.89      0.88        76\n",
      "         224       0.94      0.97      0.95        74\n",
      "         225       0.54      0.53      0.54        72\n",
      "         226       0.52      0.46      0.49        65\n",
      "         227       0.65      0.47      0.55        74\n",
      "         228       0.28      0.31      0.30        58\n",
      "         229       0.18      0.24      0.20        72\n",
      "         230       0.22      0.23      0.22        71\n",
      "         231       0.58      0.60      0.59        62\n",
      "         232       0.91      0.91      0.91        66\n",
      "         233       0.62      0.59      0.60        63\n",
      "         234       0.18      0.28      0.22        74\n",
      "         235       0.15      0.46      0.23        63\n",
      "         236       0.58      0.60      0.59        78\n",
      "         237       0.63      0.61      0.62        70\n",
      "         238       0.76      0.62      0.68        80\n",
      "         239       0.76      0.72      0.74        74\n",
      "         240       0.10      0.20      0.14        54\n",
      "         241       0.18      0.32      0.23        76\n",
      "         242       0.57      0.73      0.64        56\n",
      "         243       0.18      0.18      0.18        67\n",
      "         244       0.37      0.31      0.34        80\n",
      "         245       0.19      0.15      0.17        71\n",
      "         246       0.29      0.27      0.28        66\n",
      "         247       0.65      0.59      0.62        86\n",
      "         248       0.38      0.38      0.38        71\n",
      "         249       0.21      0.12      0.15        59\n",
      "         250       0.22      0.10      0.14        78\n",
      "         251       0.39      0.33      0.36        73\n",
      "         252       0.23      0.17      0.20        81\n",
      "         253       0.40      0.34      0.37        70\n",
      "         254       0.53      0.45      0.49        76\n",
      "         255       0.38      0.42      0.40        74\n",
      "         256       0.33      0.27      0.29        52\n",
      "         257       0.71      0.59      0.65        74\n",
      "         258       0.16      0.14      0.15        77\n",
      "         259       0.28      0.25      0.26        77\n",
      "         260       0.16      0.18      0.17        67\n",
      "         261       0.33      0.33      0.33        66\n",
      "         262       0.69      0.65      0.67        84\n",
      "         263       0.20      0.18      0.19        74\n",
      "         264       0.09      0.07      0.08        76\n",
      "         265       0.12      0.12      0.12        66\n",
      "         266       0.27      0.27      0.27        77\n",
      "         267       0.26      0.28      0.27        72\n",
      "         268       0.44      0.59      0.51        34\n",
      "         269       0.82      0.92      0.86        73\n",
      "         270       0.67      0.72      0.69        80\n",
      "         271       0.59      0.81      0.68        63\n",
      "         272       0.48      0.61      0.54        84\n",
      "         273       0.00      0.00      0.00        16\n",
      "         275       0.41      0.43      0.42        65\n",
      "         276       0.54      0.51      0.52        74\n",
      "         277       0.87      0.82      0.84        71\n",
      "         278       0.53      0.53      0.53        60\n",
      "         279       0.35      0.48      0.40        83\n",
      "         280       0.55      0.21      0.30        82\n",
      "         281       0.68      0.71      0.70        70\n",
      "         282       0.20      0.06      0.10        79\n",
      "         283       0.60      0.50      0.55        70\n",
      "         284       0.44      0.58      0.50        74\n",
      "         285       0.23      0.23      0.23        69\n",
      "         286       0.24      0.21      0.22        61\n",
      "         287       0.13      0.15      0.14        68\n",
      "         288       0.17      0.17      0.17        71\n",
      "         289       0.15      0.16      0.16        73\n",
      "         290       0.31      0.29      0.30        70\n",
      "         291       0.44      0.42      0.43        76\n",
      "         292       0.72      0.74      0.73        69\n",
      "         293       0.46      0.54      0.50        63\n",
      "         294       0.09      0.08      0.08        64\n",
      "         295       0.22      0.35      0.27        72\n",
      "         296       0.25      0.23      0.24        81\n",
      "         297       0.25      0.21      0.23        72\n",
      "         298       0.52      0.45      0.48        73\n",
      "         299       0.43      0.68      0.53        57\n",
      "         300       0.50      0.18      0.27        65\n",
      "         301       0.92      0.84      0.88        70\n",
      "         302       0.38      0.24      0.30        75\n",
      "         303       0.44      0.53      0.48        59\n",
      "         304       0.23      0.26      0.24        66\n",
      "         305       0.37      0.34      0.35        71\n",
      "         306       0.56      0.62      0.59        64\n",
      "         307       0.77      0.71      0.74        62\n",
      "         308       0.32      0.26      0.29        73\n",
      "         309       0.16      0.17      0.17        59\n",
      "         312       0.45      0.93      0.60        56\n",
      "         313       0.99      0.96      0.97        70\n",
      "         314       0.59      0.83      0.69        58\n",
      "         315       0.40      0.59      0.48        68\n",
      "         316       0.31      0.26      0.28        65\n",
      "         317       0.17      0.13      0.15        70\n",
      "         318       0.18      0.13      0.15        71\n",
      "         319       0.24      0.38      0.30        58\n",
      "         320       0.46      0.57      0.51        67\n",
      "         321       0.53      0.38      0.44        21\n",
      "         322       0.22      0.45      0.29        58\n",
      "         323       0.52      0.53      0.52        70\n",
      "         324       0.22      0.52      0.31        73\n",
      "         328       0.70      0.85      0.77        59\n",
      "         329       0.92      0.81      0.86        69\n",
      "         330       0.39      0.33      0.36        82\n",
      "         332       0.57      0.47      0.52        70\n",
      "         333       0.76      0.83      0.79        64\n",
      "         335       0.81      0.72      0.76        69\n",
      "         336       0.35      0.09      0.14        80\n",
      "         337       0.41      0.53      0.46        59\n",
      "         340       0.93      0.86      0.90        66\n",
      "         341       0.67      0.97      0.79        58\n",
      "         342       0.61      0.73      0.66        62\n",
      "         343       0.91      0.70      0.79        83\n",
      "         344       0.63      0.24      0.34        51\n",
      "         345       0.60      0.67      0.63        63\n",
      "         346       0.62      0.44      0.51        84\n",
      "         347       0.37      0.57      0.45        61\n",
      "         348       0.68      0.79      0.73        71\n",
      "         349       0.63      0.69      0.66        65\n",
      "         350       0.49      0.51      0.50        87\n",
      "         351       0.20      0.18      0.19        72\n",
      "\n",
      "    accuracy                           0.47     14329\n",
      "   macro avg       0.48      0.47      0.46     14329\n",
      "weighted avg       0.48      0.47      0.46     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  0  0 ...  0  0  0]\n",
      " [ 1 35  0 ...  0  0  0]\n",
      " [ 0  0 36 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 45  0  1]\n",
      " [ 0  0  0 ...  0 44  8]\n",
      " [ 0  0  0 ...  0 33 13]]\n",
      "\n",
      "--- Running Random Forest ---\n",
      "Random Forest Results\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.695975808327518\n",
      "\n",
      "--- Evaluating Random Forest on Holdout Test Set ---\n",
      "Holdout Test Set Results\n",
      "Accuracy: 0.6307488310419429\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.50      0.82      0.62        74\n",
      "         134       1.00      0.92      0.96        71\n",
      "         135       0.95      0.93      0.94        75\n",
      "         136       0.82      0.92      0.87        78\n",
      "         137       0.59      0.73      0.65        75\n",
      "         138       0.42      0.42      0.42        83\n",
      "         139       0.31      0.61      0.41        61\n",
      "         140       0.45      0.91      0.60        77\n",
      "         141       0.87      0.93      0.90        59\n",
      "         142       0.99      0.96      0.97        69\n",
      "         143       0.76      0.78      0.77        54\n",
      "         144       0.77      0.46      0.58        71\n",
      "         145       0.77      0.51      0.62        78\n",
      "         146       0.55      0.30      0.39        69\n",
      "         147       0.75      0.08      0.14        77\n",
      "         148       0.67      0.62      0.64        60\n",
      "         149       1.00      1.00      1.00        57\n",
      "         150       0.68      0.52      0.59        65\n",
      "         151       0.96      1.00      0.98        75\n",
      "         152       0.98      0.99      0.98        83\n",
      "         153       0.56      0.66      0.61        68\n",
      "         154       0.52      0.50      0.51        74\n",
      "         155       0.58      0.82      0.68        60\n",
      "         156       0.96      0.98      0.97        90\n",
      "         157       0.99      0.97      0.98        73\n",
      "         158       0.88      0.98      0.93        64\n",
      "         159       0.61      0.46      0.53        71\n",
      "         160       0.54      0.49      0.52        65\n",
      "         161       0.53      0.64      0.58        59\n",
      "         162       0.65      0.44      0.52        75\n",
      "         163       0.71      0.95      0.81        74\n",
      "         164       0.97      0.91      0.94        92\n",
      "         165       0.63      0.91      0.74        78\n",
      "         166       0.65      0.79      0.71        76\n",
      "         167       0.55      0.41      0.47        79\n",
      "         168       0.49      0.53      0.51        78\n",
      "         169       0.56      0.24      0.33        63\n",
      "         170       0.92      0.98      0.95        61\n",
      "         174       0.76      0.49      0.60        57\n",
      "         175       0.88      0.57      0.69        74\n",
      "         176       0.82      0.82      0.82        68\n",
      "         177       0.83      0.79      0.81        57\n",
      "         178       0.85      0.86      0.86        79\n",
      "         179       0.83      0.78      0.80        68\n",
      "         180       0.70      0.78      0.74        73\n",
      "         181       0.53      0.76      0.62        78\n",
      "         182       0.57      0.80      0.67        69\n",
      "         183       0.26      0.14      0.18        73\n",
      "         184       0.24      0.14      0.18        72\n",
      "         185       0.29      0.44      0.35        57\n",
      "         186       0.64      0.81      0.71        68\n",
      "         187       0.78      0.76      0.77        74\n",
      "         188       0.49      0.76      0.59        66\n",
      "         189       0.47      0.40      0.43        70\n",
      "         190       0.28      0.19      0.23        74\n",
      "         191       0.36      0.24      0.29        70\n",
      "         192       0.15      0.19      0.17        64\n",
      "         193       0.94      0.95      0.94        81\n",
      "         194       1.00      0.27      0.43        62\n",
      "         195       0.90      0.88      0.89        78\n",
      "         196       0.49      0.96      0.65        72\n",
      "         197       0.56      0.54      0.55        70\n",
      "         198       0.65      0.77      0.71        71\n",
      "         199       0.70      0.49      0.58        81\n",
      "         200       0.68      0.26      0.38        73\n",
      "         201       0.89      0.97      0.93        66\n",
      "         202       0.97      0.99      0.98        70\n",
      "         203       0.88      1.00      0.94        68\n",
      "         204       0.55      0.77      0.64        81\n",
      "         205       0.82      0.66      0.73        71\n",
      "         206       0.81      0.86      0.83        83\n",
      "         207       0.71      0.62      0.66        66\n",
      "         208       0.50      0.81      0.62        62\n",
      "         209       0.84      0.64      0.72        66\n",
      "         210       0.86      0.71      0.78        69\n",
      "         211       0.59      0.70      0.64        67\n",
      "         212       0.38      0.59      0.46        70\n",
      "         213       0.32      0.48      0.39        77\n",
      "         214       0.56      0.13      0.21        76\n",
      "         215       0.42      0.43      0.42        75\n",
      "         216       0.62      0.81      0.71        68\n",
      "         217       0.79      0.83      0.81        66\n",
      "         218       0.50      0.37      0.43        73\n",
      "         219       0.68      0.53      0.60        77\n",
      "         220       0.63      0.56      0.59        66\n",
      "         221       0.35      0.29      0.32        79\n",
      "         222       0.51      0.40      0.45        70\n",
      "         223       0.99      0.97      0.98        76\n",
      "         224       0.97      0.99      0.98        74\n",
      "         225       0.69      0.56      0.62        72\n",
      "         226       0.67      0.78      0.72        65\n",
      "         227       0.80      0.72      0.76        74\n",
      "         228       0.37      0.57      0.45        58\n",
      "         229       0.64      0.44      0.52        72\n",
      "         230       0.48      0.34      0.40        71\n",
      "         231       0.67      0.85      0.75        62\n",
      "         232       0.93      0.94      0.93        66\n",
      "         233       0.71      0.89      0.79        63\n",
      "         234       0.80      0.64      0.71        74\n",
      "         235       0.72      0.60      0.66        63\n",
      "         236       0.67      0.74      0.71        78\n",
      "         237       0.78      0.74      0.76        70\n",
      "         238       0.79      0.69      0.73        80\n",
      "         239       0.74      0.73      0.73        74\n",
      "         240       0.47      0.39      0.42        54\n",
      "         241       0.46      0.47      0.46        76\n",
      "         242       0.52      0.80      0.63        56\n",
      "         243       0.28      0.27      0.27        67\n",
      "         244       0.61      0.45      0.52        80\n",
      "         245       0.27      0.45      0.34        71\n",
      "         246       0.46      0.56      0.51        66\n",
      "         247       0.87      0.76      0.81        86\n",
      "         248       0.63      0.68      0.65        71\n",
      "         249       0.43      0.15      0.23        59\n",
      "         250       0.48      0.15      0.23        78\n",
      "         251       0.70      0.60      0.65        73\n",
      "         252       0.55      0.42      0.48        81\n",
      "         253       0.51      0.51      0.51        70\n",
      "         254       0.80      0.59      0.68        76\n",
      "         255       0.47      0.64      0.54        74\n",
      "         256       0.43      0.71      0.54        52\n",
      "         257       0.73      0.85      0.79        74\n",
      "         258       0.28      0.21      0.24        77\n",
      "         259       0.52      0.29      0.37        77\n",
      "         260       0.34      0.27      0.30        67\n",
      "         261       0.52      0.68      0.59        66\n",
      "         262       0.78      0.85      0.81        84\n",
      "         263       0.39      0.39      0.39        74\n",
      "         264       0.43      0.17      0.25        76\n",
      "         265       0.35      0.12      0.18        66\n",
      "         266       0.42      0.62      0.50        77\n",
      "         267       0.45      0.57      0.50        72\n",
      "         268       0.47      0.91      0.62        34\n",
      "         269       0.80      0.89      0.84        73\n",
      "         270       0.80      0.50      0.62        80\n",
      "         271       0.71      0.81      0.76        63\n",
      "         272       0.69      0.55      0.61        84\n",
      "         273       0.62      0.31      0.42        16\n",
      "         275       0.44      0.52      0.48        65\n",
      "         276       0.70      0.81      0.75        74\n",
      "         277       0.97      0.82      0.89        71\n",
      "         278       0.79      0.83      0.81        60\n",
      "         279       0.43      0.60      0.50        83\n",
      "         280       0.60      0.49      0.54        82\n",
      "         281       0.73      0.81      0.77        70\n",
      "         282       0.83      0.85      0.84        79\n",
      "         283       0.60      0.86      0.71        70\n",
      "         284       0.55      0.46      0.50        74\n",
      "         285       0.40      0.39      0.40        69\n",
      "         286       0.61      0.28      0.38        61\n",
      "         287       0.34      0.40      0.36        68\n",
      "         288       0.36      0.35      0.35        71\n",
      "         289       0.20      0.14      0.16        73\n",
      "         290       0.48      0.63      0.54        70\n",
      "         291       0.60      0.63      0.62        76\n",
      "         292       0.84      0.90      0.87        69\n",
      "         293       0.50      0.62      0.55        63\n",
      "         294       0.35      0.39      0.37        64\n",
      "         295       0.43      0.25      0.32        72\n",
      "         296       0.49      0.23      0.32        81\n",
      "         297       0.45      0.46      0.46        72\n",
      "         298       0.52      0.86      0.65        73\n",
      "         299       0.58      1.00      0.73        57\n",
      "         300       0.86      0.91      0.88        65\n",
      "         301       0.62      0.91      0.74        70\n",
      "         302       0.43      0.28      0.34        75\n",
      "         303       0.48      0.63      0.54        59\n",
      "         304       0.35      0.20      0.25        66\n",
      "         305       0.56      0.48      0.52        71\n",
      "         306       0.75      0.84      0.79        64\n",
      "         307       0.89      0.90      0.90        62\n",
      "         308       0.51      0.53      0.52        73\n",
      "         309       0.44      0.14      0.21        59\n",
      "         312       0.67      0.98      0.80        56\n",
      "         313       0.99      0.97      0.98        70\n",
      "         314       0.63      0.90      0.74        58\n",
      "         315       0.61      0.68      0.64        68\n",
      "         316       0.50      0.51      0.50        65\n",
      "         317       0.44      0.36      0.39        70\n",
      "         318       0.52      0.23      0.31        71\n",
      "         319       0.33      0.43      0.37        58\n",
      "         320       0.65      0.75      0.69        67\n",
      "         321       0.91      0.48      0.62        21\n",
      "         322       0.75      0.71      0.73        58\n",
      "         323       0.68      0.57      0.62        70\n",
      "         324       0.63      0.70      0.66        73\n",
      "         328       0.71      0.93      0.81        59\n",
      "         329       0.90      0.93      0.91        69\n",
      "         330       0.51      0.66      0.57        82\n",
      "         332       0.89      0.71      0.79        70\n",
      "         333       0.75      0.89      0.81        64\n",
      "         335       0.87      0.90      0.89        69\n",
      "         336       0.86      0.38      0.52        80\n",
      "         337       0.76      0.37      0.50        59\n",
      "         340       0.94      0.94      0.94        66\n",
      "         341       0.92      0.98      0.95        58\n",
      "         342       0.88      0.85      0.87        62\n",
      "         343       0.90      0.78      0.84        83\n",
      "         344       0.67      0.71      0.69        51\n",
      "         345       0.66      0.87      0.75        63\n",
      "         346       0.60      0.68      0.64        84\n",
      "         347       0.63      0.64      0.63        61\n",
      "         348       0.88      0.82      0.85        71\n",
      "         349       0.60      0.89      0.72        65\n",
      "         350       0.57      0.53      0.55        87\n",
      "         351       0.32      0.18      0.23        72\n",
      "\n",
      "    accuracy                           0.63     14329\n",
      "   macro avg       0.64      0.63      0.62     14329\n",
      "weighted avg       0.64      0.63      0.62     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[61  0  0 ...  0  0  0]\n",
      " [ 0 65  0 ...  0  0  0]\n",
      " [ 0  0 70 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 58  0  0]\n",
      " [ 0  0  0 ...  2 46 11]\n",
      " [ 0  0  0 ...  4 31 13]]\n",
      "\n",
      "--- Running Gaussian Naive Bayes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Na√Øve Bayes Results\n",
      "Accuracy: 0.3913700860665271\n",
      "\n",
      "--- Evaluating Gaussian Naive Bayes on Holdout Test Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Test Set Results\n",
      "Accuracy: 0.3733686928606323\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.28      0.69      0.40        74\n",
      "         134       0.84      0.93      0.88        71\n",
      "         135       0.71      0.96      0.81        75\n",
      "         136       0.78      0.94      0.85        78\n",
      "         137       0.18      0.08      0.11        75\n",
      "         138       0.45      0.22      0.29        83\n",
      "         139       0.09      0.21      0.13        61\n",
      "         140       0.30      0.81      0.44        77\n",
      "         141       0.88      0.90      0.89        59\n",
      "         142       0.96      0.94      0.95        69\n",
      "         143       0.50      0.67      0.57        54\n",
      "         144       0.00      0.00      0.00        71\n",
      "         145       0.00      0.00      0.00        78\n",
      "         146       0.19      0.09      0.12        69\n",
      "         147       0.10      0.01      0.02        77\n",
      "         148       0.44      0.48      0.46        60\n",
      "         149       0.78      0.89      0.84        57\n",
      "         150       0.71      0.18      0.29        65\n",
      "         151       1.00      0.95      0.97        75\n",
      "         152       0.95      0.95      0.95        83\n",
      "         153       0.59      0.35      0.44        68\n",
      "         154       0.00      0.00      0.00        74\n",
      "         155       0.26      0.92      0.40        60\n",
      "         156       0.94      0.94      0.94        90\n",
      "         157       1.00      0.96      0.98        73\n",
      "         158       0.77      0.91      0.83        64\n",
      "         159       0.20      0.01      0.03        71\n",
      "         160       0.12      0.18      0.15        65\n",
      "         161       0.11      0.14      0.12        59\n",
      "         162       0.08      0.05      0.06        75\n",
      "         163       0.38      0.89      0.53        74\n",
      "         164       0.82      0.82      0.82        92\n",
      "         165       0.31      0.88      0.46        78\n",
      "         166       0.26      0.80      0.39        76\n",
      "         167       0.24      0.24      0.24        79\n",
      "         168       0.21      0.09      0.12        78\n",
      "         169       0.50      0.19      0.28        63\n",
      "         170       1.00      0.02      0.03        61\n",
      "         174       0.14      0.02      0.03        57\n",
      "         175       0.00      0.00      0.00        74\n",
      "         176       0.13      0.06      0.08        68\n",
      "         177       0.00      0.00      0.00        57\n",
      "         178       0.56      0.58      0.57        79\n",
      "         179       0.34      0.84      0.48        68\n",
      "         180       0.33      0.73      0.45        73\n",
      "         181       0.09      0.04      0.05        78\n",
      "         182       0.20      0.23      0.21        69\n",
      "         183       0.06      0.04      0.05        73\n",
      "         184       0.05      0.01      0.02        72\n",
      "         185       0.05      0.09      0.06        57\n",
      "         186       0.63      0.81      0.71        68\n",
      "         187       0.73      0.69      0.71        74\n",
      "         188       0.36      0.26      0.30        66\n",
      "         189       0.00      0.00      0.00        70\n",
      "         190       0.00      0.00      0.00        74\n",
      "         191       0.00      0.00      0.00        70\n",
      "         192       0.05      0.02      0.02        64\n",
      "         193       0.80      0.91      0.86        81\n",
      "         194       0.00      0.00      0.00        62\n",
      "         195       0.75      0.85      0.80        78\n",
      "         196       0.54      0.71      0.61        72\n",
      "         197       0.16      0.44      0.24        70\n",
      "         198       0.60      0.35      0.44        71\n",
      "         199       0.27      0.10      0.14        81\n",
      "         200       0.26      0.36      0.30        73\n",
      "         201       0.97      0.85      0.90        66\n",
      "         202       1.00      0.97      0.99        70\n",
      "         203       0.86      1.00      0.93        68\n",
      "         204       0.21      0.04      0.06        81\n",
      "         205       0.12      0.03      0.05        71\n",
      "         206       0.52      0.71      0.60        83\n",
      "         207       0.31      0.33      0.32        66\n",
      "         208       0.44      0.48      0.46        62\n",
      "         209       0.24      0.86      0.37        66\n",
      "         210       0.00      0.00      0.00        69\n",
      "         211       0.24      0.79      0.37        67\n",
      "         212       0.27      0.53      0.36        70\n",
      "         213       0.20      0.32      0.25        77\n",
      "         214       0.00      0.00      0.00        76\n",
      "         215       0.10      0.37      0.15        75\n",
      "         216       0.46      0.81      0.59        68\n",
      "         217       0.43      0.80      0.56        66\n",
      "         218       0.07      0.03      0.04        73\n",
      "         219       0.00      0.00      0.00        77\n",
      "         220       0.00      0.00      0.00        66\n",
      "         221       0.00      0.00      0.00        79\n",
      "         222       0.00      0.00      0.00        70\n",
      "         223       0.99      0.87      0.92        76\n",
      "         224       0.98      0.77      0.86        74\n",
      "         225       0.27      0.31      0.29        72\n",
      "         226       0.23      0.69      0.35        65\n",
      "         227       0.45      0.72      0.55        74\n",
      "         228       0.31      0.40      0.35        58\n",
      "         229       0.31      0.21      0.25        72\n",
      "         230       0.23      0.08      0.12        71\n",
      "         231       0.51      0.63      0.57        62\n",
      "         232       0.79      0.86      0.83        66\n",
      "         233       0.50      0.49      0.50        63\n",
      "         234       0.00      0.00      0.00        74\n",
      "         235       0.10      0.02      0.03        63\n",
      "         236       0.53      0.47      0.50        78\n",
      "         237       0.08      0.04      0.06        70\n",
      "         238       0.55      0.34      0.42        80\n",
      "         239       0.75      0.41      0.53        74\n",
      "         240       0.00      0.00      0.00        54\n",
      "         241       0.26      0.12      0.16        76\n",
      "         242       0.43      0.54      0.48        56\n",
      "         243       0.15      0.15      0.15        67\n",
      "         244       0.44      0.30      0.36        80\n",
      "         245       0.10      0.21      0.14        71\n",
      "         246       0.20      0.18      0.19        66\n",
      "         247       0.80      0.42      0.55        86\n",
      "         248       0.28      0.23      0.25        71\n",
      "         249       0.00      0.00      0.00        59\n",
      "         250       0.33      0.01      0.02        78\n",
      "         251       0.17      0.01      0.03        73\n",
      "         252       0.05      0.02      0.03        81\n",
      "         253       0.17      0.20      0.19        70\n",
      "         254       0.23      0.39      0.29        76\n",
      "         255       0.12      0.31      0.18        74\n",
      "         256       0.10      0.44      0.17        52\n",
      "         257       0.45      0.47      0.46        74\n",
      "         258       0.21      0.05      0.08        77\n",
      "         259       0.33      0.06      0.11        77\n",
      "         260       0.16      0.09      0.11        67\n",
      "         261       0.33      0.30      0.31        66\n",
      "         262       0.73      0.75      0.74        84\n",
      "         263       0.20      0.16      0.18        74\n",
      "         264       0.20      0.01      0.02        76\n",
      "         265       0.17      0.02      0.03        66\n",
      "         266       0.21      0.16      0.18        77\n",
      "         267       0.12      0.14      0.13        72\n",
      "         268       0.15      0.41      0.22        34\n",
      "         269       0.66      0.86      0.75        73\n",
      "         270       0.34      0.80      0.47        80\n",
      "         271       0.28      0.83      0.42        63\n",
      "         272       0.39      0.26      0.31        84\n",
      "         273       0.14      0.19      0.16        16\n",
      "         275       0.06      0.34      0.10        65\n",
      "         276       0.48      0.59      0.53        74\n",
      "         277       0.65      0.87      0.74        71\n",
      "         278       0.37      0.83      0.52        60\n",
      "         279       0.00      0.00      0.00        83\n",
      "         280       0.12      0.01      0.02        82\n",
      "         281       0.00      0.00      0.00        70\n",
      "         282       0.00      0.00      0.00        79\n",
      "         283       0.00      0.00      0.00        70\n",
      "         284       0.19      0.16      0.18        74\n",
      "         285       0.12      0.16      0.14        69\n",
      "         286       0.02      0.02      0.02        61\n",
      "         287       0.35      0.18      0.24        68\n",
      "         288       0.20      0.27      0.23        71\n",
      "         289       0.11      0.03      0.04        73\n",
      "         290       0.00      0.00      0.00        70\n",
      "         291       0.35      0.32      0.33        76\n",
      "         292       0.80      0.81      0.81        69\n",
      "         293       0.29      0.57      0.39        63\n",
      "         294       0.00      0.00      0.00        64\n",
      "         295       0.00      0.00      0.00        72\n",
      "         296       0.00      0.00      0.00        81\n",
      "         297       0.00      0.00      0.00        72\n",
      "         298       0.13      0.60      0.22        73\n",
      "         299       0.31      0.93      0.46        57\n",
      "         300       0.85      0.94      0.89        65\n",
      "         301       0.56      0.90      0.69        70\n",
      "         302       0.22      0.08      0.12        75\n",
      "         303       0.39      0.19      0.25        59\n",
      "         304       0.28      0.27      0.28        66\n",
      "         305       0.32      0.30      0.31        71\n",
      "         306       0.71      0.58      0.64        64\n",
      "         307       0.74      0.79      0.77        62\n",
      "         308       0.04      0.01      0.02        73\n",
      "         309       0.00      0.00      0.00        59\n",
      "         312       0.00      0.00      0.00        56\n",
      "         313       0.95      0.90      0.93        70\n",
      "         314       0.34      0.76      0.47        58\n",
      "         315       0.15      0.75      0.26        68\n",
      "         316       0.25      0.23      0.24        65\n",
      "         317       0.17      0.06      0.09        70\n",
      "         318       0.00      0.00      0.00        71\n",
      "         319       0.22      0.33      0.26        58\n",
      "         320       0.60      0.54      0.57        67\n",
      "         321       0.31      0.52      0.39        21\n",
      "         322       0.13      0.03      0.05        58\n",
      "         323       0.33      0.03      0.05        70\n",
      "         324       0.30      0.12      0.17        73\n",
      "         328       0.67      0.68      0.67        59\n",
      "         329       0.66      0.83      0.74        69\n",
      "         330       0.49      0.22      0.30        82\n",
      "         332       0.67      0.03      0.05        70\n",
      "         333       0.60      0.86      0.71        64\n",
      "         335       0.92      0.64      0.75        69\n",
      "         336       0.09      0.05      0.06        80\n",
      "         337       0.30      0.14      0.19        59\n",
      "         340       0.00      0.00      0.00        66\n",
      "         341       0.48      1.00      0.65        58\n",
      "         342       0.67      0.74      0.70        62\n",
      "         343       0.59      0.73      0.65        83\n",
      "         344       0.55      0.63      0.59        51\n",
      "         345       0.72      0.70      0.71        63\n",
      "         346       0.32      0.08      0.13        84\n",
      "         347       0.34      0.72      0.46        61\n",
      "         348       0.73      0.77      0.75        71\n",
      "         349       0.53      0.77      0.62        65\n",
      "         350       0.38      0.03      0.06        87\n",
      "         351       0.11      0.03      0.04        72\n",
      "\n",
      "    accuracy                           0.37     14329\n",
      "   macro avg       0.34      0.38      0.33     14329\n",
      "weighted avg       0.34      0.37      0.33     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[51  1  3 ...  0  0  0]\n",
      " [ 0 66  0 ...  0  0  0]\n",
      " [ 0  0 72 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 50  0  0]\n",
      " [ 0  0  0 ...  2  3  4]\n",
      " [ 0  0  0 ...  3  1  2]]\n",
      "\n",
      "--- Running SVM ---\n",
      "SVM Results\n",
      "Best Parameters: {'C': 1, 'kernel': 'linear'}\n",
      "Accuracy: 0.5642009769713887\n",
      "\n",
      "--- Evaluating SVM on Holdout Test Set ---\n",
      "Holdout Test Set Results\n",
      "Accuracy: 0.5580989601507432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.76      0.73      0.74        74\n",
      "         134       0.92      0.93      0.92        71\n",
      "         135       0.83      0.96      0.89        75\n",
      "         136       0.84      0.92      0.88        78\n",
      "         137       0.58      0.53      0.56        75\n",
      "         138       0.42      0.25      0.32        83\n",
      "         139       0.37      0.62      0.46        61\n",
      "         140       0.60      0.87      0.71        77\n",
      "         141       0.93      0.95      0.94        59\n",
      "         142       0.99      0.96      0.97        69\n",
      "         143       0.61      0.69      0.64        54\n",
      "         144       0.82      0.32      0.46        71\n",
      "         145       0.61      0.47      0.53        78\n",
      "         146       0.39      0.57      0.46        69\n",
      "         147       0.51      0.35      0.42        77\n",
      "         148       0.66      0.63      0.64        60\n",
      "         149       1.00      1.00      1.00        57\n",
      "         150       0.73      0.88      0.80        65\n",
      "         151       0.99      1.00      0.99        75\n",
      "         152       0.98      1.00      0.99        83\n",
      "         153       0.51      0.63      0.56        68\n",
      "         154       0.57      0.45      0.50        74\n",
      "         155       0.52      0.83      0.64        60\n",
      "         156       0.96      0.94      0.95        90\n",
      "         157       0.99      0.96      0.97        73\n",
      "         158       0.93      0.97      0.95        64\n",
      "         159       0.53      0.52      0.52        71\n",
      "         160       0.40      0.09      0.15        65\n",
      "         161       0.40      0.44      0.42        59\n",
      "         162       0.60      0.59      0.59        75\n",
      "         163       0.58      0.70      0.63        74\n",
      "         164       0.89      0.87      0.88        92\n",
      "         165       0.45      0.82      0.58        78\n",
      "         166       0.58      0.75      0.65        76\n",
      "         167       0.47      0.41      0.44        79\n",
      "         168       0.47      0.54      0.50        78\n",
      "         169       0.52      0.27      0.35        63\n",
      "         170       0.89      0.92      0.90        61\n",
      "         174       0.40      0.37      0.39        57\n",
      "         175       0.29      0.26      0.27        74\n",
      "         176       0.56      0.49      0.52        68\n",
      "         177       0.47      0.32      0.38        57\n",
      "         178       0.68      0.85      0.76        79\n",
      "         179       0.65      0.78      0.71        68\n",
      "         180       0.65      0.74      0.69        73\n",
      "         181       0.56      0.36      0.44        78\n",
      "         182       0.39      0.58      0.47        69\n",
      "         183       0.09      0.04      0.06        73\n",
      "         184       0.12      0.15      0.14        72\n",
      "         185       0.10      0.21      0.13        57\n",
      "         186       0.77      0.90      0.83        68\n",
      "         187       0.87      0.74      0.80        74\n",
      "         188       0.59      0.64      0.61        66\n",
      "         189       0.19      0.06      0.09        70\n",
      "         190       0.17      0.01      0.03        74\n",
      "         191       0.15      0.09      0.11        70\n",
      "         192       0.11      0.14      0.12        64\n",
      "         193       0.92      0.95      0.93        81\n",
      "         194       0.75      0.94      0.83        62\n",
      "         195       0.75      0.96      0.84        78\n",
      "         196       0.50      0.89      0.64        72\n",
      "         197       0.46      0.34      0.39        70\n",
      "         198       0.68      0.75      0.71        71\n",
      "         199       0.56      0.31      0.40        81\n",
      "         200       0.68      0.34      0.45        73\n",
      "         201       0.88      0.92      0.90        66\n",
      "         202       0.93      0.99      0.96        70\n",
      "         203       0.92      0.97      0.94        68\n",
      "         204       0.62      0.53      0.57        81\n",
      "         205       0.59      0.45      0.51        71\n",
      "         206       0.61      0.83      0.70        83\n",
      "         207       0.50      0.39      0.44        66\n",
      "         208       0.51      0.61      0.56        62\n",
      "         209       0.46      0.86      0.60        66\n",
      "         210       0.74      0.77      0.75        69\n",
      "         211       0.46      0.64      0.54        67\n",
      "         212       0.53      0.56      0.55        70\n",
      "         213       0.37      0.52      0.43        77\n",
      "         214       0.00      0.00      0.00        76\n",
      "         215       0.18      0.16      0.17        75\n",
      "         216       0.70      0.78      0.74        68\n",
      "         217       0.74      0.79      0.76        66\n",
      "         218       0.36      0.33      0.35        73\n",
      "         219       0.81      0.22      0.35        77\n",
      "         220       0.40      0.50      0.45        66\n",
      "         221       0.21      0.28      0.24        79\n",
      "         222       0.38      0.27      0.32        70\n",
      "         223       0.96      0.91      0.93        76\n",
      "         224       0.92      0.97      0.95        74\n",
      "         225       0.55      0.44      0.49        72\n",
      "         226       0.49      0.71      0.58        65\n",
      "         227       0.72      0.72      0.72        74\n",
      "         228       0.35      0.52      0.42        58\n",
      "         229       0.56      0.49      0.52        72\n",
      "         230       0.36      0.11      0.17        71\n",
      "         231       0.67      0.81      0.73        62\n",
      "         232       0.92      0.92      0.92        66\n",
      "         233       0.73      0.73      0.73        63\n",
      "         234       0.26      0.08      0.12        74\n",
      "         235       0.46      0.60      0.52        63\n",
      "         236       0.58      0.64      0.61        78\n",
      "         237       0.71      0.67      0.69        70\n",
      "         238       0.68      0.75      0.71        80\n",
      "         239       0.75      0.72      0.73        74\n",
      "         240       0.06      0.04      0.04        54\n",
      "         241       0.26      0.22      0.24        76\n",
      "         242       0.53      0.75      0.62        56\n",
      "         243       0.19      0.22      0.21        67\n",
      "         244       0.59      0.46      0.52        80\n",
      "         245       0.22      0.44      0.29        71\n",
      "         246       0.40      0.48      0.44        66\n",
      "         247       0.85      0.80      0.83        86\n",
      "         248       0.68      0.68      0.68        71\n",
      "         249       0.35      0.10      0.16        59\n",
      "         250       0.27      0.31      0.29        78\n",
      "         251       0.61      0.59      0.60        73\n",
      "         252       0.32      0.30      0.31        81\n",
      "         253       0.23      0.27      0.25        70\n",
      "         254       0.77      0.53      0.62        76\n",
      "         255       0.24      0.46      0.31        74\n",
      "         256       0.27      0.52      0.36        52\n",
      "         257       0.66      0.78      0.72        74\n",
      "         258       0.29      0.22      0.25        77\n",
      "         259       0.33      0.18      0.23        77\n",
      "         260       0.27      0.21      0.24        67\n",
      "         261       0.56      0.55      0.55        66\n",
      "         262       0.82      0.93      0.87        84\n",
      "         263       0.39      0.38      0.39        74\n",
      "         264       0.60      0.12      0.20        76\n",
      "         265       0.09      0.02      0.03        66\n",
      "         266       0.31      0.52      0.38        77\n",
      "         267       0.29      0.40      0.34        72\n",
      "         268       0.29      0.32      0.31        34\n",
      "         269       0.78      0.85      0.82        73\n",
      "         270       0.50      0.79      0.61        80\n",
      "         271       0.66      0.81      0.73        63\n",
      "         272       0.47      0.48      0.47        84\n",
      "         273       0.20      0.12      0.15        16\n",
      "         275       0.55      0.42      0.47        65\n",
      "         276       0.65      0.68      0.66        74\n",
      "         277       0.89      0.87      0.88        71\n",
      "         278       0.72      0.82      0.77        60\n",
      "         279       0.25      0.34      0.29        83\n",
      "         280       0.40      0.12      0.19        82\n",
      "         281       0.63      0.64      0.64        70\n",
      "         282       0.64      0.67      0.65        79\n",
      "         283       0.66      0.79      0.72        70\n",
      "         284       0.54      0.61      0.57        74\n",
      "         285       0.33      0.28      0.30        69\n",
      "         286       0.13      0.11      0.12        61\n",
      "         287       0.31      0.31      0.31        68\n",
      "         288       0.29      0.38      0.33        71\n",
      "         289       0.14      0.05      0.08        73\n",
      "         290       0.19      0.41      0.26        70\n",
      "         291       0.61      0.67      0.64        76\n",
      "         292       0.85      0.87      0.86        69\n",
      "         293       0.60      0.62      0.61        63\n",
      "         294       0.28      0.44      0.34        64\n",
      "         295       0.06      0.01      0.02        72\n",
      "         296       0.07      0.01      0.02        81\n",
      "         297       0.40      0.24      0.30        72\n",
      "         298       0.38      0.75      0.51        73\n",
      "         299       0.92      0.84      0.88        57\n",
      "         300       0.78      0.95      0.86        65\n",
      "         301       0.73      0.91      0.81        70\n",
      "         302       0.35      0.39      0.37        75\n",
      "         303       0.46      0.53      0.49        59\n",
      "         304       0.24      0.24      0.24        66\n",
      "         305       0.46      0.52      0.49        71\n",
      "         306       0.76      0.81      0.79        64\n",
      "         307       0.90      0.87      0.89        62\n",
      "         308       0.41      0.41      0.41        73\n",
      "         309       0.29      0.03      0.06        59\n",
      "         312       0.90      0.77      0.83        56\n",
      "         313       0.97      0.97      0.97        70\n",
      "         314       0.92      0.76      0.83        58\n",
      "         315       0.59      0.68      0.63        68\n",
      "         316       0.52      0.25      0.33        65\n",
      "         317       0.31      0.33      0.32        70\n",
      "         318       0.12      0.03      0.05        71\n",
      "         319       0.33      0.50      0.40        58\n",
      "         320       0.75      0.70      0.72        67\n",
      "         321       0.73      0.38      0.50        21\n",
      "         322       0.70      0.48      0.57        58\n",
      "         323       0.55      0.43      0.48        70\n",
      "         324       0.51      0.64      0.57        73\n",
      "         328       0.73      0.75      0.74        59\n",
      "         329       0.86      0.88      0.87        69\n",
      "         330       0.35      0.37      0.36        82\n",
      "         332       0.47      0.61      0.53        70\n",
      "         333       0.56      0.89      0.69        64\n",
      "         335       0.93      0.80      0.86        69\n",
      "         336       0.25      0.03      0.05        80\n",
      "         337       0.50      0.10      0.17        59\n",
      "         340       0.94      0.77      0.85        66\n",
      "         341       0.76      0.98      0.86        58\n",
      "         342       0.78      0.82      0.80        62\n",
      "         343       0.75      0.78      0.76        83\n",
      "         344       0.59      0.78      0.67        51\n",
      "         345       0.59      0.75      0.66        63\n",
      "         346       0.59      0.43      0.50        84\n",
      "         347       0.41      0.64      0.50        61\n",
      "         348       0.89      0.82      0.85        71\n",
      "         349       0.71      0.85      0.77        65\n",
      "         350       0.58      0.48      0.53        87\n",
      "         351       0.52      0.18      0.27        72\n",
      "\n",
      "    accuracy                           0.56     14329\n",
      "   macro avg       0.55      0.56      0.54     14329\n",
      "weighted avg       0.55      0.56      0.54     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  1  0 ...  0  0  0]\n",
      " [ 0 66  0 ...  0  0  0]\n",
      " [ 0  0 72 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 55  0  0]\n",
      " [ 0  0  0 ...  2 42  7]\n",
      " [ 0  0  0 ...  2 30 13]]\n",
      "\n",
      "--- Running KNN ---\n",
      "KNN Results\n",
      "Best Parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy: 0.6549197487787858\n",
      "\n",
      "--- Evaluating KNN on Holdout Test Set ---\n",
      "Holdout Test Set Results\n",
      "Accuracy: 0.6359131830553423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.81      0.81      0.81        74\n",
      "         134       0.97      0.93      0.95        71\n",
      "         135       0.86      0.95      0.90        75\n",
      "         136       0.92      0.88      0.90        78\n",
      "         137       0.64      0.57      0.61        75\n",
      "         138       0.47      0.34      0.39        83\n",
      "         139       0.47      0.61      0.53        61\n",
      "         140       0.86      0.86      0.86        77\n",
      "         141       0.81      0.93      0.87        59\n",
      "         142       0.94      0.94      0.94        69\n",
      "         143       0.67      0.76      0.71        54\n",
      "         144       0.73      0.62      0.67        71\n",
      "         145       0.59      0.53      0.55        78\n",
      "         146       0.56      0.65      0.60        69\n",
      "         147       0.58      0.52      0.55        77\n",
      "         148       0.67      0.80      0.73        60\n",
      "         149       0.98      1.00      0.99        57\n",
      "         150       0.81      0.83      0.82        65\n",
      "         151       1.00      0.99      0.99        75\n",
      "         152       0.99      1.00      0.99        83\n",
      "         153       0.52      0.37      0.43        68\n",
      "         154       0.48      0.42      0.45        74\n",
      "         155       0.56      0.67      0.61        60\n",
      "         156       0.85      0.89      0.87        90\n",
      "         157       0.99      0.93      0.96        73\n",
      "         158       0.87      0.94      0.90        64\n",
      "         159       0.62      0.59      0.60        71\n",
      "         160       0.67      0.58      0.62        65\n",
      "         161       0.54      0.61      0.57        59\n",
      "         162       0.66      0.68      0.67        75\n",
      "         163       0.84      0.78      0.81        74\n",
      "         164       0.94      0.98      0.96        92\n",
      "         165       0.66      0.81      0.73        78\n",
      "         166       0.73      0.80      0.77        76\n",
      "         167       0.57      0.53      0.55        79\n",
      "         168       0.58      0.36      0.44        78\n",
      "         169       0.50      0.33      0.40        63\n",
      "         170       0.92      1.00      0.96        61\n",
      "         174       0.64      0.68      0.66        57\n",
      "         175       0.74      0.68      0.70        74\n",
      "         176       0.75      0.66      0.70        68\n",
      "         177       0.59      0.72      0.65        57\n",
      "         178       0.79      0.77      0.78        79\n",
      "         179       0.75      0.85      0.80        68\n",
      "         180       0.68      0.75      0.71        73\n",
      "         181       0.61      0.72      0.66        78\n",
      "         182       0.65      0.65      0.65        69\n",
      "         183       0.18      0.11      0.14        73\n",
      "         184       0.22      0.18      0.20        72\n",
      "         185       0.14      0.21      0.17        57\n",
      "         186       0.56      0.75      0.64        68\n",
      "         187       0.66      0.72      0.69        74\n",
      "         188       0.47      0.41      0.44        66\n",
      "         189       0.50      0.43      0.46        70\n",
      "         190       0.30      0.34      0.32        74\n",
      "         191       0.34      0.34      0.34        70\n",
      "         192       0.14      0.16      0.15        64\n",
      "         193       0.93      0.99      0.96        81\n",
      "         194       0.91      0.94      0.92        62\n",
      "         195       0.83      0.92      0.87        78\n",
      "         196       0.70      0.78      0.74        72\n",
      "         197       0.69      0.53      0.60        70\n",
      "         198       0.84      0.75      0.79        71\n",
      "         199       0.67      0.58      0.62        81\n",
      "         200       0.52      0.56      0.54        73\n",
      "         201       0.84      0.92      0.88        66\n",
      "         202       1.00      0.97      0.99        70\n",
      "         203       0.84      0.93      0.88        68\n",
      "         204       0.74      0.75      0.75        81\n",
      "         205       0.87      0.66      0.75        71\n",
      "         206       0.77      0.82      0.80        83\n",
      "         207       0.66      0.67      0.66        66\n",
      "         208       0.67      0.76      0.71        62\n",
      "         209       0.76      0.85      0.80        66\n",
      "         210       0.85      0.87      0.86        69\n",
      "         211       0.64      0.66      0.65        67\n",
      "         212       0.41      0.44      0.43        70\n",
      "         213       0.32      0.30      0.31        77\n",
      "         214       0.41      0.30      0.35        76\n",
      "         215       0.36      0.40      0.38        75\n",
      "         216       0.49      0.69      0.58        68\n",
      "         217       0.66      0.80      0.73        66\n",
      "         218       0.49      0.37      0.42        73\n",
      "         219       0.65      0.60      0.62        77\n",
      "         220       0.53      0.62      0.57        66\n",
      "         221       0.39      0.37      0.38        79\n",
      "         222       0.54      0.44      0.49        70\n",
      "         223       0.95      0.92      0.93        76\n",
      "         224       0.99      0.99      0.99        74\n",
      "         225       0.64      0.67      0.65        72\n",
      "         226       0.62      0.74      0.67        65\n",
      "         227       0.63      0.68      0.65        74\n",
      "         228       0.23      0.24      0.24        58\n",
      "         229       0.66      0.57      0.61        72\n",
      "         230       0.43      0.42      0.43        71\n",
      "         231       0.65      0.55      0.60        62\n",
      "         232       0.88      0.85      0.86        66\n",
      "         233       0.82      0.67      0.74        63\n",
      "         234       0.67      0.65      0.66        74\n",
      "         235       0.60      0.71      0.65        63\n",
      "         236       0.84      0.67      0.74        78\n",
      "         237       0.70      0.74      0.72        70\n",
      "         238       0.83      0.65      0.73        80\n",
      "         239       0.80      0.80      0.80        74\n",
      "         240       0.26      0.37      0.31        54\n",
      "         241       0.39      0.46      0.42        76\n",
      "         242       0.54      0.79      0.64        56\n",
      "         243       0.29      0.19      0.23        67\n",
      "         244       0.58      0.35      0.44        80\n",
      "         245       0.35      0.32      0.34        71\n",
      "         246       0.34      0.39      0.37        66\n",
      "         247       0.89      0.55      0.68        86\n",
      "         248       0.59      0.37      0.45        71\n",
      "         249       0.49      0.49      0.49        59\n",
      "         250       0.44      0.37      0.40        78\n",
      "         251       0.77      0.64      0.70        73\n",
      "         252       0.48      0.54      0.51        81\n",
      "         253       0.61      0.63      0.62        70\n",
      "         254       0.84      0.76      0.80        76\n",
      "         255       0.55      0.64      0.59        74\n",
      "         256       0.39      0.56      0.46        52\n",
      "         257       0.75      0.70      0.73        74\n",
      "         258       0.30      0.26      0.28        77\n",
      "         259       0.44      0.40      0.42        77\n",
      "         260       0.27      0.18      0.22        67\n",
      "         261       0.40      0.50      0.45        66\n",
      "         262       0.77      0.82      0.79        84\n",
      "         263       0.42      0.30      0.35        74\n",
      "         264       0.39      0.29      0.33        76\n",
      "         265       0.40      0.35      0.37        66\n",
      "         266       0.53      0.60      0.56        77\n",
      "         267       0.50      0.54      0.52        72\n",
      "         268       0.80      0.82      0.81        34\n",
      "         269       0.90      0.89      0.90        73\n",
      "         270       0.69      0.76      0.72        80\n",
      "         271       0.79      0.84      0.82        63\n",
      "         272       0.72      0.57      0.64        84\n",
      "         273       0.60      0.38      0.46        16\n",
      "         275       0.67      0.66      0.67        65\n",
      "         276       0.46      0.62      0.53        74\n",
      "         277       0.83      0.89      0.86        71\n",
      "         278       0.59      0.82      0.69        60\n",
      "         279       0.59      0.71      0.64        83\n",
      "         280       0.78      0.78      0.78        82\n",
      "         281       0.88      0.86      0.87        70\n",
      "         282       0.83      0.89      0.86        79\n",
      "         283       0.74      0.70      0.72        70\n",
      "         284       0.55      0.62      0.59        74\n",
      "         285       0.41      0.54      0.47        69\n",
      "         286       0.45      0.54      0.49        61\n",
      "         287       0.31      0.29      0.30        68\n",
      "         288       0.25      0.15      0.19        71\n",
      "         289       0.31      0.27      0.29        73\n",
      "         290       0.54      0.54      0.54        70\n",
      "         291       0.52      0.53      0.52        76\n",
      "         292       0.78      0.86      0.81        69\n",
      "         293       0.57      0.52      0.55        63\n",
      "         294       0.40      0.44      0.42        64\n",
      "         295       0.38      0.33      0.35        72\n",
      "         296       0.49      0.46      0.47        81\n",
      "         297       0.51      0.51      0.51        72\n",
      "         298       0.88      0.89      0.88        73\n",
      "         299       0.93      0.95      0.94        57\n",
      "         300       0.89      0.95      0.92        65\n",
      "         301       0.86      0.91      0.89        70\n",
      "         302       0.45      0.43      0.44        75\n",
      "         303       0.41      0.47      0.44        59\n",
      "         304       0.36      0.24      0.29        66\n",
      "         305       0.47      0.44      0.45        71\n",
      "         306       0.74      0.78      0.76        64\n",
      "         307       0.82      0.79      0.80        62\n",
      "         308       0.46      0.58      0.51        73\n",
      "         309       0.44      0.46      0.45        59\n",
      "         312       0.90      0.98      0.94        56\n",
      "         313       0.95      0.99      0.97        70\n",
      "         314       0.88      0.84      0.86        58\n",
      "         315       0.68      0.66      0.67        68\n",
      "         316       0.38      0.35      0.37        65\n",
      "         317       0.31      0.24      0.27        70\n",
      "         318       0.34      0.28      0.31        71\n",
      "         319       0.31      0.40      0.35        58\n",
      "         320       0.51      0.58      0.55        67\n",
      "         321       0.61      0.52      0.56        21\n",
      "         322       0.61      0.66      0.63        58\n",
      "         323       0.75      0.60      0.67        70\n",
      "         324       0.56      0.62      0.58        73\n",
      "         328       0.69      0.85      0.76        59\n",
      "         329       0.88      0.91      0.89        69\n",
      "         330       0.40      0.48      0.43        82\n",
      "         332       0.80      0.74      0.77        70\n",
      "         333       0.65      0.91      0.76        64\n",
      "         335       0.93      0.80      0.86        69\n",
      "         336       0.73      0.57      0.64        80\n",
      "         337       0.48      0.53      0.50        59\n",
      "         340       0.97      0.88      0.92        66\n",
      "         341       0.84      1.00      0.91        58\n",
      "         342       0.79      0.90      0.84        62\n",
      "         343       0.89      0.75      0.81        83\n",
      "         344       0.59      0.67      0.62        51\n",
      "         345       0.78      0.62      0.69        63\n",
      "         346       0.64      0.69      0.67        84\n",
      "         347       0.60      0.69      0.64        61\n",
      "         348       0.74      0.77      0.76        71\n",
      "         349       0.71      0.77      0.74        65\n",
      "         350       0.69      0.60      0.64        87\n",
      "         351       0.42      0.42      0.42        72\n",
      "\n",
      "    accuracy                           0.64     14329\n",
      "   macro avg       0.63      0.64      0.63     14329\n",
      "weighted avg       0.64      0.64      0.63     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[60  0  0 ...  0  0  0]\n",
      " [ 0 66  0 ...  0  0  0]\n",
      " [ 1  0 71 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 50  0  0]\n",
      " [ 0  0  0 ...  0 52 19]\n",
      " [ 0  0  0 ...  0 16 30]]\n",
      "\n",
      "--- Running AdaBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Results\n",
      "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Accuracy: 0.0654803442661084\n",
      "\n",
      "--- Evaluating AdaBoost on Holdout Test Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nahid\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Test Set Results\n",
      "Accuracy: 0.06518249703398701\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         133       0.00      0.00      0.00        74\n",
      "         134       0.00      0.00      0.00        71\n",
      "         135       0.00      0.00      0.00        75\n",
      "         136       0.00      0.00      0.00        78\n",
      "         137       0.00      0.00      0.00        75\n",
      "         138       0.00      0.00      0.00        83\n",
      "         139       0.00      0.00      0.00        61\n",
      "         140       0.00      0.00      0.00        77\n",
      "         141       0.00      0.00      0.00        59\n",
      "         142       0.00      0.00      0.00        69\n",
      "         143       0.00      0.00      0.00        54\n",
      "         144       0.01      0.48      0.02        71\n",
      "         145       0.20      0.01      0.02        78\n",
      "         146       0.00      0.00      0.00        69\n",
      "         147       0.00      0.00      0.00        77\n",
      "         148       0.00      0.00      0.00        60\n",
      "         149       0.00      0.00      0.00        57\n",
      "         150       0.00      0.00      0.00        65\n",
      "         151       0.00      0.00      0.00        75\n",
      "         152       0.97      0.88      0.92        83\n",
      "         153       0.00      0.00      0.00        68\n",
      "         154       0.06      0.08      0.07        74\n",
      "         155       0.00      0.00      0.00        60\n",
      "         156       0.00      0.00      0.00        90\n",
      "         157       0.17      0.01      0.03        73\n",
      "         158       0.34      0.94      0.50        64\n",
      "         159       0.00      0.00      0.00        71\n",
      "         160       0.00      0.00      0.00        65\n",
      "         161       0.00      0.00      0.00        59\n",
      "         162       0.00      0.00      0.00        75\n",
      "         163       0.00      0.00      0.00        74\n",
      "         164       0.32      0.98      0.48        92\n",
      "         165       0.08      1.00      0.15        78\n",
      "         166       0.00      0.00      0.00        76\n",
      "         167       0.00      0.00      0.00        79\n",
      "         168       0.00      0.00      0.00        78\n",
      "         169       0.00      0.00      0.00        63\n",
      "         170       0.00      0.00      0.00        61\n",
      "         174       0.00      0.00      0.00        57\n",
      "         175       0.00      0.00      0.00        74\n",
      "         176       0.00      0.00      0.00        68\n",
      "         177       0.03      0.07      0.04        57\n",
      "         178       0.26      0.86      0.40        79\n",
      "         179       0.39      0.72      0.51        68\n",
      "         180       0.03      0.03      0.03        73\n",
      "         181       0.00      0.00      0.00        78\n",
      "         182       0.04      0.03      0.03        69\n",
      "         183       0.00      0.00      0.00        73\n",
      "         184       0.00      0.00      0.00        72\n",
      "         185       0.00      0.00      0.00        57\n",
      "         186       0.00      0.00      0.00        68\n",
      "         187       0.00      0.00      0.00        74\n",
      "         188       0.22      0.03      0.05        66\n",
      "         189       0.00      0.00      0.00        70\n",
      "         190       0.00      0.00      0.00        74\n",
      "         191       0.00      0.00      0.00        70\n",
      "         192       0.00      0.00      0.00        64\n",
      "         193       0.00      0.00      0.00        81\n",
      "         194       0.00      0.00      0.00        62\n",
      "         195       0.00      0.00      0.00        78\n",
      "         196       0.00      0.00      0.00        72\n",
      "         197       0.00      0.00      0.00        70\n",
      "         198       0.00      0.00      0.00        71\n",
      "         199       0.00      0.00      0.00        81\n",
      "         200       0.00      0.00      0.00        73\n",
      "         201       0.00      0.00      0.00        66\n",
      "         202       0.00      0.00      0.00        70\n",
      "         203       0.00      0.00      0.00        68\n",
      "         204       0.00      0.00      0.00        81\n",
      "         205       0.00      0.00      0.00        71\n",
      "         206       0.00      0.00      0.00        83\n",
      "         207       0.07      0.92      0.13        66\n",
      "         208       0.33      0.05      0.08        62\n",
      "         209       0.00      0.00      0.00        66\n",
      "         210       0.00      0.00      0.00        69\n",
      "         211       0.00      0.00      0.00        67\n",
      "         212       0.00      0.00      0.00        70\n",
      "         213       0.00      0.00      0.00        77\n",
      "         214       0.00      0.00      0.00        76\n",
      "         215       0.00      0.00      0.00        75\n",
      "         216       0.00      0.00      0.00        68\n",
      "         217       0.03      0.15      0.04        66\n",
      "         218       0.00      0.00      0.00        73\n",
      "         219       0.00      0.00      0.00        77\n",
      "         220       0.00      0.00      0.00        66\n",
      "         221       0.00      0.00      0.00        79\n",
      "         222       0.00      0.00      0.00        70\n",
      "         223       0.00      0.00      0.00        76\n",
      "         224       0.78      0.69      0.73        74\n",
      "         225       0.00      0.00      0.00        72\n",
      "         226       0.00      0.00      0.00        65\n",
      "         227       0.00      0.00      0.00        74\n",
      "         228       0.00      0.00      0.00        58\n",
      "         229       0.00      0.00      0.00        72\n",
      "         230       0.00      0.00      0.00        71\n",
      "         231       0.00      0.00      0.00        62\n",
      "         232       0.00      0.00      0.00        66\n",
      "         233       0.00      0.00      0.00        63\n",
      "         234       0.00      0.00      0.00        74\n",
      "         235       0.00      0.00      0.00        63\n",
      "         236       0.00      0.00      0.00        78\n",
      "         237       0.00      0.00      0.00        70\n",
      "         238       0.00      0.00      0.00        80\n",
      "         239       0.30      0.74      0.42        74\n",
      "         240       0.03      0.24      0.06        54\n",
      "         241       0.00      0.00      0.00        76\n",
      "         242       0.00      0.00      0.00        56\n",
      "         243       0.00      0.00      0.00        67\n",
      "         244       0.00      0.00      0.00        80\n",
      "         245       0.00      0.00      0.00        71\n",
      "         246       0.00      0.00      0.00        66\n",
      "         247       0.00      0.00      0.00        86\n",
      "         248       0.00      0.00      0.00        71\n",
      "         249       0.00      0.00      0.00        59\n",
      "         250       0.00      0.00      0.00        78\n",
      "         251       0.00      0.00      0.00        73\n",
      "         252       0.00      0.00      0.00        81\n",
      "         253       0.00      0.00      0.00        70\n",
      "         254       0.00      0.00      0.00        76\n",
      "         255       0.00      0.00      0.00        74\n",
      "         256       0.01      1.00      0.02        52\n",
      "         257       0.00      0.00      0.00        74\n",
      "         258       0.00      0.00      0.00        77\n",
      "         259       0.00      0.00      0.00        77\n",
      "         260       0.00      0.00      0.00        67\n",
      "         261       0.00      0.00      0.00        66\n",
      "         262       0.00      0.00      0.00        84\n",
      "         263       0.00      0.00      0.00        74\n",
      "         264       0.00      0.00      0.00        76\n",
      "         265       0.00      0.00      0.00        66\n",
      "         266       0.00      0.00      0.00        77\n",
      "         267       0.00      0.00      0.00        72\n",
      "         268       0.00      0.00      0.00        34\n",
      "         269       0.75      0.12      0.21        73\n",
      "         270       0.00      0.00      0.00        80\n",
      "         271       0.00      0.00      0.00        63\n",
      "         272       0.00      0.00      0.00        84\n",
      "         273       0.00      0.00      0.00        16\n",
      "         275       0.00      0.00      0.00        65\n",
      "         276       0.00      0.00      0.00        74\n",
      "         277       0.00      0.00      0.00        71\n",
      "         278       0.25      0.02      0.03        60\n",
      "         279       0.00      0.00      0.00        83\n",
      "         280       0.00      0.00      0.00        82\n",
      "         281       0.00      0.00      0.00        70\n",
      "         282       0.00      0.00      0.00        79\n",
      "         283       0.00      0.00      0.00        70\n",
      "         284       0.00      0.00      0.00        74\n",
      "         285       0.00      0.00      0.00        69\n",
      "         286       0.00      0.00      0.00        61\n",
      "         287       0.00      0.00      0.00        68\n",
      "         288       0.00      0.00      0.00        71\n",
      "         289       0.00      0.00      0.00        73\n",
      "         290       0.00      0.00      0.00        70\n",
      "         291       0.00      0.00      0.00        76\n",
      "         292       0.00      0.00      0.00        69\n",
      "         293       0.41      0.11      0.17        63\n",
      "         294       0.00      0.00      0.00        64\n",
      "         295       0.00      0.00      0.00        72\n",
      "         296       0.00      0.00      0.00        81\n",
      "         297       0.00      0.00      0.00        72\n",
      "         298       0.04      0.04      0.04        73\n",
      "         299       0.00      0.00      0.00        57\n",
      "         300       0.00      0.00      0.00        65\n",
      "         301       0.00      0.00      0.00        70\n",
      "         302       0.00      0.00      0.00        75\n",
      "         303       0.00      0.00      0.00        59\n",
      "         304       0.00      0.00      0.00        66\n",
      "         305       0.00      0.00      0.00        71\n",
      "         306       0.00      0.00      0.00        64\n",
      "         307       0.37      0.31      0.34        62\n",
      "         308       0.00      0.00      0.00        73\n",
      "         309       0.00      0.00      0.00        59\n",
      "         312       0.00      0.00      0.00        56\n",
      "         313       0.00      0.00      0.00        70\n",
      "         314       0.00      0.00      0.00        58\n",
      "         315       0.00      0.00      0.00        68\n",
      "         316       0.00      0.00      0.00        65\n",
      "         317       0.00      0.00      0.00        70\n",
      "         318       0.00      0.00      0.00        71\n",
      "         319       0.00      0.00      0.00        58\n",
      "         320       0.01      0.01      0.01        67\n",
      "         321       0.00      0.00      0.00        21\n",
      "         322       0.03      0.05      0.04        58\n",
      "         323       0.00      0.00      0.00        70\n",
      "         324       0.03      0.05      0.04        73\n",
      "         328       0.00      0.00      0.00        59\n",
      "         329       0.00      0.00      0.00        69\n",
      "         330       0.00      0.06      0.01        82\n",
      "         332       0.00      0.00      0.00        70\n",
      "         333       0.00      0.00      0.00        64\n",
      "         335       0.64      0.26      0.37        69\n",
      "         336       0.00      0.00      0.00        80\n",
      "         337       0.00      0.00      0.00        59\n",
      "         340       0.58      0.64      0.61        66\n",
      "         341       0.00      0.00      0.00        58\n",
      "         342       0.66      0.77      0.71        62\n",
      "         343       0.00      0.00      0.00        83\n",
      "         344       0.00      0.00      0.00        51\n",
      "         345       0.00      0.00      0.00        63\n",
      "         346       0.00      0.00      0.00        84\n",
      "         347       0.00      0.00      0.00        61\n",
      "         348       0.00      0.00      0.00        71\n",
      "         349       0.35      0.49      0.41        65\n",
      "         350       0.00      0.00      0.00        87\n",
      "         351       0.06      0.38      0.11        72\n",
      "\n",
      "    accuracy                           0.07     14329\n",
      "   macro avg       0.04      0.06      0.04     14329\n",
      "weighted avg       0.04      0.07      0.04     14329\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 32  0  5]\n",
      " [ 0  0  0 ...  0  0 27]\n",
      " [ 0  0  0 ...  2  0 27]]\n",
      "\n",
      "--- Running Gradient Boost ---\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # List of models and their functions\n",
    "    models = {\n",
    "        \"Logistic Regression\": logistic_regression_grid_search,\n",
    "        \"Decision Tree\": decision_tree_grid_search,\n",
    "        \"Random Forest\": random_forest_grid_search,\n",
    "        \"Gaussian Naive Bayes\": gaussian_naive_bayes,\n",
    "        \"SVM\": svm_grid_search,\n",
    "        \"KNN\": knn_grid_search,\n",
    "        \"AdaBoost\": adaboost_grid_search,\n",
    "        \"Gradient Boost\": gradient_boost_grid_search,\n",
    "        \"XGBoost\": xgboost_grid_search,\n",
    "        \"Artificial Neural Networks (ANN)\": ann_grid_search,\n",
    "    }\n",
    "\n",
    "    # Run each model\n",
    "    for model_name, model_function in models.items():\n",
    "        print(f\"\\n--- Running {model_name} ---\")\n",
    "        best_model = model_function(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        \n",
    "        # Evaluate on holdout test set\n",
    "        print(f\"\\n--- Evaluating {model_name} on Holdout Test Set ---\")\n",
    "        evaluate_on_holdout(best_model, X_holdout_scaled, y_holdout)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8ff9a43-2902-4162-a7cf-0e5fb07c670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute All Models One by One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7c335-5fba-4997-bc1a-3bacf8b730c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa179bf0-3246-4fc3-b8f9-a93c0d33f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4468b51-628d-4624-ba6a-907901d3e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gradient_boosting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa926889-9604-46c1-ae0c-22dea3023cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ada_boost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01c2c8-06a2-4cf7-b010-990adfb92cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gaussian_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37262ad-b19a-4684-9328-bfe8d6412ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_svc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2c7ff-db47-44a2-bfe1-e6b67ea9a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cbe18-f608-4866-99fd-e4bfc2512467",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_xgboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f09805-29c7-4015-9345-fb589db237f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8478f0-d29e-46df-9855-9c4d7b8b4034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
