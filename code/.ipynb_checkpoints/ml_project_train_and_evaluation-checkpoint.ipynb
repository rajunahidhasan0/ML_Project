{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218aeb79",
   "metadata": {
    "id": "218aeb79"
   },
   "source": [
    "## Predication with Different Classification Method to The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8u87wItZgc5z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10160,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "8u87wItZgc5z",
    "outputId": "afc8db8e-a3ed-44a0-a2b9-6ec5d7c597ff"
   },
   "outputs": [],
   "source": [
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecb0a47",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "cecb0a47"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Ensemble Methods\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5f1c92",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518653,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "df5f1c92"
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b276802",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "4b276802",
    "outputId": "202ce665-362a-4eda-9c93-74ed5c461aab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function IPython.lib.pretty._type_pprint(obj, p, cycle)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set maximum output lines before scrolling\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.instance().display_formatter.formatters['text/plain'].for_type(\n",
    "    type, lambda obj, p, cycle: p.text(repr(obj)[:10000])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db941cad",
   "metadata": {
    "id": "db941cad"
   },
   "source": [
    "### Metrics Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aceecb7",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "1aceecb7"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(classifier, y_value, y_pred):\n",
    "    print(f\"{classifier} Metrics: \")\n",
    "    print(classification_report(y_value, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9677b8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733444518654,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "c9677b8a"
   },
   "outputs": [],
   "source": [
    "def fit_model_and_generate_metrics(model, label, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    calculate_metrics(label, y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a91ddf",
   "metadata": {
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1733444518838,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "93a91ddf"
   },
   "outputs": [],
   "source": [
    "class ModelTuningAndEvaluation:\n",
    "\n",
    "    param_grid_logistic_regression = {\n",
    "        'C': [0.01, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [100, 500, 1000]\n",
    "    }\n",
    "\n",
    "    param_grid_decission_tree_classifier = {\n",
    "        'max_depth': [None, 5, 20, 50],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "\n",
    "    param_grid_random_forest_classifier = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20, 50],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_gaussian_naive_bias = {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    }\n",
    "\n",
    "    param_grid_svc = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': [100, 500, 700, 900, 1100, 1500],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['minkowski'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    param_grid_ada_boost = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.5, 1.0],\n",
    "        'estimator': [\n",
    "            DecisionTreeClassifier(max_depth=1),\n",
    "            DecisionTreeClassifier(max_depth=3)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    }\n",
    "\n",
    "    param_grid_grad_boost = {\n",
    "      'n_estimators': [50, 100, 200],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 5, 7],\n",
    "      'random_state': [42]\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'model__n_neurons': [64],\n",
    "        'model__activation': ['relu', 'tanh'],\n",
    "        'epochs': [100, 150],\n",
    "        'batch_size': [50, 100]\n",
    "    }\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.feature_path = file_path\n",
    "        self.feature_df = self.get_feture()\n",
    "        self.X, self.y = self.split_feture_and_target()\n",
    "        # for xgaboost mapping y to start from zero\n",
    "        self.y = self.map_zero_to_n() \n",
    "        self.number_of_categories = self.get_number_of_categories()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.get_scale_and_test_train_split()\n",
    "\n",
    "    # data read and processing section\n",
    "    def remove_outliear(self, feature_df):\n",
    "        iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "        outliers = iso.fit_predict(feature_df)\n",
    "        data_cleaned = feature_df[outliers == 1]\n",
    "        return data_cleaned\n",
    "\n",
    "    def get_feture(self):\n",
    "        feature_df = pd.read_csv(self.feature_path)\n",
    "        feature_df = feature_df.iloc[:, 1:] # remove index\n",
    "        return self.remove_outliear(feature_df)\n",
    "\n",
    "    def split_feture_and_target(self):\n",
    "        X = self.feature_df.iloc[:, :-1]\n",
    "        y = self.feature_df.iloc[:, -1]\n",
    "        return X, y\n",
    "\n",
    "    def get_scale_and_test_train_split(self):\n",
    "        #Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_fature = scaler.fit_transform(self.X)\n",
    "        #test train split\n",
    "        return train_test_split(scaled_fature, self.y, train_size=.20, random_state=42, stratify=self.y)\n",
    "\n",
    "    def map_zero_to_n(self):\n",
    "        unique_values = {val: idx for idx, val in enumerate(self.y.unique())}\n",
    "        y_mapped = self.y.map(unique_values)\n",
    "        return y_mapped\n",
    "\n",
    "    def get_number_of_categories(self):\n",
    "        return len(self.y.unique())\n",
    "\n",
    "    def onehot_encode(self):\n",
    "        self.y_train = to_categorical(self.y_train, num_classes = self.number_of_categories)\n",
    "        print(self.y_train.shape)\n",
    "\n",
    "    # Cross validation\n",
    "    def kfold_cross_validation(self, model, n_splits):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        kfold_score = cross_val_score(model, self.X, self.y, cv=kf)\n",
    "        mean_score = np.mean(kfold_score)\n",
    "        print(\"K-fold cross-validation scores:\", kfold_score)\n",
    "        print(\"Mean K-fold cross-validation score:\", mean_score)\n",
    "\n",
    "    def stratified_cross_validation(self, model, n_splits):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        skfold_score = cross_val_score(model, self.X, self.y, cv=skf)\n",
    "        \n",
    "        mean_score = np.mean(skfold_score)\n",
    "        print(\"Straified cross validation scores:\", skfold_score)\n",
    "        print(\"Mean Straified cross-validation score:\", mean_score)\n",
    "\n",
    "    def cross_validation(self, model, n_splits):\n",
    "        self.kfold_cross_validation(model, n_splits)\n",
    "        self.stratified_cross_validation(model, n_splits)\n",
    "\n",
    "    # Hyper-parameter tuning\n",
    "\n",
    "    def gridSerach(self, estimator, param_grid):\n",
    "        print(\"#-------- Grid Search --------#\")\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3, verbose=0)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters: \", grid_search.best_params_)\n",
    "        print(\"Best score: \", grid_search.best_score_)\n",
    "        return grid_search\n",
    "\n",
    "    def randomSearch(self, estimator, param_grid):\n",
    "        print(\"\\n#---------- Random Search -----------#\")\n",
    "\n",
    "        random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=500, cv=3, random_state=42)\n",
    "        random_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters: \", random_search.best_params_)\n",
    "        print(\"Best score: \", random_search.best_score_)\n",
    "        return random_search\n",
    "\n",
    "    def hyper_parameter_tuning(self, model, param_grid):\n",
    "        grid_search = self.gridSerach(model, param_grid)\n",
    "        random_search = self.randomSearch(model, param_grid)\n",
    "        return grid_search if grid_search.best_score_ > random_search.best_score_ else random_search\n",
    "\n",
    "    # Models section\n",
    "    def run_logistic_regression_model(self):\n",
    "        print(\"#------------------- #1. Logistic Regression Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(LogisticRegression(), self.param_grid_logistic_regression)\n",
    "        lrm = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(lrm, \"Logistic Regression\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(lrm, 10)\n",
    "\n",
    "    def run_decission_tree_classifier_model(self):\n",
    "        print(\"#-------------------- #2. Decission Tree Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(DecisionTreeClassifier(), self.param_grid_decission_tree_classifier)\n",
    "        dt = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(dt, \"Decission Tree Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(dt, 10)\n",
    "\n",
    "    def run_random_forest_classifier_model(self):\n",
    "        print(\"#-------------------- #3. Random Forest Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(RandomForestClassifier(), self.param_grid_random_forest_classifier)\n",
    "        rfc = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(rfc, \"Random Forest Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(rfc, 10)\n",
    "\n",
    "    def run_gaussian_naive_bias_classifier_model(self):\n",
    "        print(\"#-------------------- #4. Gaussian Naive Bias Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GaussianNB(), self.param_grid_gaussian_naive_bias)\n",
    "        gnb = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(gnb, \"Gaussian Naive Bias Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gnb, 10)\n",
    "\n",
    "\n",
    "    def run_support_vector_classifier_model(self):\n",
    "        print(\"#-------------------- #5. Support Vector Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(SVC(), self.param_grid_svc)\n",
    "        svc = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(svc, \"Support Vector Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(svc, 10)\n",
    "\n",
    "\n",
    "    def run_knn_classifier_model(self):\n",
    "        print(\"#-------------------- #6. K-Nearest Neighbors Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(KNeighborsClassifier(), self.param_grid_knn)\n",
    "        knn = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(knn, \"K-Nearest Neighbors\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(knn, 10)\n",
    "\n",
    "    def run_ada_boost_classifier_model(self):\n",
    "        print(\"#-------------------- #7. Ada-Boost Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(AdaBoostClassifier(), self.param_grid_ada_boost)\n",
    "        abc = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(abc, \"Ada-Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(abc, 10)\n",
    "\n",
    "    def run_xg_boost_classifier_model(self):\n",
    "        print(\"-------------------- #8. XG Boost Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(XGBClassifier(), self.param_grid_xgb)\n",
    "        xgb = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(xgb, \"XG Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(xgb, 10)\n",
    "\n",
    "    def run_gradient_boost_classifier_model(self):\n",
    "        print(\"#-------------------- #9. Gradient Boost Classifier Model --------------------#\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GradientBoostingClassifier(), self.param_grid_grad_boost)\n",
    "        gb = tuned_model.best_estimator_\n",
    "\n",
    "        fit_model_and_generate_metrics(gb, \"Gradient Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gb, 10)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_ann(n_neurons=128, activation='relu'):\n",
    "        model = Sequential()\n",
    "        # Input layer\n",
    "        model.add(Dense(n_neurons, activation=activation, input_shape=(24,)))\n",
    "\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(units=15, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def run_ann_model(self):\n",
    "        print(\"#-------------------- #10. Artificial Neural Net Model --------------------#\")\n",
    "\n",
    "        y_train_tmp = self.y_train\n",
    "\n",
    "        self.onehot_encode()\n",
    "\n",
    "        model = KerasClassifier(build_fn=self.build_ann, verbose=0, epochs = 50, batch_size = 100)\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(model, self.param_grid_ann)\n",
    "        ann = tuned_model.best_estimator_\n",
    "\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        calculate_metrics(\"10. Artificial Neural Net\", self.y_test, y_pred_classes)\n",
    "        self.cross_validation(ann, 2)\n",
    "\n",
    "        self.y_train = y_train_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "xkrwkNYuf8X7",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1733444518838,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "xkrwkNYuf8X7"
   },
   "outputs": [],
   "source": [
    "path = '../data/Processed_Features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "A0T3QkR1CVXP",
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1733444519546,
     "user": {
      "displayName": "Nadim Mahmud",
      "userId": "12866761848113428285"
     },
     "user_tz": 300
    },
    "id": "A0T3QkR1CVXP"
   },
   "outputs": [],
   "source": [
    "model_evaluation_pipeline = ModelEvaluationPipeline(path + \"W500_O50_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ba5f7e-4ef8-48ef-983d-a8d96e856514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================2. Decission Tree Classifier Section: ================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2}\n",
      "Best score found:  0.4882718290421515\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 2, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "Best score found:  0.486462088346639\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       591\n",
      "           1       0.72      0.70      0.71       619\n",
      "           2       0.56      0.55      0.55       667\n",
      "           3       0.51      0.53      0.52       651\n",
      "           4       0.43      0.39      0.41       667\n",
      "           5       0.45      0.41      0.43       579\n",
      "           6       0.37      0.40      0.38       610\n",
      "           7       0.41      0.46      0.43       652\n",
      "           8       0.66      0.65      0.66       484\n",
      "           9       0.84      0.85      0.85       502\n",
      "          10       0.67      0.69      0.68       589\n",
      "          11       0.36      0.35      0.36       631\n",
      "          12       0.35      0.32      0.34       619\n",
      "          13       0.37      0.37      0.37       523\n",
      "          14       0.32      0.36      0.34       484\n",
      "\n",
      "    accuracy                           0.51      8868\n",
      "   macro avg       0.51      0.51      0.51      8868\n",
      "weighted avg       0.51      0.51      0.51      8868\n",
      "\n",
      "K-fold cross-validation scores: [0.65464382 0.64562669 0.64201984 0.64743012 0.65523466 0.65523466\n",
      " 0.64350181 0.65884477 0.67148014 0.64981949]\n",
      "Mean K-fold cross-validation score: 0.6523835992356596\n",
      "Straified cross validation scores: [0.65734896 0.65103697 0.66185753 0.66095582 0.6633574  0.65884477\n",
      " 0.63447653 0.6398917  0.6868231  0.64440433]\n",
      "Mean Straified cross-validation score: 0.6558997112564413\n"
     ]
    }
   ],
   "source": [
    "model_evaluation_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2762c3c-ebb4-460a-a3af-16587e341cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
