{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  \\\n",
      "0   w100_o25_pipeline.run_logistic_regression_model()   \n",
      "1   w100_o25_pipeline.run_decission_tree_classifie...   \n",
      "2   w100_o25_pipeline.run_random_forest_classifier...   \n",
      "3   w100_o25_pipeline.run_gaussian_naive_bias_clas...   \n",
      "4   w100_o25_pipeline.run_support_vector_classifie...   \n",
      "..                                                ...   \n",
      "93  w500_o50_features_pipeline.run_support_vector_...   \n",
      "94  w500_o50_features_pipeline.run_ada_boost_class...   \n",
      "95  w500_o50_features_pipeline.run_xg_boost_classi...   \n",
      "96  w500_o50_features_pipeline.run_gradient_boost_...   \n",
      "97         w500_o25_features_pipeline.run_ann_model()   \n",
      "\n",
      "                                                    1  \n",
      "0   =============== 1. Logistic Regression Section...  \n",
      "1   \\n\\n=================2. Decission Tree Classif...  \n",
      "2   \\n\\n=================== 3. Random Forest Class...  \n",
      "3   \\n\\n=================== 4. Gaussian Naive Bias...  \n",
      "4   \\n\\n=================== 5. Support Vector Clas...  \n",
      "..                                                ...  \n",
      "93  =================== 5. Support Vector Classifi...  \n",
      "94  =================== 7. Ada Boost Classifier Se...  \n",
      "95  =================== 8. XG Boost Classifier Sec...  \n",
      "96  =================== 9. Gradient Boost Classifi...  \n",
      "97  =================== 10. Artificial Neural Net ...  \n",
      "\n",
      "[98 rows x 2 columns]\n",
      "Results saved to: parsed_metrics_with_source.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = \"ml_project_train_and_evaluation.json\"  # Replace with your file path\n",
    "with open(file_path, \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract all outputs and their corresponding sources\n",
    "outputs_with_sources = []\n",
    "for cell in json_data[\"cells\"]:\n",
    "    if cell[\"cell_type\"] == \"code\" and \"outputs\" in cell:\n",
    "        source = \"\\n\".join(cell[\"source\"])\n",
    "        for output in cell[\"outputs\"]:\n",
    "            if \"text\" in output:\n",
    "                outputs_with_sources.append((source, \"\\n\".join(output[\"text\"])))\n",
    "\n",
    "# Initialize a results list\n",
    "results_list = []\n",
    "\n",
    "# Function to extract pipeline prefix\n",
    "def extract_source(command):\n",
    "    match = re.match(r\"(\\w+)_pipeline\", command)\n",
    "    return match.group(1) if match else \"Unknown\"\n",
    "\n",
    "df_summary = pd.DataFrame(outputs_with_sources)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_summary)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = \"parsed_metrics_with_source.csv\"\n",
    "df_summary.to_csv(output_csv_path, index=False)\n",
    "print(f\"Results saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w100_o25_pipeline.run_logistic_regression_model()</td>\n",
       "      <td>=============== 1. Logistic Regression Section...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w100_o25_pipeline.run_decission_tree_classifie...</td>\n",
       "      <td>\\n\\n=================2. Decission Tree Classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w100_o25_pipeline.run_random_forest_classifier...</td>\n",
       "      <td>\\n\\n=================== 3. Random Forest Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w100_o25_pipeline.run_gaussian_naive_bias_clas...</td>\n",
       "      <td>\\n\\n=================== 4. Gaussian Naive Bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w100_o25_pipeline.run_support_vector_classifie...</td>\n",
       "      <td>\\n\\n=================== 5. Support Vector Clas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  w100_o25_pipeline.run_logistic_regression_model()   \n",
       "1  w100_o25_pipeline.run_decission_tree_classifie...   \n",
       "2  w100_o25_pipeline.run_random_forest_classifier...   \n",
       "3  w100_o25_pipeline.run_gaussian_naive_bias_clas...   \n",
       "4  w100_o25_pipeline.run_support_vector_classifie...   \n",
       "\n",
       "                                                   1  \n",
       "0  =============== 1. Logistic Regression Section...  \n",
       "1  \\n\\n=================2. Decission Tree Classif...  \n",
       "2  \\n\\n=================== 3. Random Forest Class...  \n",
       "3  \\n\\n=================== 4. Gaussian Naive Bias...  \n",
       "4  \\n\\n=================== 5. Support Vector Clas...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file = pd.read_csv(\"parsed_metrics_with_source.csv\")\n",
    "source_file.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Model  Accuracy  Precision  Recall  F1 Score  \\\n",
      "0             Logistic Regression      0.30       0.30    0.30      0.28   \n",
      "1       Decission Tree Classifier      0.51       0.51    0.51      0.51   \n",
      "2        Random Forest Classifier      0.64       0.64    0.64      0.64   \n",
      "3  Gaussian Naive Bias Classifier      0.22       0.23    0.22      0.19   \n",
      "4       Support Vector Classifier      0.56       0.55    0.56      0.55   \n",
      "\n",
      "   k-fold score  stratified score    Source  \n",
      "0      0.252359          0.255485  w100_o25  \n",
      "1      0.601506          0.603069  w100_o25  \n",
      "2      0.723282          0.723386  w100_o25  \n",
      "3      0.130738          0.130738  w100_o25  \n",
      "4      0.275702          0.274556  w100_o25  \n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "def parse_metrics_flexible(source, text):\n",
    "    try:\n",
    "        # Define improved regex patterns\n",
    "        model_pattern = r\"={3,}\\s*\\d+\\.\\s*(.*?)\\s*Section:\"\n",
    "        accuracy_pattern = r\"accuracy\\s+([\\d.]+)\"\n",
    "        weighted_avg_pattern = r\"weighted avg\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"\n",
    "\n",
    "        if 'ann' in source:\n",
    "            kfold_pattern = r\"K-fold cross-validation scores:.*?Average score:\\s*([\\d.]+)\"\n",
    "            stratified_pattern = r\"Stratified cross-validation scores:.*?Average score:\\s*([\\d.]+)\"\n",
    "        else:\n",
    "            kfold_pattern = r\"K-fold cross validaiton scores:\\s*\\[([\\d.\\s]+)\\]\"\n",
    "            stratified_pattern = r\"Straified cross validation scores:\\s*\\[([\\d.\\s]+)\\]\"\n",
    "\n",
    "        # Extract metrics\n",
    "        model = re.search(model_pattern, text).group(1).strip()\n",
    "        accuracy_match = re.search(accuracy_pattern, text)\n",
    "        match = re.search(weighted_avg_pattern, text)\n",
    "        kfold_match = re.search(kfold_pattern, text)\n",
    "        stratified_match = re.search(stratified_pattern, text)\n",
    "\n",
    "        accuracy = float(accuracy_match.group(1)) if accuracy_match else None\n",
    "\n",
    "        if match:\n",
    "            precision = float(match.group(1))\n",
    "            recall = float(match.group(2))\n",
    "            f1_score = float(match.group(3))\n",
    "        else:\n",
    "            print(\"Weighted avg row not found.\")\n",
    "\n",
    "        if 'ann' in source:\n",
    "            kfold_match = re.search(kfold_pattern, text, re.DOTALL)\n",
    "            kfold_avg = float(kfold_match.group(1))\n",
    "\n",
    "            stratified_match = re.search(stratified_pattern, text, re.DOTALL)\n",
    "            stratified_avg = float(stratified_match.group(1))\n",
    "\n",
    "        else:\n",
    "            kfold_scores = [float(x) for x in kfold_match.group(1).split()]\n",
    "            kfold_avg = sum(kfold_scores) / len(kfold_scores)\n",
    "            \n",
    "            stratified_scores = [float(x) for x in stratified_match.group(1).split()]\n",
    "            stratified_avg = sum(stratified_scores) / len(stratified_scores)\n",
    "\n",
    "        # Append to results list\n",
    "        results_list.append({\n",
    "            \"Model\": model,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1_score,\n",
    "            \"k-fold score\": kfold_avg,\n",
    "            \"stratified score\": stratified_avg,\n",
    "            \"Source\": extract_source(source)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing source '{source}': {e}\")\n",
    "\n",
    "# Parse all rows with improved regex\n",
    "\n",
    "for row in source_file.itertuples(index=False):\n",
    "    parse_metrics_flexible(row[0], row[1])\n",
    "\n",
    "# Convert parsed results to a DataFrame\n",
    "df_parsed_metrics = pd.DataFrame(results_list)\n",
    "print(df_parsed_metrics.head())\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(outputs_with_sources[i][1])\n",
    "\n",
    "df_parsed_metrics.to_csv(\"evaluation_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlKernel",
   "language": "python",
   "name": "mlkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
