{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  \\\n",
      "0   # 1. Logistic Regression on W100_O25_Features\\...   \n",
      "1   # 2. Decision Tree Classifier on W100_O25_Feat...   \n",
      "2   # 3. Random Forest Classifier on W100_O25_Feat...   \n",
      "3   # 4. Gaussian Naive Bayes on W100_O25_Features...   \n",
      "4   # 5. Support Vector Classifier on W100_O25_Fea...   \n",
      "..                                                ...   \n",
      "95  # 6. K-Nearest Neighbors on W500_O50_Features\\...   \n",
      "96  # 7. AdaBoost Classifier on W500_O50_Features\\...   \n",
      "97  # 8. Gradient Boost on W500_O50_Features\\n\\nev...   \n",
      "98  # 9. XGBoost Classifier on W500_O50_Features\\n...   \n",
      "99  # 10. Artificial Neural Network on W500_O50_Fe...   \n",
      "\n",
      "                                                    1  \n",
      "0   #------------------- #1. Logistic Regression M...  \n",
      "1   #-------------------- #2. Decission Tree Class...  \n",
      "2   #-------------------- #3. Random Forest Classi...  \n",
      "3   #-------------------- #4. Gaussian Naive Bias ...  \n",
      "4   #-------------------- #5. Support Vector Class...  \n",
      "..                                                ...  \n",
      "95  #-------------------- #6. K-Nearest Neighbors ...  \n",
      "96  #-------------------- #7. Ada-Boost Classifier...  \n",
      "97  #-------------------- #9. Gradient Boost Class...  \n",
      "98  -------------------- #8. XG Boost Classifier M...  \n",
      "99  #----------------------- #10. Artificial Neura...  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Results saved to: parsed_metrics_with_source.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "file_path = \"ml_project_train_and_evaluation.json\"  # Replace with your file path\n",
    "with open(file_path, \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract all outputs and their corresponding sources\n",
    "outputs_with_sources = []\n",
    "for cell in json_data[\"cells\"]:\n",
    "    if cell[\"cell_type\"] == \"code\" and \"outputs\" in cell:\n",
    "        source = \"\\n\".join(cell[\"source\"])\n",
    "        for output in cell[\"outputs\"]:\n",
    "            if \"text\" in output:\n",
    "                outputs_with_sources.append((source, \"\\n\".join(output[\"text\"])))\n",
    "                \n",
    "df_summary = pd.DataFrame(outputs_with_sources)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_summary)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = \"parsed_metrics_with_source.csv\"\n",
    "df_summary.to_csv(output_csv_path, index=False)\n",
    "print(f\"Results saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># 1. Logistic Regression on W100_O25_Features\\...</td>\n",
       "      <td>#------------------- #1. Logistic Regression M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># 2. Decision Tree Classifier on W100_O25_Feat...</td>\n",
       "      <td>#-------------------- #2. Decission Tree Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># 3. Random Forest Classifier on W100_O25_Feat...</td>\n",
       "      <td>#-------------------- #3. Random Forest Classi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># 4. Gaussian Naive Bayes on W100_O25_Features...</td>\n",
       "      <td>#-------------------- #4. Gaussian Naive Bias ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># 5. Support Vector Classifier on W100_O25_Fea...</td>\n",
       "      <td>#-------------------- #5. Support Vector Class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  # 1. Logistic Regression on W100_O25_Features\\...   \n",
       "1  # 2. Decision Tree Classifier on W100_O25_Feat...   \n",
       "2  # 3. Random Forest Classifier on W100_O25_Feat...   \n",
       "3  # 4. Gaussian Naive Bayes on W100_O25_Features...   \n",
       "4  # 5. Support Vector Classifier on W100_O25_Fea...   \n",
       "\n",
       "                                                   1  \n",
       "0  #------------------- #1. Logistic Regression M...  \n",
       "1  #-------------------- #2. Decission Tree Class...  \n",
       "2  #-------------------- #3. Random Forest Classi...  \n",
       "3  #-------------------- #4. Gaussian Naive Bias ...  \n",
       "4  #-------------------- #5. Support Vector Class...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file = pd.read_csv(\"parsed_metrics_with_source.csv\")\n",
    "source_file.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Source                      Model  Accuracy  \\\n",
      "0        Logistic Regression on W100_O25        Logistic Regression      0.35   \n",
      "1   Decision Tree Classifier on W100_O25   Decision Tree Classifier      0.53   \n",
      "2   Random Forest Classifier on W100_O25   Random Forest Classifier      0.65   \n",
      "3       Gaussian Naive Bayes on W100_O25       Gaussian Naive Bayes      0.22   \n",
      "4  Support Vector Classifier on W100_O25  Support Vector Classifier      0.59   \n",
      "\n",
      "   Precision  Recall  F1 Score  K-fold score  Stratified score  \n",
      "0       0.34    0.35      0.32      0.319709          0.314451  \n",
      "1       0.53    0.53      0.53      0.620816          0.618992  \n",
      "2       0.65    0.65      0.64      0.734933          0.736941  \n",
      "3       0.24    0.22      0.18      0.200148          0.200095  \n",
      "4       0.57    0.59      0.58      0.168098          0.169947  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Function to extract pipeline prefix\n",
    "def extract_source(command):\n",
    "    match = re.search(r\"on\\s+(\\w+)_Features\", command)\n",
    "    return match.group(1) if match else \"Unknown\"\n",
    "\n",
    "\n",
    "def parse_metrics_flexible(source, text):\n",
    "    try:\n",
    "        # Define regex patterns\n",
    "        model_pattern = r\"#\\s*\\d+\\.\\s*(.*?)\\s*on\\s*(\\w+)_Features\"  # Extract model name and feature set\n",
    "        accuracy_pattern = r\"accuracy\\s+([\\d.]+)\"  # Extract accuracy\n",
    "        weighted_avg_pattern = r\"weighted avg\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"  # Extract weighted avg precision, recall, f1-score\n",
    "        kfold_pattern = r\"K-fold cross-validation scores:\\s*\\[([\\d.\\s]+)\\]\"  # Extract K-fold scores\n",
    "        stratified_pattern = r\"Straified cross validation scores:\\s*\\[([\\d.\\s]+)\\]\"  # Extract stratified scores\n",
    "\n",
    "        # Extract model name and feature set from the source\n",
    "        model_match = re.search(model_pattern, source)\n",
    "        if model_match:\n",
    "            model = model_match.group(1).strip()\n",
    "            feature_set = model_match.group(2).strip()\n",
    "        else:\n",
    "            model = \"Unknown Model\"\n",
    "            feature_set = \"Unknown Features\"\n",
    "\n",
    "        # Extract accuracy\n",
    "        accuracy_match = re.search(accuracy_pattern, text)\n",
    "        accuracy = float(accuracy_match.group(1)) if accuracy_match else None\n",
    "\n",
    "        # Extract weighted avg precision, recall, and f1-score\n",
    "        weighted_avg_match = re.search(weighted_avg_pattern, text)\n",
    "        if weighted_avg_match:\n",
    "            precision = float(weighted_avg_match.group(1))\n",
    "            recall = float(weighted_avg_match.group(2))\n",
    "            f1_score = float(weighted_avg_match.group(3))\n",
    "        else:\n",
    "            precision, recall, f1_score = None, None, None\n",
    "\n",
    "        # Extract K-fold cross-validation scores and calculate average\n",
    "        kfold_match = re.search(kfold_pattern, text)\n",
    "        if kfold_match:\n",
    "            kfold_scores = [float(x) for x in kfold_match.group(1).split()]\n",
    "            kfold_avg = sum(kfold_scores) / len(kfold_scores)\n",
    "        else:\n",
    "            kfold_avg = None\n",
    "\n",
    "        # Extract stratified cross-validation scores and calculate average\n",
    "        stratified_match = re.search(stratified_pattern, text)\n",
    "        if stratified_match:\n",
    "            stratified_scores = [float(x) for x in stratified_match.group(1).split()]\n",
    "            stratified_avg = sum(stratified_scores) / len(stratified_scores)\n",
    "        else:\n",
    "            stratified_avg = None\n",
    "\n",
    "        # Append the extracted results to the results list\n",
    "        results_list.append({\n",
    "            \"Source\": f\"{model} on {feature_set}\",\n",
    "            \"Model\": model,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1_score,\n",
    "            \"K-fold score\": kfold_avg,\n",
    "            \"Stratified score\": stratified_avg\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing source '{source}': {e}\")\n",
    "\n",
    "# Parse all rows with improved regex\n",
    "\n",
    "for row in source_file.itertuples(index=False):\n",
    "    parse_metrics_flexible(row[0], row[1])\n",
    "\n",
    "# Convert parsed results to a DataFrame\n",
    "df_parsed_metrics = pd.DataFrame(results_list)\n",
    "print(df_parsed_metrics.head())\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(outputs_with_sources[i][1])\n",
    "\n",
    "df_parsed_metrics.to_csv(\"evaluation_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
