{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  \\\n",
      "0   # 1. Logistic Regression on W100_O25_Features\\...   \n",
      "1   # 2. Decision Tree Classifier on W100_O25_Feat...   \n",
      "2   # 3. Random Forest Classifier on W100_O25_Feat...   \n",
      "3   # 4. Gaussian Naive Bayes on W100_O25_Features...   \n",
      "4   # 5. Support Vector Classifier on W100_O25_Fea...   \n",
      "..                                                ...   \n",
      "95  # 6. K-Nearest Neighbors on W500_O50_Features\\...   \n",
      "96  # 7. AdaBoost Classifier on W500_O50_Features\\...   \n",
      "97  # 8. Gradient Boost on W500_O50_Features\\n\\nev...   \n",
      "98  # 9. XGBoost Classifier on W500_O50_Features\\n...   \n",
      "99  # 10. Artificial Neural Network on W500_O50_Fe...   \n",
      "\n",
      "                                                    1  \n",
      "0   #------------------- #1. Logistic Regression M...  \n",
      "1   #-------------------- #2. Decission Tree Class...  \n",
      "2   #-------------------- #3. Random Forest Classi...  \n",
      "3   #-------------------- #4. Gaussian Naive Bias ...  \n",
      "4   #-------------------- #5. Support Vector Class...  \n",
      "..                                                ...  \n",
      "95  #-------------------- #6. K-Nearest Neighbors ...  \n",
      "96  #-------------------- #7. Ada-Boost Classifier...  \n",
      "97  #-------------------- #9. Gradient Boost Class...  \n",
      "98  -------------------- #8. XG Boost Classifier M...  \n",
      "99  #----------------------- #10. Artificial Neura...  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'parsed_metrics_with_source.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m     21\u001b[0m output_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsed_metrics_with_source.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mdf_summary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'parsed_metrics_with_source.csv'"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "file_path = \"ml_project_train_and_evaluation.json\"  # Replace with your file path\n",
    "with open(file_path, \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Extract all outputs and their corresponding sources\n",
    "outputs_with_sources = []\n",
    "for cell in json_data[\"cells\"]:\n",
    "    if cell[\"cell_type\"] == \"code\" and \"outputs\" in cell:\n",
    "        source = \"\\n\".join(cell[\"source\"])\n",
    "        for output in cell[\"outputs\"]:\n",
    "            if \"text\" in output:\n",
    "                outputs_with_sources.append((source, \"\\n\".join(output[\"text\"])))\n",
    "                \n",
    "df_summary = pd.DataFrame(outputs_with_sources)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_summary)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = \"parsed_metrics_with_source.csv\"\n",
    "df_summary.to_csv(output_csv_path, index=False)\n",
    "print(f\"Results saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># 1. Logistic Regression on W100_O25_Features\\...</td>\n",
       "      <td>#------------------- #1. Logistic Regression M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># 2. Decision Tree Classifier on W100_O25_Feat...</td>\n",
       "      <td>#-------------------- #2. Decission Tree Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># 3. Random Forest Classifier on W100_O25_Feat...</td>\n",
       "      <td>#-------------------- #3. Random Forest Classi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># 4. Gaussian Naive Bayes on W100_O25_Features...</td>\n",
       "      <td>#-------------------- #4. Gaussian Naive Bias ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># 5. Support Vector Classifier on W100_O25_Fea...</td>\n",
       "      <td>#-------------------- #5. Support Vector Class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  # 1. Logistic Regression on W100_O25_Features\\...   \n",
       "1  # 2. Decision Tree Classifier on W100_O25_Feat...   \n",
       "2  # 3. Random Forest Classifier on W100_O25_Feat...   \n",
       "3  # 4. Gaussian Naive Bayes on W100_O25_Features...   \n",
       "4  # 5. Support Vector Classifier on W100_O25_Fea...   \n",
       "\n",
       "                                                   1  \n",
       "0  #------------------- #1. Logistic Regression M...  \n",
       "1  #-------------------- #2. Decission Tree Class...  \n",
       "2  #-------------------- #3. Random Forest Classi...  \n",
       "3  #-------------------- #4. Gaussian Naive Bias ...  \n",
       "4  #-------------------- #5. Support Vector Class...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file = pd.read_csv(\"parsed_metrics_with_source.csv\")\n",
    "source_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Source                      Model  Accuracy  Precision  Recall  \\\n",
      "0   W100_O25        Logistic Regression      0.35       0.34    0.35   \n",
      "1   W100_O25   Decision Tree Classifier      0.53       0.53    0.53   \n",
      "2   W100_O25   Random Forest Classifier      0.65       0.65    0.65   \n",
      "3   W100_O25       Gaussian Naive Bayes      0.22       0.24    0.22   \n",
      "4   W100_O25  Support Vector Classifier      0.59       0.57    0.59   \n",
      "5   W100_O25        K-Nearest Neighbors      0.52       0.54    0.52   \n",
      "6   W100_O25        AdaBoost Classifier      0.35       0.40    0.35   \n",
      "7   W100_O25             Gradient Boost      0.62       0.62    0.62   \n",
      "8   W100_O25         XGBoost Classifier      0.63       0.63    0.63   \n",
      "9   W100_O25  Artificial Neural Network      0.51       0.50    0.51   \n",
      "10  W100_O50        Logistic Regression      0.36       0.35    0.36   \n",
      "11  W100_O50   Decision Tree Classifier      0.57       0.57    0.57   \n",
      "\n",
      "    F1 Score  K-fold score  Stratified score  \n",
      "0       0.32      0.319709          0.314451  \n",
      "1       0.53      0.620816          0.618992  \n",
      "2       0.64      0.734933          0.736941  \n",
      "3       0.18      0.200148          0.200095  \n",
      "4       0.58      0.168098          0.169947  \n",
      "5       0.50      0.358866          0.360055  \n",
      "6       0.29      0.331651          0.331466  \n",
      "7       0.62      0.696198          0.694877  \n",
      "8       0.62      0.679182          0.678971  \n",
      "9       0.50           NaN               NaN  \n",
      "10      0.33      0.183765          0.184047  \n",
      "11      0.57      0.663171          0.660404  \n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "# Function to extract pipeline prefix\n",
    "def extract_source(command):\n",
    "    match = re.search(r\"on\\s+(\\w+)_Features\", command)\n",
    "    return match.group(1) if match else \"Unknown\"\n",
    "\n",
    "\n",
    "def parse_metrics_flexible(source, text):\n",
    "    try:\n",
    "        # Define regex patterns\n",
    "        model_pattern = r\"#\\s*\\d+\\.\\s*(.*?)\\s*on\\s*(\\w+)_Features\"  # Extract model name and feature set\n",
    "        accuracy_pattern = r\"accuracy\\s+([\\d.]+)\"  # Extract accuracy\n",
    "        weighted_avg_pattern = r\"weighted avg\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"  # Extract weighted avg precision, recall, f1-score\n",
    "        \n",
    "        if \"artificial neural network\" in source.lower():  # Check if the source is ANN\n",
    "            kfold_pattern = r\"K-fold cross-validation scores:.*?Average score:\\s*([\\d.]+)\"\n",
    "            stratified_pattern = r\"Stratified cross-validation scores:.*?Average score:\\s*([\\d.]+)\"\n",
    "        else:\n",
    "            kfold_pattern = r\"K-fold cross-validation scores:\\s*\\[([\\d.\\s]+)\\]\"  # Extract K-fold scores\n",
    "            stratified_pattern = r\"Straified cross validation scores:\\s*\\[([\\d.\\s]+)\\]\"  # Extract stratified scores\n",
    "\n",
    "        # Extract model name and feature set from the source\n",
    "        model_match = re.search(model_pattern, source)\n",
    "        if model_match:\n",
    "            model = model_match.group(1).strip()\n",
    "            feature_set = model_match.group(2).strip()\n",
    "        else:\n",
    "            model = \"Unknown Model\"\n",
    "            feature_set = \"Unknown Features\"\n",
    "\n",
    "        # Extract accuracy\n",
    "        accuracy_match = re.search(accuracy_pattern, text)\n",
    "        accuracy = float(accuracy_match.group(1)) if accuracy_match else None\n",
    "\n",
    "        # Extract weighted avg precision, recall, and f1-score\n",
    "        weighted_avg_match = re.search(weighted_avg_pattern, text)\n",
    "        if weighted_avg_match:\n",
    "            precision = float(weighted_avg_match.group(1))\n",
    "            recall = float(weighted_avg_match.group(2))\n",
    "            f1_score = float(weighted_avg_match.group(3))\n",
    "        else:\n",
    "            precision, recall, f1_score = None, None, None\n",
    "\n",
    "        # Extract K-fold cross-validation scores and calculate average\n",
    "        kfold_match = re.search(kfold_pattern, text)\n",
    "        if kfold_match:\n",
    "            kfold_scores = [float(x) for x in kfold_match.group(1).split()]\n",
    "            kfold_avg = sum(kfold_scores) / len(kfold_scores)\n",
    "        else:\n",
    "            kfold_avg = None\n",
    "\n",
    "        # Extract stratified cross-validation scores and calculate average\n",
    "        stratified_match = re.search(stratified_pattern, text)\n",
    "        if stratified_match:\n",
    "            stratified_scores = [float(x) for x in stratified_match.group(1).split()]\n",
    "            stratified_avg = sum(stratified_scores) / len(stratified_scores)\n",
    "        else:\n",
    "            stratified_avg = None\n",
    "\n",
    "        # Append the extracted results to the results list\n",
    "        results_list.append({\n",
    "            \"Source\": extract_source(source),\n",
    "            \"Model\": model,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1_score,\n",
    "            \"K-fold score\": kfold_avg,\n",
    "            \"Stratified score\": stratified_avg\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing source '{source}': {e}\")\n",
    "\n",
    "# Parse all rows with improved regex\n",
    "\n",
    "for row in source_file.itertuples(index=False):\n",
    "    parse_metrics_flexible(row[0], row[1])\n",
    "\n",
    "# Convert parsed results to a DataFrame\n",
    "df_parsed_metrics = pd.DataFrame(results_list)\n",
    "print(df_parsed_metrics.head(12))\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(outputs_with_sources[i][1])\n",
    "\n",
    "df_parsed_metrics.to_csv(\"evaluation_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
