{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b3ce6d-b275-405f-b04a-b7d0ed5602d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849d0bf7-e249-41cd-b809-e7c6109240cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation function\n",
    "def perform_cross_validation(model, X, y, k_folds=5, stratified=True):\n",
    "    if stratified:\n",
    "        cv = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        cv = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_val)\n",
    "        \n",
    "        scores['accuracy'].append(accuracy_score(y_val, predictions))\n",
    "        scores['precision'].append(precision_score(y_val, predictions, average='weighted'))\n",
    "        scores['recall'].append(recall_score(y_val, predictions, average='weighted'))\n",
    "        scores['f1'].append(f1_score(y_val, predictions, average='weighted'))\n",
    "    \n",
    "    return {metric: sum(values)/len(values) for metric, values in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51a31e40-0414-48c5-a772-774fa346d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "def tune_hyperparameters(model, param_grid, X, y, search_type='grid', k_folds=5, stratified=True):\n",
    "    if stratified:\n",
    "        cv = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        cv = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    if search_type == 'grid':\n",
    "        search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    else:\n",
    "        search = RandomizedSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "    \n",
    "    search.fit(X, y)\n",
    "    return search.best_estimator_, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74f5d3bf-ff9f-45bb-9e56-6447d7b0ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(file_path, model_name):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop('target', axis=1)  # Assuming 'target' is the label column\n",
    "    y = data['target']\n",
    "    \n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Define models and parameter grids\n",
    "    models = {\n",
    "        'logistic_regression': (LogisticRegression(), {'C': [0.1, 1, 10]}),\n",
    "        'decision_tree': (DecisionTreeClassifier(), {'max_depth': [5, 10, 20]}),\n",
    "        'random_forest': (RandomForestClassifier(), {'n_estimators': [50, 100, 200], 'max_depth': [10, 20]}),\n",
    "        'naive_bayes': (GaussianNB(), {}),\n",
    "        'svm': (SVC(), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}),\n",
    "        'knn': (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7]}),\n",
    "        'adaboost': (AdaBoostClassifier(), {'n_estimators': [50, 100]}),\n",
    "        'gradient_boost': (GradientBoostingClassifier(), {'n_estimators': [50, 100]}),\n",
    "        'xgboost': (XGBClassifier(), {'n_estimators': [50, 100], 'max_depth': [5, 10]}),\n",
    "        'ann': (MLPClassifier(), {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['relu', 'tanh']})\n",
    "    }\n",
    "    \n",
    "    model, param_grid = models[model_name]\n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    best_model, best_params = tune_hyperparameters(model, param_grid, X_train, y_train, search_type='grid')\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = perform_cross_validation(best_model, X_train, y_train)\n",
    "    \n",
    "    # Train final model and evaluate\n",
    "    best_model.fit(X_train, y_train)\n",
    "    predictions = best_model.predict(X_test)\n",
    "    final_scores = {\n",
    "        'accuracy': accuracy_score(y_test, predictions),\n",
    "        'precision': precision_score(y_test, predictions, average='weighted'),\n",
    "        'recall': recall_score(y_test, predictions, average='weighted'),\n",
    "        'f1': f1_score(y_test, predictions, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'cv_scores': scores,\n",
    "        'test_scores': final_scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272e695-10e6-41a3-8e69-f443180e54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_files = [\n",
    "    \"W100_O25_Features.csv\", \"W100_O50_Features.csv\",\n",
    "    \"W200_O25_Features.csv\", \"W200_O50_Features.csv\",\n",
    "    \"W300_O25_Features.csv\", \"W300_O50_Features.csv\",\n",
    "    \"W400_O25_Features.csv\", \"W400_O50_Features.csv\",\n",
    "    \"W500_O25_Features.csv\", \"W500_O50_Features.csv\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    'logistic_regression', 'decision_tree', 'random_forest', 'naive_bayes',\n",
    "    'svm', 'knn', 'adaboost', 'gradient_boost', 'xgboost', 'ann'\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for file in feature_files:\n",
    "    results[file] = {}\n",
    "    for model in models:\n",
    "        print(f\"Processing {file} with {model}...\")\n",
    "        results[file][model] = train_model(file, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee628ef2-781c-4e09-b244-5c627340682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "final_results = {}\n",
    "\n",
    "# Directory to store results\n",
    "project_path='../'\n",
    "results_dir = os.path.join(project_path, 'data/Model_Results')\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af98de5-83ae-418a-b299-1a3dad1fba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save overall results\n",
    "overall_results_path = os.path.join(results_dir, \"overall_results_W100_O50.json\")\n",
    "with open(overall_results_path, 'w') as f:\n",
    "    json.dump(final_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
